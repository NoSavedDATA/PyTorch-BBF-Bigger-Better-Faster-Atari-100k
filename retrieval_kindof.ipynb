{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57cb10b8-6556-487a-80d5-7f5b165b996a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\diffusers\\utils\\outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msnykralafk\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\sneep\\Python\\bbf\\wandb\\run-20240406_135943-yxljjxtr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/snykralafk/Atari-100k-BBF/runs/yxljjxtr' target=\"_blank\">BBF-retrieval-Assault</a></strong> to <a href='https://wandb.ai/snykralafk/Atari-100k-BBF' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/snykralafk/Atari-100k-BBF' target=\"_blank\">https://wandb.ai/snykralafk/Atari-100k-BBF</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/snykralafk/Atari-100k-BBF/runs/yxljjxtr' target=\"_blank\">https://wandb.ai/snykralafk/Atari-100k-BBF/runs/yxljjxtr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count, chain\n",
    "import tqdm\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "from nosaveddata.nsd_utils.save_hypers import Hypers, nsd_Module\n",
    "from nosaveddata.nsd_utils.nsd_csv import add_to_csv\n",
    "from nosaveddata.nsd_utils.networks import params_count, params_and_grad_norm, seed_np_torch\n",
    "from nosaveddata.nsd_utils.einstein import Rearrange\n",
    "\n",
    "from nosaveddata.builders.mlp import *\n",
    "from nosaveddata.builders.weight_init import *\n",
    "from nosaveddata.builders.resnet import IMPALA_Resnet, DQN_Conv, IMPALA_YY\n",
    "\n",
    "\n",
    "from utils.experience_replay_retrieval import *\n",
    "\n",
    "\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "import wandb\n",
    "\n",
    "\n",
    "# Environment configuration\n",
    "#env_name = 'Kangaroo'\n",
    "#SEED = 8712\n",
    "\n",
    "env_name = 'Assault'\n",
    "SEED = 7783\n",
    "\n",
    "\n",
    "wandb.init(\n",
    "    project=\"Atari-100k-BBF\",\n",
    "    name=f\"BBF-retrieval-{env_name}\",\n",
    "\n",
    "    #id='rotdmtc5',\n",
    "    #resume='must',\n",
    "\n",
    "    config={\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"architecture\": \"BBF\",\n",
    "        \"dataset\": \"Assault\",\n",
    "        \"epochs\": 100,\n",
    "    },\n",
    "\n",
    "    reinit=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Optimization\n",
    "batch_size_critical = 16\n",
    "batch_size = 32\n",
    "lr=1e-4\n",
    "\n",
    "eps=1e-8\n",
    "\n",
    "\n",
    "# Target network EMA rate\n",
    "critic_ema_decay=0.995\n",
    "\n",
    "\n",
    "# Return function\n",
    "initial_gamma=torch.tensor(1-0.97).log()\n",
    "final_gamma=torch.tensor(1-0.997).log()\n",
    "\n",
    "initial_n = 10\n",
    "final_n = 3\n",
    "n_critical=20\n",
    "\n",
    "num_buckets=51\n",
    "\n",
    "# Reset Schedule and Buffer\n",
    "reset_every=40000 # grad steps, not steps.\n",
    "schedule_max_step=reset_every//4\n",
    "total_steps=102000\n",
    "\n",
    "prefetch_cap=1 # actually, no prefetch is being done\n",
    "\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'reward', 'action', 'c_flag'))\n",
    "memory = PrioritizedReplay_nSteps_Sqrt(total_steps+5, total_steps=schedule_max_step, prefetch_cap=prefetch_cap)\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint(net, model_target, optimizer, step, path):\n",
    "    torch.save({\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'model_target_state_dict': model_target.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'step': step,\n",
    "            }, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c831907e-0868-4915-bc34-3d1dd1fe363c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\gymnasium\\vector\\__init__.py:53: UserWarning: \u001b[33mWARN: `gymnasium.vector.make(...)` is deprecated and will be replaced by `gymnasium.make_vec(...)` in v1.0\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# Adapted from: https://github.com/weipu-zhang/STORM/blob/main/env_wrapper.py\n",
    "class MaxLast2FrameSkipWrapper(Hypers, gym.Wrapper):\n",
    "    def __init__(self, env, skip=4, noops=30, seed=0):\n",
    "        super().__init__(env=env)\n",
    "        self.env.action_space.seed(seed)\n",
    "        \n",
    "    def reset(self, **kwargs):\n",
    "        kwargs[\"seed\"] = self.seed\n",
    "        obs, _ = self.env.reset(**kwargs)\n",
    "\n",
    "        return obs, _\n",
    "        \n",
    "    def noop_steps(self, states):\n",
    "        noops = random.randint(0,self.noops)\n",
    "        \n",
    "        for i in range(noops):\n",
    "            state = self.step(np.array([0]))[0]\n",
    "            state = preprocess(state)\n",
    "            states.append(state)\n",
    "        return states\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0\n",
    "        self.obs_buffer = deque(maxlen=2)\n",
    "        for _ in range(self.skip):\n",
    "            obs, reward, done, truncated, info = self.env.step(action)\n",
    "            self.obs_buffer.append(obs)\n",
    "            total_reward += reward\n",
    "\n",
    "            terminated = np.logical_or(done, truncated)\n",
    "            #if terminated.any():\n",
    "            #    for i in range(len(terminated)):\n",
    "            #       obs[i] = self.reset()[0][i]\n",
    "            if done or truncated:\n",
    "                break\n",
    "        if len(self.obs_buffer) == 1:\n",
    "            obs = self.obs_buffer[0]\n",
    "        else:\n",
    "            obs = np.max(np.stack(self.obs_buffer), axis=0)\n",
    "        return obs, total_reward, done, truncated, info\n",
    "        # Life loss is calculated on the training code\n",
    "\n",
    "env = gym.vector.make(f\"{env_name}NoFrameskip-v4\", num_envs=1)\n",
    "env = MaxLast2FrameSkipWrapper(env,seed=SEED)\n",
    "\n",
    "\n",
    "#n_actions = env.action_space.n\n",
    "n_actions = env.action_space[0].n\n",
    "\n",
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "seed_np_torch(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8d429f2-aee0-4c6b-b221-d2a8b09b0e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 35.21M\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 35.21M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def renormalize(tensor, has_batch=False):\n",
    "    shape = tensor.shape\n",
    "    tensor = tensor.view(tensor.shape[0], -1)\n",
    "    max_value,_ = torch.max(tensor, -1, keepdim=True)\n",
    "    min_value,_ = torch.min(tensor, -1, keepdim=True)\n",
    "    return ((tensor - min_value) / (max_value - min_value + 1e-5)).view(shape)\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, n_actions, hiddens=2048, mlp_layers=1, scale_width=4,\n",
    "                 n_atoms=51, Vmin=-10, Vmax=10):\n",
    "        super().__init__()\n",
    "        self.support = torch.linspace(Vmin, Vmax, n_atoms).cuda()\n",
    "        \n",
    "        self.hiddens=hiddens\n",
    "        self.scale_width=scale_width\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "        \n",
    "        self.encoder_cnn = IMPALA_Resnet(scale_width=scale_width, norm=False, init=init_xavier, act=self.act)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Single layer dense that maps the flattened encoded representation into hiddens.\n",
    "        self.projection = MLP(3456*scale_width, med_hiddens=hiddens, out_hiddens=hiddens,\n",
    "                              last_init=init_xavier, layers=1)\n",
    "        self.prediction = MLP(hiddens, out_hiddens=hiddens, layers=1, last_init=init_xavier)\n",
    "        self.G = MLP(hiddens, out_hiddens=1, layers=1, last_init=init_zeros)\n",
    "        self.critical_s_mlp = MLP(hiddens, out_hiddens=1, layers=1, out_act=nn.Sigmoid(), last_init=init_xavier)\n",
    "                                              \n",
    "        self.transition = nn.Sequential(DQN_Conv(32*scale_width+n_actions, 32*scale_width, 3, 1, 1, norm=False, init=init_xavier, act=self.act),\n",
    "                                        DQN_Conv(32*scale_width, 32*scale_width, 3, 1, 1, norm=False, init=init_xavier, act=self.act))\n",
    "\n",
    "        # Single layer dense that maps hiddens into the output dim according to:\n",
    "        # 1. https://arxiv.org/pdf/1707.06887.pdf -- Distributional Reinforcement Learning\n",
    "        # 2. https://arxiv.org/pdf/1511.06581.pdf -- Dueling DQN\n",
    "        self.a = MLP(hiddens, out_hiddens=n_actions*num_buckets, layers=1, in_act=self.act, last_init=init_xavier)\n",
    "        self.v = MLP(hiddens, out_hiddens=num_buckets, layers=1, in_act=self.act, last_init=init_xavier)\n",
    "    \n",
    "        params_count(self, 'DQN')\n",
    "    \n",
    "    def forward(self, X, y_action):\n",
    "        X, z = self.encode(X)\n",
    "        \n",
    "        \n",
    "        q, action = self.q_head(X)\n",
    "        z_pred = self.get_transition(z, y_action)\n",
    "        G_pred = self.G(X)\n",
    "\n",
    "        return q, action, X[:,1:].clone().detach(), z_pred, G_pred\n",
    "    \n",
    "\n",
    "    def env_step(self, X):\n",
    "        with torch.no_grad():\n",
    "            X, _ = self.encode(X)\n",
    "            _, action = self.q_head(X)\n",
    "            \n",
    "            return action.detach()\n",
    "    \n",
    "    def encode(self, X):\n",
    "        batch, seq = X.shape[:2]\n",
    "        self.batch = batch\n",
    "        self.seq = seq\n",
    "        X = self.encoder_cnn(X.contiguous().view(self.batch*self.seq, *(X.shape[2:])))\n",
    "        X = renormalize(X).contiguous().view(self.batch, self.seq, *X.shape[-3:])\n",
    "        X = X.contiguous().view(self.batch, self.seq, *X.shape[-3:])\n",
    "        z = X.clone()\n",
    "        X = X.flatten(-3,-1)\n",
    "        X = self.projection(X)\n",
    "        return X, z\n",
    "\n",
    "    def pred_G(self, X):\n",
    "        X, _ = self.encode(X)\n",
    "        \n",
    "        return self.G(X)\n",
    "        \n",
    "    def pred_critical_states(self, X):\n",
    "        X, _ = self.encode(X)\n",
    "        \n",
    "        return self.critical_s_mlp(X)\n",
    "    \n",
    "    def get_transition(self, z, action):\n",
    "        z = z.contiguous().view(-1, *z.shape[-3:])\n",
    "        \n",
    "        action = F.one_hot(action.clone(), n_actions).view(-1, n_actions)\n",
    "        action = action.view(-1, 5, n_actions, 1, 1).expand(-1, 5, n_actions, *z.shape[-2:])\n",
    "\n",
    "        z_pred = torch.cat( (z, action[:,0]), 1)\n",
    "        z_pred = self.transition(z_pred)\n",
    "        z_pred = renormalize(z_pred)\n",
    "        \n",
    "        z_preds=[z_pred.clone()]\n",
    "        \n",
    "\n",
    "        for k in range(4):\n",
    "            z_pred = torch.cat( (z_pred, action[:,k+1]), 1)\n",
    "            z_pred = self.transition(z_pred)\n",
    "            z_pred = renormalize(z_pred)\n",
    "            \n",
    "            z_preds.append(z_pred)\n",
    "        \n",
    "        \n",
    "        z_pred = torch.stack(z_preds,1)\n",
    "\n",
    "        z_pred = self.projection(z_pred.flatten(-3,-1)).view(self.batch,5,-1)\n",
    "        z_pred = self.prediction(z_pred)\n",
    "        \n",
    "        return z_pred\n",
    "\n",
    "    \n",
    "    def q_head(self, X):\n",
    "        q = self.dueling_dqn(X)\n",
    "        action = (q*self.support).sum(-1).argmax(-1)\n",
    "        \n",
    "        return q, action\n",
    "\n",
    "    def get_max_action(self, X):\n",
    "        with torch.no_grad():\n",
    "            X, _ = self.encode(X)\n",
    "            q = self.dueling_dqn(X)\n",
    "            \n",
    "            action = (q*self.support).sum(-1).argmax(-1)\n",
    "            return action\n",
    "\n",
    "    def evaluate(self, X, action):\n",
    "        with torch.no_grad():\n",
    "            X, _ = self.encode(X)\n",
    "            \n",
    "            q = self.dueling_dqn(X)\n",
    "            \n",
    "            action = action[:,:,None,None].expand_as(q)[:,:,0][:,:,None]\n",
    "            q = q.gather(-2,action)\n",
    "            \n",
    "            return q\n",
    "\n",
    "    def dueling_dqn(self, X):\n",
    "        X = F.relu(X)\n",
    "        \n",
    "        a = self.a(X).view(self.batch, -1, n_actions, num_buckets)\n",
    "        v = self.v(X).view(self.batch, -1, 1, num_buckets)\n",
    "        \n",
    "        q = v + a - a.mean(-2,keepdim=True)\n",
    "        q = F.softmax(q,-1)\n",
    "        \n",
    "        return q\n",
    "    \n",
    "    def network_ema(self, rand_network, target_network, alpha=0.5):\n",
    "        for param, param_target in zip(rand_network.parameters(), target_network.parameters()):\n",
    "            param_target.data = alpha * param_target.data + (1 - alpha) * param.data.clone()\n",
    "\n",
    "    def hard_reset(self, random_model, alpha=0.8):\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            self.network_ema(random_model.encoder_cnn, self.encoder_cnn, alpha)\n",
    "            self.network_ema(random_model.transition, self.transition, alpha)\n",
    "\n",
    "            self.network_ema(random_model.projection, self.projection, 0)\n",
    "            self.network_ema(random_model.prediction, self.prediction, 0)\n",
    "\n",
    "            self.network_ema(random_model.a, self.a, 0)\n",
    "            self.network_ema(random_model.v, self.v, 0)\n",
    "\n",
    "\n",
    "\n",
    "def copy_states(source, target):\n",
    "    for key, _ in zip(source.state_dict()['state'].keys(), target.state_dict()['state'].keys()):\n",
    "\n",
    "        target.state_dict()['state'][key]['exp_avg_sq'] = copy.deepcopy(source.state_dict()['state'][key]['exp_avg_sq'])\n",
    "        target.state_dict()['state'][key]['exp_avg'] = copy.deepcopy(source.state_dict()['state'][key]['exp_avg'])\n",
    "        target.state_dict()['state'][key]['step'] = copy.deepcopy(source.state_dict()['state'][key]['step'])\n",
    "        \n",
    "def target_model_ema(model, model_target):\n",
    "    with torch.no_grad():\n",
    "        for param, param_target in zip(model.parameters(), model_target.parameters()):\n",
    "            param_target.data = critic_ema_decay * param_target.data + (1.0 - critic_ema_decay) * param.data.clone()\n",
    "\n",
    "\n",
    "    \n",
    "model=DQN(n_actions).cuda()\n",
    "model_target=DQN(n_actions).cuda()\n",
    "\n",
    "model_target.load_state_dict(model.state_dict())\n",
    "\n",
    "\n",
    "# Testing only\n",
    "#with torch.no_grad():\n",
    "#    q, action, X, z_pred = model(torch.randn(4,1,12,96,72, device='cuda', dtype=torch.float), torch.randint(0,n_actions,(4,5),device='cuda').long())\n",
    "#z = model.encode(torch.randn(4,5,12,96,72, device='cuda'))[0]\n",
    "\n",
    "# I believe the authors have actually miscalculated the params count on the paper.\n",
    "# My training time is lower than theirs while having more parameters, and the same architecture is used as is their original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ca1d0e5-d128-428b-bcbc-be68dccc005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "perception_modules=[model.encoder_cnn, model.transition]\n",
    "actor_modules=[model.prediction, model.projection, model.a, model.v, model.critical_s_mlp, model.G]\n",
    "\n",
    "params_wm=[]\n",
    "for module in perception_modules:\n",
    "    for param in module.parameters():\n",
    "        if param.requires_grad==True: # They all require grad\n",
    "            params_wm.append(param)\n",
    "\n",
    "params_ac=[]\n",
    "for module in actor_modules:\n",
    "    for param in module.parameters():\n",
    "        if param.requires_grad==True:\n",
    "            params_ac.append(param)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(chain(params_wm, params_ac),\n",
    "                                lr=lr, weight_decay=0.1, eps=1.5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7f2a7d7-81c6-4c93-8cbe-1f15fa75af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "                         transforms.Resize((96,72)),\n",
    "                        ])\n",
    "\n",
    "\n",
    "def preprocess(state):\n",
    "    state=torch.tensor(state, dtype=torch.float, device='cuda') / 255\n",
    "    state=train_tfms(state.permute(0,3,1,2))\n",
    "    return state\n",
    "\n",
    "# https://github.com/google/dopamine/blob/master/dopamine/jax/agents/dqn/dqn_agent.py\n",
    "def linearly_decaying_epsilon(decay_period, step, warmup_steps, epsilon):\n",
    "    steps_left = decay_period + warmup_steps - step\n",
    "    bonus = (1.0 - epsilon) * steps_left / decay_period\n",
    "    bonus = np.clip(bonus, 0., 1. - epsilon)\n",
    "    return epsilon + bonus\n",
    "\n",
    "\n",
    "def epsilon_greedy(Q_action, step, final_eps=0, num_envs=1):\n",
    "    epsilon = linearly_decaying_epsilon(2001, step, 2000, final_eps)\n",
    "    \n",
    "    if random.random() < epsilon:\n",
    "        action = torch.randint(0, n_actions, (num_envs,), dtype=torch.int64, device='cuda').squeeze(0)\n",
    "    else:\n",
    "        action = Q_action.view(num_envs).squeeze(0).to(torch.int64)\n",
    "    return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6722829c-d4bc-4d9f-aa35-80f6133a4819",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# https://github.com/google/dopamine/blob/master/dopamine/jax/agents/rainbow/rainbow_agent.py\n",
    "def project_distribution(supports, weights, target_support):\n",
    "    with torch.no_grad():\n",
    "        v_min, v_max = target_support[0], target_support[-1]\n",
    "        # `N` in Eq7.\n",
    "        num_dims = target_support.shape[-1]\n",
    "        # delta_z = `\\Delta z` in Eq7.\n",
    "        delta_z = (v_max - v_min) / (num_buckets-1)\n",
    "        # clipped_support = `[\\hat{T}_{z_j}]^{V_max}_{V_min}` in Eq7.\n",
    "        clipped_support = supports.clip(v_min, v_max)\n",
    "        # numerator = `|clipped_support - z_i|` in Eq7.\n",
    "        numerator = (clipped_support[:,None] - target_support[None,:,None].repeat_interleave(clipped_support.shape[0],0)).abs()\n",
    "        quotient = 1 - (numerator / delta_z)\n",
    "        # clipped_quotient = `[1 - numerator / (\\Delta z)]_0^1` in Eq7.\n",
    "        clipped_quotient = quotient.clip(0, 1)\n",
    "        # inner_prod = `\\sum_{j=0}^{N-1} clipped_quotient * p_j(x', \\pi(x'))` in Eq7.\n",
    "        inner_prod = (clipped_quotient * weights[:,None]).sum(-1)\n",
    "        #inner_prod = (clipped_quotient).sum(-1) * weights\n",
    "        return inner_prod.squeeze()\n",
    "\n",
    "mse = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "\n",
    "def optimize_critical_states(step, grad_step, n):\n",
    "    model.train()\n",
    "    model_target.train()\n",
    "\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.bfloat16, enabled=False):\n",
    "        with torch.no_grad():\n",
    "            states, next_states, rewards, action, c_flag, idxs, is_w = memory.sample(n*5, batch_size_critical, grad_step)\n",
    "        terminal=1-c_flag\n",
    "        #print(f\"STUFF HERE {states.shape, rewards.shape, c_flag.shape, action.shape, n}\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            gammas_one=torch.ones(batch_size_critical,n*5,1,dtype=torch.float,device='cuda')\n",
    "            gamma_step = 1-torch.tensor(( (schedule_max_step - min(grad_step, schedule_max_step)) / schedule_max_step) * (initial_gamma-final_gamma) + final_gamma).exp()\n",
    "            gammas=gammas_one*gamma_step\n",
    "\n",
    "            \n",
    "            returns = []\n",
    "            for t in range(n*4-1):\n",
    "                ret = 0\n",
    "                for u in reversed(range(t, t+n)):\n",
    "                    ret += torch.prod(c_flag[:,t+1:u+1],-2)*torch.prod(gammas[:,t:u],-2)*rewards[:,u+1]\n",
    "                returns.append(ret)\n",
    "                \n",
    "            returns = torch.stack(returns,1).squeeze()\n",
    "\n",
    "        states = states[:,:-n-2]\n",
    "        \n",
    "        #G_pred = model_target.pred_G(states).squeeze()\n",
    "        critical_states = model.pred_critical_states(states).squeeze()[...,None,None,None]\n",
    "\n",
    "        \n",
    "        importance_preservation = mse(model_target.pred_G(states*critical_states).squeeze(), returns).sum(-1)\n",
    "        reverse = -mse(model_target.pred_G(states*(1-critical_states)).squeeze(), returns).sum(-1)\n",
    "        compactness = critical_states.squeeze().sum(-1)\n",
    "\n",
    "\n",
    "        mask = critical_states.squeeze()\n",
    "        Ort_loss_matrix = torch.abs(mask.mm(mask.t())).cuda()\n",
    "        Ort_loss_matrix = (torch.ones_like(Ort_loss_matrix) - torch.eye(Ort_loss_matrix.size(0)).cuda()) * Ort_loss_matrix\n",
    "        orthogonal_loss = torch.mean(torch.triu(Ort_loss_matrix, diagonal=1))\n",
    "\n",
    "        loss = importance_preservation + 2*reverse + 5e-3*compactness + 5e-4*orthogonal_loss\n",
    "        \n",
    "        loss = (loss*is_w).mean()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        wandb.log({'Importance Preservation': importance_preservation.mean(), 'Reverse': reverse.mean(), 'Compactness': compactness.mean(), 'Critical States Loss': loss})\n",
    "\n",
    "\n",
    "        #print(f\"{states.shape, returns.shape, G_pred.shape}\")\n",
    "        \n",
    "\n",
    "#The remaining hyper-parameters λs, λr, and λv are set to 1, 5 × 10−3 and 2 respectively.\n",
    "\n",
    "\n",
    "def optimize(step, grad_step, n):\n",
    "        \n",
    "    model.train()\n",
    "    model_target.train()\n",
    "\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.bfloat16, enabled=False):\n",
    "        with torch.no_grad():\n",
    "            states, next_states, rewards, action, c_flag, idxs, is_w = memory.sample(n, batch_size, grad_step)\n",
    "        terminal=1-c_flag\n",
    "        #print(f\"STUFF HERE {states.shape, rewards.shape, c_flag.shape, action.shape, n}\")\n",
    "    \n",
    "    \n",
    "        q, max_action, _, z_pred, G_pred = model(states[:,0][:,None], action[:,:5].long())\n",
    "        z = model_target.encode(states[:,1:6])[0].detach()\n",
    "\n",
    "        \n",
    "        max_action  = model.get_max_action(next_states[:,n-1][:,None])\n",
    "        next_values = model_target.evaluate(next_states[:,n-1][:,None].contiguous(), max_action)\n",
    "        \n",
    "\n",
    "        action = action[:,0,None].expand(batch_size,num_buckets)\n",
    "        action=action[:,None]\n",
    "        with torch.no_grad():\n",
    "            gammas_one=torch.ones(batch_size,n,1,dtype=torch.float,device='cuda')\n",
    "            gamma_step = 1-torch.tensor(( (schedule_max_step - min(grad_step, schedule_max_step)) / schedule_max_step) * (initial_gamma-final_gamma) + final_gamma).exp()\n",
    "            gammas=gammas_one*gamma_step\n",
    "\n",
    "            \n",
    "            returns = []\n",
    "            for t in range(n):\n",
    "                ret = 0\n",
    "                for u in reversed(range(t, n)):\n",
    "                    ret += torch.prod(c_flag[:,t+1:u+1],-2)*torch.prod(gammas[:,t:u],-2)*rewards[:,u+1]\n",
    "                returns.append(ret)\n",
    "            returns = torch.stack(returns,1)\n",
    "        \n",
    "        plot_vs = returns.clone().sum(-1)\n",
    "        \n",
    "        same_traj = (torch.prod(c_flag[:,:n],-2)).squeeze()\n",
    "        \n",
    "        returns = returns[:,0]\n",
    "        #G_loss = mse(G_pred.squeeze(), returns.squeeze())\n",
    "        \n",
    "        returns = returns + torch.prod(gammas[0,:10],-2).squeeze()*same_traj[:,None]*model.support[None,:]\n",
    "        returns = returns.squeeze()\n",
    "        \n",
    "        next_values = next_values[:,0]\n",
    "\n",
    "        log_probs = torch.log(q[:,0].gather(-2, action)[:,None] + eps).contiguous()\n",
    "        \n",
    "        \n",
    "        dist = project_distribution(returns, next_values.squeeze(), model.support)\n",
    "        \n",
    "        loss = -(dist*(log_probs.squeeze())).sum(-1).view(batch_size,-1).sum(-1)\n",
    "        dqn_loss = loss.clone().mean()\n",
    "        td_error = (loss + torch.nan_to_num((dist*torch.log(dist))).sum(-1)).mean()\n",
    "\n",
    "        \n",
    "        batched_loss = loss.clone()\n",
    "\n",
    "        #loss += G_loss\n",
    "        \n",
    "        z = F.normalize(z, 2, dim=-1, eps=1e-5)\n",
    "        z_pred = F.normalize(z_pred, 2, dim=-1, eps=1e-5)\n",
    "\n",
    "        \n",
    "        recon_loss = (mse(z_pred.contiguous().view(-1,2048), z.contiguous().view(-1,2048))).sum(-1)\n",
    "        recon_loss = 5*(recon_loss.view(batch_size, -1).mean(-1))*same_traj\n",
    "        \n",
    "        \n",
    "        loss += recon_loss\n",
    "        \n",
    "        loss = (loss*is_w).mean() # mean across batch axis\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    param_norm, grad_norm = params_and_grad_norm(model)\n",
    "    #scaler.scale(loss).backward()\n",
    "    #scaler.unscale_(optimizer)\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "    #scaler.step(optimizer)\n",
    "    #scaler.update()\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #memory.set_priority(idxs, batched_loss)\n",
    "    memory.set_priority(idxs, batched_loss, same_traj)\n",
    "    \n",
    "    \n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    wandb.log({'loss': loss, 'dqn_loss': dqn_loss, 'recon_loss': recon_loss.mean(), 'lr': lr, 'returns': plot_vs.mean(),\n",
    "               'buffer rewards': rewards.mean(0).sum(), 'is_w': is_w.mean(),\n",
    "               'gamma': gamma_step, 'td_error': td_error, 'param_norm': param_norm.sum(), 'grad_norm': grad_norm.sum()})\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scores=[]\n",
    "memory.free()\n",
    "step=0\n",
    "#model.share_memory()\n",
    "grad_step=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c34ff06-59ca-49fb-8af1-3432918a899c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05991348-a11a-43bd-882f-02df107fc543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1980/102000 [00:07<06:02, 275.69it/s]C:\\Users\\sneep\\AppData\\Local\\Temp\\ipykernel_11648\\2975910885.py:108: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gamma_step = 1-torch.tensor(( (schedule_max_step - min(grad_step, schedule_max_step)) / schedule_max_step) * (initial_gamma-final_gamma) + final_gamma).exp()\n",
      "C:\\Users\\sneep\\AppData\\Local\\Temp\\ipykernel_11648\\2975910885.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gamma_step = 1-torch.tensor(( (schedule_max_step - min(grad_step, schedule_max_step)) / schedule_max_step) * (initial_gamma-final_gamma) + final_gamma).exp()\n",
      " 22%|██▏       | 22002/102000 [1:51:56<6:57:38,  3.19it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting on step 22001 40002\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 35.21M\n",
      "IMPALA ResNet Parameters: 1.56M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22003/102000 [1:51:58<18:39:10,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Parameters: 35.21M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 42003/102000 [3:54:13<5:30:40,  3.02it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting on step 42002 40002\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 35.21M\n",
      "IMPALA ResNet Parameters: 1.56M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 42004/102000 [3:54:15<15:22:06,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Parameters: 35.21M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 62004/102000 [7:26:10<3:51:40,  2.88it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting on step 62003 40002\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 35.21M\n",
      "IMPALA ResNet Parameters: 1.56M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 62005/102000 [7:26:13<10:05:25,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Parameters: 35.21M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 82005/102000 [9:35:23<1:44:56,  3.18it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting on step 82004 40002\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 35.21M\n",
      "IMPALA ResNet Parameters: 1.56M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 82006/102000 [9:35:25<4:47:38,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Parameters: 35.21M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102000/102000 [11:49:09<00:00,  2.88it/s] "
     ]
    }
   ],
   "source": [
    "step=0\n",
    "\n",
    "progress_bar = tqdm.tqdm(total=total_steps)\n",
    "\n",
    "while step<(10):\n",
    "    state, info = env.reset()\n",
    "    state = preprocess(state)\n",
    "\n",
    "    states = deque(maxlen=4)\n",
    "    for i in range(4):\n",
    "        states.append(state)\n",
    "    \n",
    "    \n",
    "    eps_reward=torch.tensor([0], dtype=torch.float)\n",
    "    \n",
    "    reward=np.array([0])\n",
    "    done_flag=np.array([False])\n",
    "    terminated=np.array([False])\n",
    "\n",
    "    last_lives=np.array([0])\n",
    "    life_loss=np.array([0])\n",
    "    resetted=np.array([0])\n",
    "    \n",
    "    last_grad_update=0\n",
    "    while step<(total_steps):\n",
    "        progress_bar.update(1)\n",
    "        model_target.train()\n",
    "        \n",
    "        len_memory = len(memory)\n",
    "        \n",
    "        #if resetted[0]>0:\n",
    "        #    states = env.noop_steps(states)\n",
    "            \n",
    "        Q_action = model_target.env_step(torch.cat(list(states),-3).unsqueeze(0))\n",
    "        \n",
    "        action = epsilon_greedy(Q_action, len_memory).cpu()\n",
    "        \n",
    "        memory.push(torch.cat(list(states),-3).detach().cpu(), reward, action, np.logical_or(done_flag, life_loss))\n",
    "        #print('action', action, action.shape)\n",
    "        \n",
    "        state, reward, terminated, truncated, info = env.step([action.numpy()])\n",
    "        state = preprocess(state)\n",
    "        states.append(state)\n",
    "        \n",
    "        eps_reward+=reward\n",
    "        reward = reward.clip(-1, 1)\n",
    "\n",
    "\n",
    "        \n",
    "        done_flag = np.logical_or(terminated, truncated)\n",
    "        lives = info['lives']\n",
    "        life_loss = (last_lives-lives).clip(min=0)\n",
    "        resetted = (lives-last_lives).clip(min=0)\n",
    "        last_lives = lives\n",
    "\n",
    "        \n",
    "        n = int(initial_n * (final_n/initial_n)**(min(grad_step,schedule_max_step) / schedule_max_step))\n",
    "        n = np.array(n).item()\n",
    "        \n",
    "        memory.priority[len_memory] = memory.max_priority()\n",
    "        \n",
    "\n",
    "        if len_memory>2000:\n",
    "            for i in range(2):\n",
    "                optimize(step, grad_step, n)\n",
    "                target_model_ema(model, model_target)\n",
    "                grad_step+=1\n",
    "            optimize_critical_states(step, grad_step, n)\n",
    "\n",
    "        \n",
    "        if ((step+1)%10000)==0:\n",
    "            save_checkpoint(model, model_target, optimizer, step,\n",
    "                            'checkpoints/atari_last.pth')\n",
    "        \n",
    "            \n",
    "        \n",
    "        if grad_step>reset_every:\n",
    "            #eval()\n",
    "            print('Reseting on step', step, grad_step)\n",
    "            \n",
    "            #seed_np_torch(random.randint(SEED-1000, SEED+1000)+step)\n",
    "            random_model = DQN(n_actions).cuda()\n",
    "            model.hard_reset(random_model)\n",
    "            \n",
    "            #seed_np_torch(random.randint(SEED-1000, SEED+1000)+step)\n",
    "            random_model = DQN(n_actions).cuda()\n",
    "            model_target.hard_reset(random_model)\n",
    "            seed_np_torch(SEED)\n",
    "            \n",
    "            random_model=None\n",
    "            grad_step=0\n",
    "\n",
    "            actor_modules=[model.prediction, model.projection, model.a, model.v, model.critical_s_mlp, model.G]\n",
    "            params_ac=[]\n",
    "            for module in actor_modules:\n",
    "                for param in module.parameters():\n",
    "                    params_ac.append(param)\n",
    "                    \n",
    "\n",
    "            perception_modules=[model.encoder_cnn, model.transition]\n",
    "            params_wm=[]\n",
    "            for module in perception_modules:\n",
    "                for param in module.parameters():\n",
    "                    params_wm.append(param)\n",
    "            \n",
    "            optimizer_aux = torch.optim.AdamW(params_wm, lr=lr, weight_decay=0.1, eps=1.5e-4)\n",
    "            copy_states(optimizer, optimizer_aux)\n",
    "            optimizer = torch.optim.AdamW(chain(params_wm, params_ac),\n",
    "                                lr=lr, weight_decay=0.1, eps=1.5e-4)\n",
    "            copy_states(optimizer_aux, optimizer)\n",
    "        \n",
    "        \n",
    "        \n",
    "        step+=1\n",
    "        \n",
    "        log_t = done_flag.astype(float).nonzero()[0]\n",
    "        \n",
    "        if len(log_t)>0:\n",
    "            for log in log_t:\n",
    "                wandb.log({'eps_reward': eps_reward[log].sum()})\n",
    "                scores.append(eps_reward[log].clone())\n",
    "            eps_reward[log_t]=0\n",
    "\n",
    "save_checkpoint(model, model_target, optimizer, step, f'checkpoints/{env_name}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87344597-e733-451c-8a5f-2a00b5511061",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_to_eval=False\n",
    "\n",
    "if load_to_eval:\n",
    "    model.load_state_dict(torch.load(f'checkpoints/{env_name}.pth')['model_state_dict'])\n",
    "    model_target.load_state_dict(torch.load(f'checkpoints/{env_name}.pth')['model_target_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12d36218-ab48-42d9-a7ba-fabb66cc758f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init state torch.Size([1, 3, 96, 72])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 1/100 [00:08<13:52,  8.41s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:19<16:22, 10.03s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [00:26<13:54,  8.60s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [00:30<10:55,  6.83s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [00:34<08:52,  5.61s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [00:38<08:03,  5.15s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [00:48<10:47,  6.96s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [01:00<12:59,  8.47s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [01:11<14:01,  9.24s/it]\u001b[A\n",
      " 10%|█         | 10/100 [01:15<11:16,  7.52s/it]\u001b[A\n",
      " 11%|█         | 11/100 [01:18<09:04,  6.12s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [01:29<11:04,  7.55s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [01:31<08:54,  6.15s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [01:34<07:13,  5.04s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [01:37<06:23,  4.51s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [01:49<09:22,  6.69s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [01:52<07:51,  5.68s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [02:05<10:43,  7.85s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [02:09<09:02,  6.70s/it]\u001b[A\n",
      " 20%|██        | 20/100 [02:21<11:08,  8.36s/it]\u001b[A\n",
      " 21%|██        | 21/100 [02:29<10:41,  8.11s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [02:39<11:26,  8.80s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [02:49<11:36,  9.05s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [03:01<12:24,  9.79s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [03:10<12:02,  9.64s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [03:18<11:22,  9.22s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [03:28<11:36,  9.54s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [03:39<12:00, 10.00s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [03:43<09:40,  8.18s/it]\u001b[A\n",
      " 30%|███       | 30/100 [03:47<07:51,  6.74s/it]\u001b[A\n",
      " 31%|███       | 31/100 [03:50<06:32,  5.68s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [04:01<08:21,  7.38s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [04:05<06:53,  6.18s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [04:08<05:43,  5.20s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [04:12<05:23,  4.97s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [04:22<07:01,  6.59s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [04:34<08:23,  7.99s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [04:37<06:44,  6.53s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [04:43<06:37,  6.52s/it]\u001b[A\n",
      " 40%|████      | 40/100 [04:47<05:36,  5.61s/it]\u001b[A\n",
      " 41%|████      | 41/100 [04:57<06:47,  6.91s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [05:00<05:39,  5.85s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [05:03<04:46,  5.03s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [05:07<04:27,  4.77s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [05:14<04:49,  5.27s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [05:24<06:03,  6.74s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [05:33<06:26,  7.29s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [05:39<06:04,  7.00s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [05:47<06:21,  7.47s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [05:59<07:17,  8.75s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [06:02<05:47,  7.09s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [06:07<05:09,  6.45s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [06:10<04:16,  5.46s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [06:14<03:44,  4.87s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [06:19<03:38,  4.85s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [06:22<03:16,  4.46s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [06:26<03:06,  4.33s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [06:30<02:58,  4.24s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [06:39<03:47,  5.54s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [06:48<04:21,  6.53s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [06:57<04:41,  7.21s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [07:01<04:05,  6.46s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [07:14<05:08,  8.35s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [07:25<05:25,  9.05s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [07:28<04:12,  7.20s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [07:39<04:48,  8.50s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [07:42<03:48,  6.93s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [07:46<03:05,  5.81s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [07:55<03:30,  6.80s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [08:02<03:28,  6.96s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [08:07<02:59,  6.20s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [08:15<03:11,  6.84s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [08:22<03:07,  6.96s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [08:26<02:37,  6.06s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [08:29<02:09,  5.18s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [08:34<01:58,  4.93s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [08:37<01:45,  4.60s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [08:40<01:31,  4.15s/it]\u001b[A\n",
      " 79%|███████▉  | 79/100 [08:44<01:22,  3.91s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [08:48<01:17,  3.90s/it]\u001b[A\n",
      " 81%|████████  | 81/100 [08:51<01:10,  3.73s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [08:59<01:29,  4.98s/it]\u001b[A\n",
      " 83%|████████▎ | 83/100 [09:03<01:17,  4.58s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [09:05<01:03,  3.95s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [09:08<00:56,  3.76s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [09:16<01:09,  4.93s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [09:28<01:32,  7.11s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [09:41<01:47,  8.96s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [09:44<01:18,  7.16s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [09:55<01:22,  8.29s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [09:58<01:00,  6.72s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [10:11<01:06,  8.37s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [10:14<00:48,  6.93s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [10:21<00:40,  6.83s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [10:29<00:36,  7.22s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [10:36<00:28,  7.12s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [10:39<00:17,  5.81s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [10:42<00:10,  5.04s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [10:45<00:04,  4.45s/it]\u001b[A\n",
      "100%|██████████| 100/100 [10:51<00:00,  6.52s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Mean 1626.06\n",
      "Inter Quantile Mean 1446.38\n",
      "Inter Quantile STD 561.1519816686136\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_envs=1\n",
    "\n",
    "#env = gym.vector.make(f\"{env_name}NoFrameskip-v4\", num_envs=num_envs, render_mode='human')\n",
    "env = gym.vector.make(f\"{env_name}NoFrameskip-v4\", num_envs=num_envs)\n",
    "env = MaxLast2FrameSkipWrapper(env,seed=SEED)\n",
    "\n",
    "def eval_phase(eval_runs=50, max_eval_steps=27000, num_envs=1):\n",
    "    progress_bar = tqdm.tqdm(total=eval_runs)\n",
    "    \n",
    "    scores=[]\n",
    "    \n",
    "    state, info = env.reset()\n",
    "    state = preprocess(state)\n",
    "    print(f\"init state {state.shape}\")\n",
    "    \n",
    "    states = deque(maxlen=4)\n",
    "    for i in range(4):\n",
    "        states.append(state)\n",
    "    \n",
    "    \n",
    "    eps_reward=torch.tensor([0]*num_envs, dtype=torch.float)\n",
    "    \n",
    "    reward=np.array([0]*num_envs)\n",
    "    terminated=np.array([False]*num_envs)\n",
    "    \n",
    "    last_lives=np.array([0]*num_envs)\n",
    "    life_loss=np.array([0]*num_envs)\n",
    "    resetted=np.array([0])\n",
    "\n",
    "    finished_envs=np.array([False]*num_envs)\n",
    "    done_flag=0\n",
    "    last_grad_update=0\n",
    "    eval_run=0\n",
    "    step=np.array([0]*num_envs)\n",
    "    while eval_run<eval_runs:\n",
    "        #seed_np_torch(SEED+eval_run)\n",
    "        env.seed=SEED+eval_run\n",
    "        model_target.train()\n",
    "        \n",
    "        #if resetted[0]>0:\n",
    "        #    states = env.noop_steps(states)\n",
    "        \n",
    "        Q_action = model_target.env_step(torch.cat(list(states),-3).unsqueeze(0))\n",
    "        action = epsilon_greedy(Q_action.squeeze(), 5000, 0.0005, num_envs).cpu()\n",
    "        \n",
    "        state, reward, terminated, truncated, info = env.step([action.numpy()] if num_envs==1 else action.numpy())\n",
    "        state = preprocess(state)\n",
    "        states.append(state)\n",
    "        \n",
    "        eps_reward+=reward\n",
    "\n",
    "        \n",
    "        done_flag = np.logical_or(terminated, truncated)\n",
    "        lives = info['lives']\n",
    "        life_loss = (last_lives-lives).clip(min=0)\n",
    "        resetted = (lives-last_lives).clip(min=0)\n",
    "        last_lives = lives        \n",
    "        \n",
    "        step+=1\n",
    "        \n",
    "        log_t = done_flag.astype(float).nonzero()[0]\n",
    "        if len(log_t)>0:# or (step>max_eval_steps).any():\n",
    "            progress_bar.update(1)\n",
    "            for log in log_t:\n",
    "                \n",
    "                if finished_envs[log]==False:\n",
    "                    scores.append(eps_reward[log].clone())\n",
    "                    eval_run+=1\n",
    "                    #finished_envs[log]=True\n",
    "                step[log]=0\n",
    "                \n",
    "            eps_reward[log_t]=0            \n",
    "            for i, log in enumerate(step>max_eval_steps):\n",
    "                if log==True and finished_envs[i]==False:\n",
    "                    scores.append(eps_reward[i].clone())\n",
    "                    step[i]=0\n",
    "                    eval_run+=1\n",
    "                    eps_reward[i]=0\n",
    "                    #finished_envs[i]=True\n",
    "            \n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "def eval(eval_runs=50, max_eval_steps=27000, num_envs=1):\n",
    "    assert num_envs==1, 'The code for num eval envs > 1 is messed up.'\n",
    "    \n",
    "    scores = eval_phase(eval_runs, max_eval_steps, num_envs)    \n",
    "    scores = torch.stack(scores)\n",
    "    scores, _ = scores.sort()\n",
    "    \n",
    "    _25th = eval_runs//4\n",
    "\n",
    "    iq = scores[_25th:-_25th]\n",
    "    iqm = iq.mean()\n",
    "    iqs = iq.std()\n",
    "\n",
    "    print(f\"Scores Mean {scores.mean()}\")\n",
    "    print(f\"Inter Quantile Mean {iqm}\")\n",
    "    print(f\"Inter Quantile STD {iqs}\")\n",
    "\n",
    "    \n",
    "    plt.xlabel('Episode (Sorted by Reward)')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.plot(scores)\n",
    "    \n",
    "    new_row = {'env_name': env_name, 'mean': scores.mean().item(), 'iqm': iqm.item(), 'std': iqs.item(), 'seed': SEED}\n",
    "    add_to_csv('results.csv', new_row)\n",
    "\n",
    "    with open(f'results/{env_name}-{SEED}.txt', 'w') as f:\n",
    "        f.write(f\" Scores Mean {scores.mean()}\\n Inter Quantile Mean {iqm}\\n Inter Quantile STD {iqs}\")\n",
    "    \n",
    "    \n",
    "    return scores\n",
    "\n",
    "scores = eval(eval_runs=100, num_envs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57556912-f811-4eb5-9030-f8f77e3962ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
