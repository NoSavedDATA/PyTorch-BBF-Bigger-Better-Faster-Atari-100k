{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57cb10b8-6556-487a-80d5-7f5b165b996a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\diffusers\\utils\\outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msnykralafk\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\sneep\\Python\\bbf\\wandb\\run-20240219_222619-4kszhyr6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/snykralafk/Atari-100k/runs/4kszhyr6' target=\"_blank\">BBF</a></strong> to <a href='https://wandb.ai/snykralafk/Atari-100k' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/snykralafk/Atari-100k' target=\"_blank\">https://wandb.ai/snykralafk/Atari-100k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/snykralafk/Atari-100k/runs/4kszhyr6' target=\"_blank\">https://wandb.ai/snykralafk/Atari-100k/runs/4kszhyr6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count, chain\n",
    "import tqdm\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "\n",
    "from nosaveddata.builders.mlp import *\n",
    "from nosaveddata.builders.weight_init import *\n",
    "from nosaveddata.nsd_utils.networks import params_count, params_and_grad_norm, seed_np_torch\n",
    "from nosaveddata.builders.resnet import IMPALA_Resnet, DQN_Conv\n",
    "\n",
    "\n",
    "from utils.experience_replay import *\n",
    "\n",
    "\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "\n",
    "\n",
    "import wandb\n",
    "wandb.init(\n",
    "    project=\"Atari-100k\",\n",
    "    name=f\"BBF\",\n",
    "\n",
    "    #id='rotdmtc5',\n",
    "    #resume='must',\n",
    "\n",
    "    config={\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"architecture\": \"BBF\",\n",
    "        \"dataset\": \"Assault\",\n",
    "        \"epochs\": 100,\n",
    "    },\n",
    "\n",
    "    reinit=False\n",
    ")\n",
    "\n",
    "\n",
    "# Environment configuration\n",
    "env_name = 'Assault'\n",
    "SEED = 7783\n",
    "\n",
    "\n",
    "# Optimization\n",
    "batch_size = 32\n",
    "lr=1e-4\n",
    "\n",
    "eps=1e-8\n",
    "\n",
    "\n",
    "# Target network EMA rate\n",
    "critic_ema_decay=0.995\n",
    "\n",
    "\n",
    "# Return function\n",
    "initial_gamma=torch.tensor(1-0.97).log()\n",
    "final_gamma=torch.tensor(1-0.997).log()\n",
    "\n",
    "initial_n = 10\n",
    "final_n = 3\n",
    "\n",
    "num_buckets=51\n",
    "\n",
    "\n",
    "# Reset Schedule and Buffer\n",
    "reset_every=40000 # grad steps, not steps.\n",
    "schedule_max_step=reset_every//4\n",
    "total_steps=100000\n",
    "\n",
    "prefetch_cap=1 # actually, no prefetch is being done\n",
    "\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'reward', 'action', 'c_flag'))\n",
    "memory = PrioritizedReplay_nSteps_Sqrt(100005, total_steps=schedule_max_step, prefetch_cap=prefetch_cap)\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint(net, model_target, optimizer, step, path):\n",
    "    torch.save({\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'model_target_state_dict': model_target.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'step': step,\n",
    "            }, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c831907e-0868-4915-bc34-3d1dd1fe363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxLast2FrameSkipWrapper(gym.Wrapper):\n",
    "    def __init__(self, env, skip=4, seed=0):\n",
    "        super().__init__(env)\n",
    "        self.seed = seed\n",
    "        self.skip = skip\n",
    "        self.env.action_space.seed(seed)\n",
    "        \n",
    "    def reset(self, **kwargs):\n",
    "        kwargs[\"seed\"] = self.seed\n",
    "        obs, _ = self.env.reset(**kwargs)\n",
    "        return obs, _\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0\n",
    "        self.obs_buffer = deque(maxlen=2)\n",
    "        for _ in range(self.skip):\n",
    "            obs, reward, done, truncated, info = self.env.step(action)\n",
    "            self.obs_buffer.append(obs)\n",
    "            total_reward += reward\n",
    "\n",
    "            terminated = np.logical_or(done, truncated)\n",
    "            #if terminated.any():\n",
    "            #    for i in range(len(terminated)):\n",
    "            #       obs[i] = self.reset()[0][i]\n",
    "            if done or truncated:\n",
    "                break\n",
    "        if len(self.obs_buffer) == 1:\n",
    "            obs = self.obs_buffer[0]\n",
    "        else:\n",
    "            obs = np.max(np.stack(self.obs_buffer), axis=0)\n",
    "        return obs, total_reward, done, truncated, info\n",
    "\n",
    "\n",
    "env = gym.vector.make(f\"{env_name}NoFrameskip-v4\", num_envs=1)\n",
    "env = MaxLast2FrameSkipWrapper(env,seed=SEED)\n",
    "\n",
    "\n",
    "#n_actions = env.action_space.n\n",
    "n_actions = env.action_space[0].n\n",
    "\n",
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "seed_np_torch(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8d429f2-aee0-4c6b-b221-d2a8b09b0e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 35.21M\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 35.21M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def renormalize(tensor, has_batch=False):\n",
    "    shape = tensor.shape\n",
    "    tensor = tensor.view(tensor.shape[0], -1)\n",
    "    max_value,_ = torch.max(tensor, -1, keepdim=True)\n",
    "    min_value,_ = torch.min(tensor, -1, keepdim=True)\n",
    "    return ((tensor - min_value) / (max_value - min_value + 1e-5)).view(shape)\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, n_actions, hiddens=2048, mlp_layers=1, scale_width=4,\n",
    "                 n_atoms=51, Vmin=-10, Vmax=10):\n",
    "        super().__init__()\n",
    "        self.support = torch.linspace(Vmin, Vmax, n_atoms).cuda()\n",
    "        \n",
    "        self.hiddens=hiddens\n",
    "        self.scale_width=scale_width\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "        \n",
    "        self.encoder_cnn = IMPALA_Resnet(scale_width=scale_width, norm=False, init=init_relu, act=self.act)\n",
    "        \n",
    "        \n",
    "        #self.projection = MLP(10368, med_hiddens=hiddens, out_hiddens=hiddens,\n",
    "        self.projection = MLP(13824, med_hiddens=hiddens, out_hiddens=hiddens,\n",
    "                              in_act=nn.Identity(), init=init_xavier,\n",
    "                              last_init=init_relu, layers=1)\n",
    "        self.prediction = MLP(hiddens, out_hiddens=hiddens, layers=1, last_init=init_relu)\n",
    "                                              \n",
    "        self.transition = nn.Sequential(DQN_Conv(128+n_actions, 128, 3, 1, 1, norm=False, init=init_xavier, act=self.act),\n",
    "                                        DQN_Conv(128, 128, 3, 1, 1, norm=False, init=init_relu, act=self.act))\n",
    "\n",
    "\n",
    "        self.a = MLP(hiddens, out_hiddens=n_actions*num_buckets, layers=1, in_act=self.act, last_init=init_orth)\n",
    "        self.v = MLP(hiddens, out_hiddens=num_buckets, layers=1, in_act=self.act, last_init=init_orth)\n",
    "    \n",
    "        params_count(self, 'DQN')\n",
    "    \n",
    "    def forward(self, X, y_action):\n",
    "        X, z = self.encode(X)\n",
    "        \n",
    "        \n",
    "        q, action = self.q_head(X)\n",
    "        z_pred = self.get_transition(z, y_action)\n",
    "\n",
    "        return q, action, X[:,1:].clone().detach(), z_pred\n",
    "    \n",
    "\n",
    "    def env_step(self, X):\n",
    "        with torch.no_grad():\n",
    "            X, _ = self.encode(X)\n",
    "            _, action = self.q_head(X)\n",
    "            \n",
    "            return action.detach()\n",
    "    \n",
    "\n",
    "    def encode(self, X):\n",
    "        batch, seq = X.shape[:2]\n",
    "        self.batch = batch\n",
    "        self.seq = seq\n",
    "        X = self.encoder_cnn(X.contiguous().view(self.batch*self.seq, *(X.shape[2:])))\n",
    "        X = renormalize(X).contiguous().view(self.batch, self.seq, *X.shape[-3:])\n",
    "        X = X.contiguous().view(self.batch, self.seq, *X.shape[-3:])\n",
    "        z = X.clone()\n",
    "        X = X.flatten(-3,-1)\n",
    "        X = self.projection(X)\n",
    "        return X, z\n",
    "\n",
    "    def get_transition(self, z, action):\n",
    "        z = z.contiguous().view(-1, *z.shape[-3:])\n",
    "        \n",
    "        action = F.one_hot(action.clone(), n_actions).view(-1, n_actions)\n",
    "        action = action.view(-1, 5, n_actions, 1, 1).expand(-1, 5, n_actions, *z.shape[-2:])\n",
    "\n",
    "        \n",
    "        z_pred = torch.cat( (z, action[:,0]), 1)\n",
    "        z_pred = self.transition(z_pred)\n",
    "        z_pred = renormalize(z_pred)\n",
    "        \n",
    "        z_preds=[z_pred.clone()]\n",
    "        \n",
    "\n",
    "        for k in range(4):\n",
    "            z_pred = torch.cat( (z_pred, action[:,k+1]), 1)\n",
    "            z_pred = self.transition(z_pred)\n",
    "            z_pred = renormalize(z_pred)\n",
    "            \n",
    "            z_preds.append(z_pred)\n",
    "        \n",
    "        \n",
    "        z_pred = torch.stack(z_preds,1)\n",
    "\n",
    "        z_pred = self.projection(z_pred.flatten(-3,-1)).view(self.batch,5,-1)\n",
    "        z_pred = self.prediction(z_pred)\n",
    "        \n",
    "        return z_pred\n",
    "\n",
    "    \n",
    "    def q_head(self, X):\n",
    "        q = self.dueling_dqn(X)\n",
    "        action = (q*self.support).sum(-1).argmax(-1)\n",
    "        \n",
    "        return q, action\n",
    "\n",
    "    def get_max_action(self, X):\n",
    "        with torch.no_grad():\n",
    "            X, _ = self.encode(X)\n",
    "            q = self.dueling_dqn(X)\n",
    "            \n",
    "            action = (q*self.support).sum(-1).argmax(-1)\n",
    "            return action\n",
    "\n",
    "    def evaluate(self, X, action):\n",
    "        with torch.no_grad():\n",
    "            X, _ = self.encode(X)\n",
    "            \n",
    "            q = self.dueling_dqn(X)\n",
    "            \n",
    "            action = action[:,:,None,None].expand_as(q)[:,:,0][:,:,None]\n",
    "            q = q.gather(-2,action)\n",
    "            \n",
    "            return q\n",
    "\n",
    "    def dueling_dqn(self, X):\n",
    "        X = F.relu(X)\n",
    "        \n",
    "        a = self.a(X).view(self.batch, -1, n_actions, num_buckets)\n",
    "        v = self.v(X).view(self.batch, -1, 1, num_buckets)\n",
    "        \n",
    "        q = v + a - a.mean(-2,keepdim=True)\n",
    "        q = F.softmax(q,-1)\n",
    "        \n",
    "        return q\n",
    "    \n",
    "    def network_ema(self, rand_network, target_network, alpha=0.5):\n",
    "        for param, param_target in zip(rand_network.parameters(), target_network.parameters()):\n",
    "            param_target.data = alpha * param_target.data + (1 - alpha) * param.data.clone()\n",
    "\n",
    "    def hard_reset(self, random_model, alpha=0.5):\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            self.network_ema(random_model.encoder_cnn, self.encoder_cnn, alpha)\n",
    "            self.network_ema(random_model.transition, self.transition, alpha)\n",
    "\n",
    "            self.network_ema(random_model.projection, self.projection, 0)\n",
    "            self.network_ema(random_model.prediction, self.prediction, 0)\n",
    "\n",
    "            self.network_ema(random_model.a, self.a, 0)\n",
    "            self.network_ema(random_model.v, self.v, 0)\n",
    "\n",
    "\n",
    "\n",
    "def copy_states(source, target):\n",
    "    for key, _ in zip(source.state_dict()['state'].keys(), target.state_dict()['state'].keys()):\n",
    "\n",
    "        target.state_dict()['state'][key]['exp_avg_sq'] = copy.deepcopy(source.state_dict()['state'][key]['exp_avg_sq'])\n",
    "        target.state_dict()['state'][key]['exp_avg'] = copy.deepcopy(source.state_dict()['state'][key]['exp_avg'])\n",
    "        target.state_dict()['state'][key]['step'] = copy.deepcopy(source.state_dict()['state'][key]['step'])\n",
    "        \n",
    "def target_model_ema(model, model_target):\n",
    "    with torch.no_grad():\n",
    "        for param, param_target in zip(model.parameters(), model_target.parameters()):\n",
    "            param_target.data = critic_ema_decay * param_target.data + (1.0 - critic_ema_decay) * param.data.clone()\n",
    "\n",
    "\n",
    "    \n",
    "model=DQN(n_actions).cuda()\n",
    "model_target=DQN(n_actions).cuda()\n",
    "\n",
    "model_target.load_state_dict(model.state_dict())\n",
    "\n",
    "\n",
    "# Testing only\n",
    "#with torch.no_grad():\n",
    "#    q, action, X, z_pred = model(torch.randn(4,1,12,96,72, device='cuda', dtype=torch.float), torch.randint(0,n_actions,(4,5),device='cuda').long())\n",
    "#z = model.encode(torch.randn(4,5,12,96,72, device='cuda'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ca1d0e5-d128-428b-bcbc-be68dccc005c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model number of parameters: 35.21M\n",
      "\n"
     ]
    }
   ],
   "source": [
    "perception_modules=[model.encoder_cnn, model.transition]\n",
    "actor_modules=[model.prediction, model.projection, model.a, model.v]\n",
    "\n",
    "params_wm=[]\n",
    "for module in perception_modules:\n",
    "    for param in module.parameters():\n",
    "        if param.requires_grad==True: # They all require grad\n",
    "            params_wm.append(param)\n",
    "\n",
    "params_ac=[]\n",
    "for module in actor_modules:\n",
    "    for param in module.parameters():\n",
    "        if param.requires_grad==True:\n",
    "            params_ac.append(param)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(chain(params_wm, params_ac),\n",
    "                                lr=lr, weight_decay=0.1, eps=1.5e-4)\n",
    "\n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr*1.2,\n",
    "#                     total_steps=100000//initial_n//batch_size*16)\n",
    "\n",
    "\n",
    "params_to_count = [p for p in model.parameters() if p.requires_grad]\n",
    "print()\n",
    "print(f'Model number of parameters: {sum(p.numel() for p in params_to_count)/1e6:.2f}M')\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7f2a7d7-81c6-4c93-8cbe-1f15fa75af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "                         transforms.Resize((96,72)),\n",
    "                        ])\n",
    "\n",
    "\n",
    "def preprocess(state):\n",
    "    state=torch.tensor(state, dtype=torch.float, device='cuda') / 255\n",
    "    state=train_tfms(state.permute(0,3,1,2))\n",
    "    return state\n",
    "\n",
    "\n",
    "def linearly_decaying_epsilon(decay_period, step, warmup_steps, epsilon):\n",
    "    steps_left = decay_period + warmup_steps - step\n",
    "    bonus = (1.0 - epsilon) * steps_left / decay_period\n",
    "    bonus = np.clip(bonus, 0., 1. - epsilon)\n",
    "    return epsilon + bonus\n",
    "\n",
    "\n",
    "def epsilon_greedy(Q_action, step, final_eps=0, num_envs=1):\n",
    "    epsilon = linearly_decaying_epsilon(2001, step, 2000, final_eps)\n",
    "    \n",
    "    if random.random() < epsilon:\n",
    "        action = torch.randint(0, n_actions, (num_envs,), dtype=torch.int64, device='cuda').squeeze(0)\n",
    "    else:\n",
    "        action = Q_action.view(num_envs).squeeze(0).to(torch.int64)\n",
    "    return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6722829c-d4bc-4d9f-aa35-80f6133a4819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/google/dopamine/blob/master/dopamine/jax/agents/rainbow/rainbow_agent.py\n",
    "def project_distribution(supports, weights, target_support):\n",
    "    with torch.no_grad():\n",
    "        v_min, v_max = target_support[0], target_support[-1]\n",
    "        # `N` in Eq7.\n",
    "        num_dims = target_support.shape[-1]\n",
    "        # delta_z = `\\Delta z` in Eq7.\n",
    "        delta_z = (v_max - v_min) / (num_buckets-1)\n",
    "        # clipped_support = `[\\hat{T}_{z_j}]^{V_max}_{V_min}` in Eq7.\n",
    "        clipped_support = supports.clip(v_min, v_max)\n",
    "        # numerator = `|clipped_support - z_i|` in Eq7.\n",
    "        numerator = (clipped_support[:,None] - target_support[None,:,None].repeat_interleave(clipped_support.shape[0],0)).abs()\n",
    "        quotient = 1 - (numerator / delta_z)\n",
    "        # clipped_quotient = `[1 - numerator / (\\Delta z)]_0^1` in Eq7.\n",
    "        clipped_quotient = quotient.clip(0, 1)\n",
    "        # inner_prod = `\\sum_{j=0}^{N-1} clipped_quotient * p_j(x', \\pi(x'))` in Eq7.\n",
    "        inner_prod = (clipped_quotient * weights[:,None]).sum(-1)\n",
    "        #inner_prod = (clipped_quotient).sum(-1) * weights\n",
    "        return inner_prod.squeeze()\n",
    "\n",
    "\n",
    "mse = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "def optimize(step, grad_step, n):\n",
    "        \n",
    "    model.train()\n",
    "    #model_target.eval()\n",
    "    model_target.train()\n",
    "\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.bfloat16, enabled=False):\n",
    "        with torch.no_grad():\n",
    "            states, next_states, rewards, action, c_flag, idxs, is_w = memory.sample(n, batch_size, grad_step)\n",
    "        terminal=1-c_flag\n",
    "        #print(f\"STUFF HERE {states.shape, rewards.shape, c_flag.shape, action.shape, n}\")\n",
    "    \n",
    "    \n",
    "        q, max_action, z, z_pred = model(states[:,0][:,None], action[:,:5].long())\n",
    "        z = model_target.encode(states[:,1:6])[0].detach()\n",
    "\n",
    "        # They actually use n-1 for next states.\n",
    "        max_action  = model.get_max_action(next_states[:,n][:,None])\n",
    "        next_values = model_target.evaluate(next_states[:,n][:,None].contiguous(), max_action)\n",
    "        \n",
    "\n",
    "        action = action[:,0,None].expand(batch_size,num_buckets)\n",
    "        action=action[:,None]\n",
    "        with torch.no_grad():\n",
    "            gammas_one=torch.ones(batch_size,n,1,dtype=torch.float,device='cuda')\n",
    "            gamma_step = 1-torch.tensor(( (schedule_max_step - min(grad_step, schedule_max_step)) / schedule_max_step) * (initial_gamma-final_gamma) + final_gamma).exp()\n",
    "            gammas=gammas_one*gamma_step\n",
    "\n",
    "            \n",
    "            returns = []\n",
    "            for t in range(n):\n",
    "                ret = 0\n",
    "                for u in reversed(range(t, n)):\n",
    "                    ret += torch.prod(c_flag[:,t+1:u+1],-2)*torch.prod(gammas[:,t:u],-2)*rewards[:,u+1]\n",
    "                returns.append(ret)\n",
    "            returns = torch.stack(returns,1)\n",
    "        \n",
    "        plot_vs = returns.clone().sum(-1)\n",
    "        \n",
    "        same_traj = (torch.prod(c_flag[:,:n],-2)).squeeze()\n",
    "        \n",
    "        returns = returns[:,0]\n",
    "        returns = returns + torch.prod(gammas[0,:10],-2).squeeze()*same_traj[:,None]*model.support[None,:]\n",
    "        returns = returns.squeeze()\n",
    "        \n",
    "        next_values = next_values[:,0]\n",
    "\n",
    "        log_probs = torch.log(q[:,0].gather(-2, action)[:,None] + eps).contiguous()\n",
    "        \n",
    "        \n",
    "        dist = project_distribution(returns, next_values.squeeze(), model.support)\n",
    "        \n",
    "        loss = -(dist*(log_probs.squeeze())).sum(-1).view(batch_size,-1).sum(-1)\n",
    "        dqn_loss = loss.clone().mean()\n",
    "        td_error = (loss + torch.nan_to_num((dist*torch.log(dist))).sum(-1)).mean()\n",
    "\n",
    "        \n",
    "        batched_loss = loss.clone()\n",
    "        \n",
    "        \n",
    "        z = F.normalize(z, 2, dim=-1, eps=1e-5)\n",
    "        z_pred = F.normalize(z_pred, 2, dim=-1, eps=1e-5)\n",
    "\n",
    "        #z_mask = z_mask[:,:,:5]\n",
    "        #z_mask = z_mask.contiguous().view(5,-1).cuda()\n",
    "        #recon_loss = (mse(z_pred.contiguous().view(5,-1,2048), z.contiguous().view(-1,2048).unsqueeze(0).repeat_interleave(5,0))).sum(-1)*z_mask\n",
    "        #recon_loss = 5*((recon_loss.mean(0).view(batch_size,-1))*same_traj[:,None]).sum(-1)\n",
    "        \n",
    "        recon_loss = (mse(z_pred.contiguous().view(-1,2048), z.contiguous().view(-1,2048))).sum(-1)\n",
    "        recon_loss = 5*(recon_loss.view(batch_size, -1).mean(-1))*same_traj\n",
    "        \n",
    "        \n",
    "        loss += recon_loss\n",
    "        \n",
    "        loss = (loss*is_w).mean() # mean across batch axis\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    param_norm, grad_norm = params_and_grad_norm(model)\n",
    "    #scaler.scale(loss).backward()\n",
    "    #scaler.unscale_(optimizer)\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "    #scaler.step(optimizer)\n",
    "    #scaler.update()\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #memory.set_priority(idxs, batched_loss)\n",
    "    memory.set_priority(idxs, batched_loss, same_traj)\n",
    "    \n",
    "    \n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    wandb.log({'loss': loss, 'dqn_loss': dqn_loss, 'recon_loss': recon_loss.mean(), 'lr': lr, 'returns': plot_vs.mean(),\n",
    "               'rewards': rewards.mean(0).sum(), 'is_w': is_w.mean(),\n",
    "               'gamma': gamma_step, 'td_error': td_error, 'param_norm': param_norm.sum(), 'grad_norm': grad_norm.sum()})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scores=[]\n",
    "memory.free()\n",
    "step=0\n",
    "#model.share_memory()\n",
    "grad_step=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05991348-a11a-43bd-882f-02df107fc543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1975/100002 [00:07<05:14, 311.72it/s]C:\\Users\\sneep\\AppData\\Local\\Temp\\ipykernel_5152\\2221393133.py:96: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gamma_step = 1-torch.tensor(( (schedule_max_step - min(grad_step, schedule_max_step)) / schedule_max_step) * (initial_gamma-final_gamma) + final_gamma).exp()\n",
      "  6%|▋         | 6438/100002 [11:31<3:33:54,  7.29it/s]\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "step=0\n",
    "\n",
    "progress_bar = tqdm.tqdm(total=100002)\n",
    "\n",
    "while step<(10):\n",
    "    state, info = env.reset()\n",
    "    state = preprocess(state)\n",
    "\n",
    "    stacked = state.repeat_interleave(3,1)\n",
    "    state = torch.cat((stacked.clone(), state),1)\n",
    "    \n",
    "    \n",
    "    eps_reward=torch.tensor([0], dtype=torch.float)\n",
    "    \n",
    "    reward=np.array([0])\n",
    "    done_flag=np.array([False])\n",
    "    terminated=np.array([False])\n",
    "\n",
    "    last_lives=np.array([0])\n",
    "    life_loss=np.array([0])\n",
    "    \n",
    "    last_grad_update=0\n",
    "    while step<(total_steps):\n",
    "        progress_bar.update(1)\n",
    "        model_target.train()\n",
    "        \n",
    "        len_memory = len(memory)\n",
    "        Q_action = model_target.env_step(state.unsqueeze(0))\n",
    "        \n",
    "        action = epsilon_greedy(Q_action, len_memory).cpu()\n",
    "        \n",
    "        memory.push(state.detach().cpu(), reward, action, np.logical_or(done_flag, life_loss))\n",
    "        #print('action', action, action.shape)\n",
    "        \n",
    "        state, reward, terminated, truncated, info = env.step([action.numpy()])\n",
    "        \n",
    "        state = preprocess(state)\n",
    "        eps_reward+=reward\n",
    "        reward = reward.clip(-1, 1)\n",
    "\n",
    "        state = torch.cat((stacked.clone(), state),1)\n",
    "        stacked = torch.cat((stacked[:,3:], state[:,-3:]),1)\n",
    "\n",
    "        \n",
    "        done_flag = np.logical_or(terminated, truncated)\n",
    "        lives = info['lives']\n",
    "        life_loss = (last_lives-lives).clip(min=0)\n",
    "        last_lives = lives\n",
    "\n",
    "        \n",
    "        n = int(initial_n * (final_n/initial_n)**(min(grad_step,schedule_max_step) / schedule_max_step))\n",
    "        n = np.array(n).item()\n",
    "        \n",
    "        memory.priority[len_memory] = memory.max_priority()\n",
    "        \n",
    "\n",
    "        if len_memory>2000:\n",
    "            for i in range(2):\n",
    "                optimize(step, grad_step, n)\n",
    "                target_model_ema(model, model_target)\n",
    "                grad_step+=1\n",
    "\n",
    "        \n",
    "        if ((step+1)%10000)==0:\n",
    "            save_checkpoint(model, model_target, optimizer, step,\n",
    "                            'checkpoints/atari_last.pth')\n",
    "        \n",
    "            \n",
    "        \n",
    "        if grad_step>reset_every:\n",
    "            #eval()\n",
    "            print('Reseting on step', step, grad_step)\n",
    "            \n",
    "            seed_np_torch(random.randint(SEED-1000, SEED+1000))\n",
    "            random_model = DQN(n_actions).cuda()\n",
    "            model.hard_reset(random_model)\n",
    "            \n",
    "            seed_np_torch(random.randint(SEED-1000, SEED+1000))\n",
    "            random_model = DQN(n_actions).cuda()\n",
    "            model_target.hard_reset(random_model)\n",
    "            seed_np_torch(SEED)\n",
    "            \n",
    "            random_model=None\n",
    "            grad_step=0\n",
    "\n",
    "            actor_modules=[model.prediction, model.projection, model.a, model.v]\n",
    "            params_ac=[]\n",
    "            for module in actor_modules:\n",
    "                for param in module.parameters():\n",
    "                    params_ac.append(param)\n",
    "                    \n",
    "\n",
    "            perception_modules=[model.encoder_cnn, model.transition]\n",
    "            params_wm=[]\n",
    "            for module in perception_modules:\n",
    "                for param in module.parameters():\n",
    "                    params_wm.append(param)\n",
    "            \n",
    "            optimizer_aux = torch.optim.AdamW(params_wm, lr=lr, weight_decay=0.1, eps=1.5e-4)\n",
    "            copy_states(optimizer, optimizer_aux)\n",
    "            optimizer = torch.optim.AdamW(chain(params_wm, params_ac),\n",
    "                                lr=lr, weight_decay=0.1, eps=1.5e-4)\n",
    "            copy_states(optimizer_aux, optimizer)\n",
    "            \n",
    "        \n",
    "        \n",
    "        step+=1\n",
    "        \n",
    "        log_t = done_flag.astype(float).nonzero()[0]\n",
    "        \n",
    "        if len(log_t)>0:\n",
    "            for log in log_t:\n",
    "                wandb.log({'eps_reward': eps_reward[log].sum()})\n",
    "                scores.append(eps_reward[log].clone())\n",
    "            eps_reward[log_t]=0\n",
    "\n",
    "save_checkpoint(model, model_target, optimizer, step, f'checkpoints/{env_name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87344597-e733-451c-8a5f-2a00b5511061",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_to_eval=True\n",
    "\n",
    "if load_to_eval:\n",
    "    model.load_state_dict(torch.load(f'checkpoints/{env_name}.pth')['model_state_dict'])\n",
    "    model_target.load_state_dict(torch.load(f'checkpoints/{env_name}.pth')['model_target_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12d36218-ab48-42d9-a7ba-fabb66cc758f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init state torch.Size([1, 3, 96, 72])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 12%|█▎        | 1/8 [00:24<02:52, 24.70s/it]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 2/8 [00:33<01:31, 15.22s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 3/8 [01:00<01:44, 20.86s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 4/8 [01:31<01:39, 24.85s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▎   | 5/8 [01:39<00:56, 18.80s/it]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 6/8 [01:47<00:29, 14.84s/it]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 7/8 [02:14<00:18, 18.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 8/8 [02:40<00:00, 20.03s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter Quantile Mean 1992.25\n",
      "Inter Quantile STD 1405.6797584561475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_envs=1\n",
    "\n",
    "#env = gym.vector.make(f\"AssaultNoFrameskip-v4\", num_envs=num_envs, render_mode='human')\n",
    "env = gym.vector.make(f\"{env_name}NoFrameskip-v4\", num_envs=num_envs)\n",
    "env = MaxLast2FrameSkipWrapper(env,seed=SEED)\n",
    "\n",
    "def eval_phase(eval_runs=50, max_eval_steps=27000, num_envs=1):\n",
    "    progress_bar = tqdm.tqdm(total=eval_runs)\n",
    "    \n",
    "    scores=[]\n",
    "    \n",
    "    state, info = env.reset()\n",
    "    state = preprocess(state)\n",
    "    print(f\"init state {state.shape}\")\n",
    "    stacked = state.repeat_interleave(3,1)\n",
    "    state = torch.cat((stacked.clone(), state),1)\n",
    "    \n",
    "    \n",
    "    eps_reward=torch.tensor([0]*num_envs, dtype=torch.float)\n",
    "    \n",
    "    reward=np.array([0]*num_envs)\n",
    "    terminated=np.array([False]*num_envs)\n",
    "\n",
    "    last_lives=np.array([0]*num_envs)\n",
    "\n",
    "    finished_envs=np.array([False]*num_envs)\n",
    "    done_flag=0\n",
    "    last_grad_update=0\n",
    "    eval_run=0\n",
    "    step=np.array([0]*num_envs)\n",
    "    while eval_run<eval_runs:\n",
    "        #seed_np_torch(SEED+eval_run)\n",
    "        env.seed=SEED+eval_run\n",
    "\n",
    "        model.train()\n",
    "        model_target.train()\n",
    "        \n",
    "        Q_action = model_target.env_step(state.unsqueeze(0))\n",
    "        action = epsilon_greedy(Q_action.squeeze(), 5000, 0.0005, num_envs).cpu()\n",
    "        \n",
    "        state, reward, terminated, truncated, info = env.step([action.numpy()] if num_envs==1 else action.numpy())\n",
    "        done_flag = np.logical_or(terminated, truncated)\n",
    "        \n",
    "\n",
    "        state = preprocess(state)\n",
    "        eps_reward+=reward\n",
    "\n",
    "\n",
    "        \n",
    "        state = torch.cat((stacked.clone(), state),1)\n",
    "        stacked = torch.cat((stacked[:,3:], state[:,-3:]),1)\n",
    "        \n",
    "        \n",
    "        step+=1\n",
    "        \n",
    "        log_t = done_flag.astype(float).nonzero()[0]\n",
    "        if len(log_t)>0:# or (step>max_eval_steps).any():\n",
    "            progress_bar.update(1)\n",
    "            for log in log_t:\n",
    "                #wandb.log({'eval_eps_reward': eps_reward[log].sum()})\n",
    "                if finished_envs[log]==False:\n",
    "                    scores.append(eps_reward[log].clone())\n",
    "                    eval_run+=1\n",
    "                    #finished_envs[log]=True\n",
    "                step[log]=0\n",
    "                \n",
    "            eps_reward[log_t]=0            \n",
    "            for i, log in enumerate(step>max_eval_steps):\n",
    "                if log==True and finished_envs[i]==False:\n",
    "                    scores.append(eps_reward[i].clone())\n",
    "                    step[i]=0\n",
    "                    eval_run+=1\n",
    "                    eps_reward[i]=0\n",
    "                    #finished_envs[i]=True\n",
    "            \n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "def eval(eval_runs=50, max_eval_steps=27000, num_envs=1):\n",
    "    assert num_envs==1, 'The code for num eval envs > 1 is messed up.'\n",
    "    scores = eval_phase(eval_runs, max_eval_steps, num_envs)    \n",
    "    scores = torch.stack(scores)\n",
    "    scores, _ = scores.sort()\n",
    "    \n",
    "    _25th = eval_runs//4\n",
    "\n",
    "    iq = scores[_25th:-_25th]\n",
    "    iqm = iq.mean()\n",
    "    iqs = iq.std()\n",
    "    \n",
    "    print(f\"Inter Quantile Mean {iqm}\")\n",
    "    print(f\"Inter Quantile STD {iqs}\")\n",
    "\n",
    "    \n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.plot(scores)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "scores = eval(eval_runs=8, num_envs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc597714-f3a3-4037-b5ad-d7b8e0e1d3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, _ = scores.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2f9901c-cb5d-47b5-814c-69c548100147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 713.,  846.,  919., 2904., 2996., 3071., 3090., 3339.],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cddb4f-7fdd-4b4b-8e62-33d92f4313df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
