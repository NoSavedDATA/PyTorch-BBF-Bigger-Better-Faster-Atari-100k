{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57cb10b8-6556-487a-80d5-7f5b165b996a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\diffusers\\utils\\outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msnykralafk\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\sneep\\Python\\bbf\\wandb\\run-20240224_171506-bekgakjw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/snykralafk/Atari-100k/runs/bekgakjw' target=\"_blank\">BBF</a></strong> to <a href='https://wandb.ai/snykralafk/Atari-100k' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/snykralafk/Atari-100k' target=\"_blank\">https://wandb.ai/snykralafk/Atari-100k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/snykralafk/Atari-100k/runs/bekgakjw' target=\"_blank\">https://wandb.ai/snykralafk/Atari-100k/runs/bekgakjw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count, chain\n",
    "import tqdm\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "\n",
    "from nosaveddata.nsd_utils.networks import params_count, params_and_grad_norm, seed_np_torch\n",
    "from nosaveddata.nsd_utils.einstein import Rearrange\n",
    "\n",
    "from nosaveddata.builders.mlp import *\n",
    "from nosaveddata.builders.weight_init import *\n",
    "from nosaveddata.builders.resnet import IMPALA_Resnet, DQN_Conv\n",
    "\n",
    "\n",
    "from utils.experience_replay import *\n",
    "\n",
    "\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "\n",
    "\n",
    "import wandb\n",
    "wandb.init(\n",
    "    project=\"Atari-100k\",\n",
    "    name=f\"BBF\",\n",
    "\n",
    "    #id='rotdmtc5',\n",
    "    #resume='must',\n",
    "\n",
    "    config={\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"architecture\": \"BBF\",\n",
    "        \"dataset\": \"Assault\",\n",
    "        \"epochs\": 100,\n",
    "    },\n",
    "\n",
    "    reinit=False\n",
    ")\n",
    "\n",
    "\n",
    "# Environment configuration\n",
    "env_name = 'Boxing'\n",
    "SEED = 7800\n",
    "\n",
    "\n",
    "# Optimization\n",
    "batch_size = 32\n",
    "lr=1e-4\n",
    "\n",
    "eps=1e-8\n",
    "\n",
    "\n",
    "# Target network EMA rate\n",
    "critic_ema_decay=0.995\n",
    "\n",
    "\n",
    "# Return function\n",
    "initial_gamma=torch.tensor(1-0.97).log()\n",
    "final_gamma=torch.tensor(1-0.997).log()\n",
    "\n",
    "initial_n = 10\n",
    "final_n = 3\n",
    "\n",
    "num_buckets=51\n",
    "\n",
    "\n",
    "# Reset Schedule and Buffer\n",
    "reset_every=40000 # grad steps, not steps.\n",
    "schedule_max_step=reset_every//4\n",
    "total_steps=100000\n",
    "\n",
    "prefetch_cap=1 # actually, no prefetch is being done\n",
    "\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'reward', 'action', 'c_flag'))\n",
    "memory = PrioritizedReplay_nSteps_Sqrt(100005, total_steps=schedule_max_step, prefetch_cap=prefetch_cap)\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint(net, model_target, optimizer, step, path):\n",
    "    torch.save({\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'model_target_state_dict': model_target.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'step': step,\n",
    "            }, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c831907e-0868-4915-bc34-3d1dd1fe363c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\gymnasium\\vector\\__init__.py:53: UserWarning: \u001b[33mWARN: `gymnasium.vector.make(...)` is deprecated and will be replaced by `gymnasium.make_vec(...)` in v1.0\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/weipu-zhang/STORM/blob/main/env_wrapper.py\n",
    "class MaxLast2FrameSkipWrapper(gym.Wrapper):\n",
    "    def __init__(self, env, skip=4, seed=0):\n",
    "        super().__init__(env)\n",
    "        self.seed = seed\n",
    "        self.skip = skip\n",
    "        self.env.action_space.seed(seed)\n",
    "        \n",
    "    def reset(self, **kwargs):\n",
    "        kwargs[\"seed\"] = self.seed\n",
    "        obs, _ = self.env.reset(**kwargs)\n",
    "        return obs, _\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0\n",
    "        self.obs_buffer = deque(maxlen=2)\n",
    "        for _ in range(self.skip):\n",
    "            obs, reward, done, truncated, info = self.env.step(action)\n",
    "            self.obs_buffer.append(obs)\n",
    "            total_reward += reward\n",
    "\n",
    "            terminated = np.logical_or(done, truncated)\n",
    "            #if terminated.any():\n",
    "            #    for i in range(len(terminated)):\n",
    "            #       obs[i] = self.reset()[0][i]\n",
    "            if done or truncated:\n",
    "                break\n",
    "        if len(self.obs_buffer) == 1:\n",
    "            obs = self.obs_buffer[0]\n",
    "        else:\n",
    "            obs = np.max(np.stack(self.obs_buffer), axis=0)\n",
    "        return obs, total_reward, done, truncated, info\n",
    "        # Life loss is calculated on the training code\n",
    "\n",
    "env = gym.vector.make(f\"{env_name}NoFrameskip-v4\", num_envs=1)\n",
    "env = MaxLast2FrameSkipWrapper(env,seed=SEED)\n",
    "\n",
    "\n",
    "#n_actions = env.action_space.n\n",
    "n_actions = env.action_space[0].n\n",
    "\n",
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "seed_np_torch(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8d429f2-aee0-4c6b-b221-d2a8b09b0e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 36.37M\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 36.37M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def renormalize(tensor, has_batch=False):\n",
    "    shape = tensor.shape\n",
    "    tensor = tensor.view(tensor.shape[0], -1)\n",
    "    max_value,_ = torch.max(tensor, -1, keepdim=True)\n",
    "    min_value,_ = torch.min(tensor, -1, keepdim=True)\n",
    "    return ((tensor - min_value) / (max_value - min_value + 1e-5)).view(shape)\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, n_actions, hiddens=2048, mlp_layers=1, scale_width=4,\n",
    "                 n_atoms=51, Vmin=-10, Vmax=10):\n",
    "        super().__init__()\n",
    "        self.support = torch.linspace(Vmin, Vmax, n_atoms).cuda()\n",
    "        \n",
    "        self.hiddens=hiddens\n",
    "        self.scale_width=scale_width\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "        \n",
    "        self.encoder_cnn = IMPALA_Resnet(scale_width=scale_width, norm=False, init=init_xavier, act=self.act)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Single layer dense that maps the flattened encoded representation into hiddens.\n",
    "        self.projection = MLP(13824, med_hiddens=hiddens, out_hiddens=hiddens,\n",
    "                              last_init=init_xavier, layers=1)\n",
    "        self.prediction = MLP(hiddens, out_hiddens=hiddens, layers=1, last_init=init_xavier)\n",
    "                                              \n",
    "        self.transition = nn.Sequential(DQN_Conv(128+n_actions, 128, 3, 1, 1, norm=False, init=init_xavier, act=self.act),\n",
    "                                        DQN_Conv(128, 128, 3, 1, 1, norm=False, init=init_xavier, act=self.act))\n",
    "\n",
    "        # Single layer dense that maps hiddens into the output dim according to:\n",
    "        # 1. https://arxiv.org/pdf/1707.06887.pdf -- Distributional Reinforcement Learning\n",
    "        # 2. https://arxiv.org/pdf/1511.06581.pdf -- Dueling DQN\n",
    "        self.a = MLP(hiddens, out_hiddens=n_actions*num_buckets, layers=1, in_act=self.act, last_init=init_xavier)\n",
    "        self.v = MLP(hiddens, out_hiddens=num_buckets, layers=1, in_act=self.act, last_init=init_xavier)\n",
    "    \n",
    "        params_count(self, 'DQN')\n",
    "    \n",
    "    def forward(self, X, y_action):\n",
    "        X, z = self.encode(X)\n",
    "        \n",
    "        \n",
    "        q, action = self.q_head(X)\n",
    "        z_pred = self.get_transition(z, y_action)\n",
    "\n",
    "        return q, action, X[:,1:].clone().detach(), z_pred\n",
    "    \n",
    "\n",
    "    def env_step(self, X):\n",
    "        with torch.no_grad():\n",
    "            X, _ = self.encode(X)\n",
    "            _, action = self.q_head(X)\n",
    "            \n",
    "            return action.detach()\n",
    "    \n",
    "\n",
    "    def encode(self, X):\n",
    "        batch, seq = X.shape[:2]\n",
    "        self.batch = batch\n",
    "        self.seq = seq\n",
    "        X = self.encoder_cnn(X.contiguous().view(self.batch*self.seq, *(X.shape[2:])))\n",
    "        X = renormalize(X).contiguous().view(self.batch, self.seq, *X.shape[-3:])\n",
    "        X = X.contiguous().view(self.batch, self.seq, *X.shape[-3:])\n",
    "        z = X.clone()\n",
    "        X = X.flatten(-3,-1)\n",
    "        X = self.projection(X)\n",
    "        return X, z\n",
    "\n",
    "    def get_transition(self, z, action):\n",
    "        z = z.contiguous().view(-1, *z.shape[-3:])\n",
    "        \n",
    "        action = F.one_hot(action.clone(), n_actions).view(-1, n_actions)\n",
    "        action = action.view(-1, 5, n_actions, 1, 1).expand(-1, 5, n_actions, *z.shape[-2:])\n",
    "\n",
    "        \n",
    "        z_pred = torch.cat( (z, action[:,0]), 1)\n",
    "        z_pred = self.transition(z_pred)\n",
    "        z_pred = renormalize(z_pred)\n",
    "        \n",
    "        z_preds=[z_pred.clone()]\n",
    "        \n",
    "\n",
    "        for k in range(4):\n",
    "            z_pred = torch.cat( (z_pred, action[:,k+1]), 1)\n",
    "            z_pred = self.transition(z_pred)\n",
    "            z_pred = renormalize(z_pred)\n",
    "            \n",
    "            z_preds.append(z_pred)\n",
    "        \n",
    "        \n",
    "        z_pred = torch.stack(z_preds,1)\n",
    "\n",
    "        z_pred = self.projection(z_pred.flatten(-3,-1)).view(self.batch,5,-1)\n",
    "        z_pred = self.prediction(z_pred)\n",
    "        \n",
    "        return z_pred\n",
    "\n",
    "    \n",
    "    def q_head(self, X):\n",
    "        q = self.dueling_dqn(X)\n",
    "        action = (q*self.support).sum(-1).argmax(-1)\n",
    "        \n",
    "        return q, action\n",
    "\n",
    "    def get_max_action(self, X):\n",
    "        with torch.no_grad():\n",
    "            X, _ = self.encode(X)\n",
    "            q = self.dueling_dqn(X)\n",
    "            \n",
    "            action = (q*self.support).sum(-1).argmax(-1)\n",
    "            return action\n",
    "\n",
    "    def evaluate(self, X, action):\n",
    "        with torch.no_grad():\n",
    "            X, _ = self.encode(X)\n",
    "            \n",
    "            q = self.dueling_dqn(X)\n",
    "            \n",
    "            action = action[:,:,None,None].expand_as(q)[:,:,0][:,:,None]\n",
    "            q = q.gather(-2,action)\n",
    "            \n",
    "            return q\n",
    "\n",
    "    def dueling_dqn(self, X):\n",
    "        X = F.relu(X)\n",
    "        \n",
    "        a = self.a(X).view(self.batch, -1, n_actions, num_buckets)\n",
    "        v = self.v(X).view(self.batch, -1, 1, num_buckets)\n",
    "        \n",
    "        q = v + a - a.mean(-2,keepdim=True)\n",
    "        q = F.softmax(q,-1)\n",
    "        \n",
    "        return q\n",
    "    \n",
    "    def network_ema(self, rand_network, target_network, alpha=0.5):\n",
    "        for param, param_target in zip(rand_network.parameters(), target_network.parameters()):\n",
    "            param_target.data = alpha * param_target.data + (1 - alpha) * param.data.clone()\n",
    "\n",
    "    def hard_reset(self, random_model, alpha=0.5):\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            self.network_ema(random_model.encoder_cnn, self.encoder_cnn, alpha)\n",
    "            self.network_ema(random_model.transition, self.transition, alpha)\n",
    "\n",
    "            self.network_ema(random_model.projection, self.projection, 0)\n",
    "            self.network_ema(random_model.prediction, self.prediction, 0)\n",
    "\n",
    "            self.network_ema(random_model.a, self.a, 0)\n",
    "            self.network_ema(random_model.v, self.v, 0)\n",
    "\n",
    "\n",
    "\n",
    "def copy_states(source, target):\n",
    "    for key, _ in zip(source.state_dict()['state'].keys(), target.state_dict()['state'].keys()):\n",
    "\n",
    "        target.state_dict()['state'][key]['exp_avg_sq'] = copy.deepcopy(source.state_dict()['state'][key]['exp_avg_sq'])\n",
    "        target.state_dict()['state'][key]['exp_avg'] = copy.deepcopy(source.state_dict()['state'][key]['exp_avg'])\n",
    "        target.state_dict()['state'][key]['step'] = copy.deepcopy(source.state_dict()['state'][key]['step'])\n",
    "        \n",
    "def target_model_ema(model, model_target):\n",
    "    with torch.no_grad():\n",
    "        for param, param_target in zip(model.parameters(), model_target.parameters()):\n",
    "            param_target.data = critic_ema_decay * param_target.data + (1.0 - critic_ema_decay) * param.data.clone()\n",
    "\n",
    "\n",
    "    \n",
    "model=DQN(n_actions).cuda()\n",
    "model_target=DQN(n_actions).cuda()\n",
    "\n",
    "model_target.load_state_dict(model.state_dict())\n",
    "\n",
    "\n",
    "# Testing only\n",
    "#with torch.no_grad():\n",
    "#    q, action, X, z_pred = model(torch.randn(4,1,12,96,72, device='cuda', dtype=torch.float), torch.randint(0,n_actions,(4,5),device='cuda').long())\n",
    "#z = model.encode(torch.randn(4,5,12,96,72, device='cuda'))[0]\n",
    "\n",
    "# I believe the authors have actually miscalculated the params count on the paper.\n",
    "# My training time is lower than theirs while having more parameters, and the same architecture is used as is their original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ca1d0e5-d128-428b-bcbc-be68dccc005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "perception_modules=[model.encoder_cnn, model.transition]\n",
    "actor_modules=[model.prediction, model.projection, model.a, model.v]\n",
    "\n",
    "params_wm=[]\n",
    "for module in perception_modules:\n",
    "    for param in module.parameters():\n",
    "        if param.requires_grad==True: # They all require grad\n",
    "            params_wm.append(param)\n",
    "\n",
    "params_ac=[]\n",
    "for module in actor_modules:\n",
    "    for param in module.parameters():\n",
    "        if param.requires_grad==True:\n",
    "            params_ac.append(param)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(chain(params_wm, params_ac),\n",
    "                                lr=lr, weight_decay=0.1, eps=1.5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7f2a7d7-81c6-4c93-8cbe-1f15fa75af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "                         transforms.Resize((96,72)),\n",
    "                        ])\n",
    "\n",
    "\n",
    "def preprocess(state):\n",
    "    state=torch.tensor(state, dtype=torch.float, device='cuda') / 255\n",
    "    state=train_tfms(state.permute(0,3,1,2))\n",
    "    return state\n",
    "\n",
    "# https://github.com/google/dopamine/blob/master/dopamine/jax/agents/dqn/dqn_agent.py\n",
    "def linearly_decaying_epsilon(decay_period, step, warmup_steps, epsilon):\n",
    "    steps_left = decay_period + warmup_steps - step\n",
    "    bonus = (1.0 - epsilon) * steps_left / decay_period\n",
    "    bonus = np.clip(bonus, 0., 1. - epsilon)\n",
    "    return epsilon + bonus\n",
    "\n",
    "\n",
    "def epsilon_greedy(Q_action, step, final_eps=0, num_envs=1):\n",
    "    epsilon = linearly_decaying_epsilon(2001, step, 2000, final_eps)\n",
    "    \n",
    "    if random.random() < epsilon:\n",
    "        action = torch.randint(0, n_actions, (num_envs,), dtype=torch.int64, device='cuda').squeeze(0)\n",
    "    else:\n",
    "        action = Q_action.view(num_envs).squeeze(0).to(torch.int64)\n",
    "    return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6722829c-d4bc-4d9f-aa35-80f6133a4819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/google/dopamine/blob/master/dopamine/jax/agents/rainbow/rainbow_agent.py\n",
    "def project_distribution(supports, weights, target_support):\n",
    "    with torch.no_grad():\n",
    "        v_min, v_max = target_support[0], target_support[-1]\n",
    "        # `N` in Eq7.\n",
    "        num_dims = target_support.shape[-1]\n",
    "        # delta_z = `\\Delta z` in Eq7.\n",
    "        delta_z = (v_max - v_min) / (num_buckets-1)\n",
    "        # clipped_support = `[\\hat{T}_{z_j}]^{V_max}_{V_min}` in Eq7.\n",
    "        clipped_support = supports.clip(v_min, v_max)\n",
    "        # numerator = `|clipped_support - z_i|` in Eq7.\n",
    "        numerator = (clipped_support[:,None] - target_support[None,:,None].repeat_interleave(clipped_support.shape[0],0)).abs()\n",
    "        quotient = 1 - (numerator / delta_z)\n",
    "        # clipped_quotient = `[1 - numerator / (\\Delta z)]_0^1` in Eq7.\n",
    "        clipped_quotient = quotient.clip(0, 1)\n",
    "        # inner_prod = `\\sum_{j=0}^{N-1} clipped_quotient * p_j(x', \\pi(x'))` in Eq7.\n",
    "        inner_prod = (clipped_quotient * weights[:,None]).sum(-1)\n",
    "        #inner_prod = (clipped_quotient).sum(-1) * weights\n",
    "        return inner_prod.squeeze()\n",
    "\n",
    "\n",
    "mse = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "def optimize(step, grad_step, n):\n",
    "        \n",
    "    model.train()\n",
    "    model_target.train()\n",
    "\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.bfloat16, enabled=False):\n",
    "        with torch.no_grad():\n",
    "            states, next_states, rewards, action, c_flag, idxs, is_w = memory.sample(n, batch_size, grad_step)\n",
    "        terminal=1-c_flag\n",
    "        #print(f\"STUFF HERE {states.shape, rewards.shape, c_flag.shape, action.shape, n}\")\n",
    "    \n",
    "    \n",
    "        q, max_action, _, z_pred = model(states[:,0][:,None], action[:,:5].long())\n",
    "        z = model_target.encode(states[:,1:6])[0].detach()\n",
    "\n",
    "        \n",
    "        max_action  = model.get_max_action(next_states[:,n][:,None])\n",
    "        next_values = model_target.evaluate(next_states[:,n][:,None].contiguous(), max_action)\n",
    "        \n",
    "\n",
    "        action = action[:,0,None].expand(batch_size,num_buckets)\n",
    "        action=action[:,None]\n",
    "        with torch.no_grad():\n",
    "            gammas_one=torch.ones(batch_size,n,1,dtype=torch.float,device='cuda')\n",
    "            gamma_step = 1-torch.tensor(( (schedule_max_step - min(grad_step, schedule_max_step)) / schedule_max_step) * (initial_gamma-final_gamma) + final_gamma).exp()\n",
    "            gammas=gammas_one*gamma_step\n",
    "\n",
    "            \n",
    "            returns = []\n",
    "            for t in range(n):\n",
    "                ret = 0\n",
    "                for u in reversed(range(t, n)):\n",
    "                    ret += torch.prod(c_flag[:,t+1:u+1],-2)*torch.prod(gammas[:,t:u],-2)*rewards[:,u+1]\n",
    "                returns.append(ret)\n",
    "            returns = torch.stack(returns,1)\n",
    "        \n",
    "        plot_vs = returns.clone().sum(-1)\n",
    "        \n",
    "        same_traj = (torch.prod(c_flag[:,:n],-2)).squeeze()\n",
    "        \n",
    "        returns = returns[:,0]\n",
    "        returns = returns + torch.prod(gammas[0,:10],-2).squeeze()*same_traj[:,None]*model.support[None,:]\n",
    "        returns = returns.squeeze()\n",
    "        \n",
    "        next_values = next_values[:,0]\n",
    "\n",
    "        log_probs = torch.log(q[:,0].gather(-2, action)[:,None] + eps).contiguous()\n",
    "        \n",
    "        \n",
    "        dist = project_distribution(returns, next_values.squeeze(), model.support)\n",
    "        \n",
    "        loss = -(dist*(log_probs.squeeze())).sum(-1).view(batch_size,-1).sum(-1)\n",
    "        dqn_loss = loss.clone().mean()\n",
    "        td_error = (loss + torch.nan_to_num((dist*torch.log(dist))).sum(-1)).mean()\n",
    "\n",
    "        \n",
    "        batched_loss = loss.clone()\n",
    "        \n",
    "        \n",
    "        z = F.normalize(z, 2, dim=-1, eps=1e-5)\n",
    "        z_pred = F.normalize(z_pred, 2, dim=-1, eps=1e-5)\n",
    "\n",
    "        \n",
    "        recon_loss = (mse(z_pred.contiguous().view(-1,2048), z.contiguous().view(-1,2048))).sum(-1)\n",
    "        recon_loss = 5*(recon_loss.view(batch_size, -1).mean(-1))*same_traj\n",
    "        \n",
    "        \n",
    "        loss += recon_loss\n",
    "        \n",
    "        loss = (loss*is_w).mean() # mean across batch axis\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    param_norm, grad_norm = params_and_grad_norm(model)\n",
    "    #scaler.scale(loss).backward()\n",
    "    #scaler.unscale_(optimizer)\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "    #scaler.step(optimizer)\n",
    "    #scaler.update()\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #memory.set_priority(idxs, batched_loss)\n",
    "    memory.set_priority(idxs, batched_loss, same_traj)\n",
    "    \n",
    "    \n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    wandb.log({'loss': loss, 'dqn_loss': dqn_loss, 'recon_loss': recon_loss.mean(), 'lr': lr, 'returns': plot_vs.mean(),\n",
    "               'rewards': rewards.mean(0).sum(), 'is_w': is_w.mean(),\n",
    "               'gamma': gamma_step, 'td_error': td_error, 'param_norm': param_norm.sum(), 'grad_norm': grad_norm.sum()})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scores=[]\n",
    "memory.free()\n",
    "step=0\n",
    "#model.share_memory()\n",
    "grad_step=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05991348-a11a-43bd-882f-02df107fc543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2000/100000 [00:17<14:10, 115.20it/s]C:\\Users\\sneep\\AppData\\Local\\Temp\\ipykernel_21068\\1051792225.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gamma_step = 1-torch.tensor(( (schedule_max_step - min(grad_step, schedule_max_step)) / schedule_max_step) * (initial_gamma-final_gamma) + final_gamma).exp()\n",
      " 22%|██▏       | 22002/100000 [1:00:41<4:03:17,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting on step 22001 40002\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 36.37M\n",
      "IMPALA ResNet Parameters: 1.56M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22003/100000 [1:01:00<122:10:27,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Parameters: 36.37M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42003/100000 [2:04:51<3:11:08,  5.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting on step 42002 40002\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 36.37M\n",
      "IMPALA ResNet Parameters: 1.56M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42004/100000 [2:05:09<92:49:42,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Parameters: 36.37M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62004/100000 [3:14:59<2:15:20,  4.68it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting on step 62003 40002\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 36.37M\n",
      "IMPALA ResNet Parameters: 1.56M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62005/100000 [3:15:21<71:36:09,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Parameters: 36.37M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81200/100000 [4:29:27<1:13:16,  4.28it/s] "
     ]
    }
   ],
   "source": [
    "step=0\n",
    "\n",
    "progress_bar = tqdm.tqdm(total=total_steps)\n",
    "\n",
    "while step<(10):\n",
    "    state, info = env.reset()\n",
    "    state = preprocess(state)\n",
    "\n",
    "    stacked = state.repeat_interleave(3,1)\n",
    "    state = torch.cat((stacked.clone(), state),1)\n",
    "    \n",
    "    \n",
    "    eps_reward=torch.tensor([0], dtype=torch.float)\n",
    "    \n",
    "    reward=np.array([0])\n",
    "    done_flag=np.array([False])\n",
    "    terminated=np.array([False])\n",
    "\n",
    "    last_lives=np.array([0])\n",
    "    life_loss=np.array([0])\n",
    "    \n",
    "    last_grad_update=0\n",
    "    while step<(total_steps):\n",
    "        progress_bar.update(1)\n",
    "        model_target.train()\n",
    "        \n",
    "        len_memory = len(memory)\n",
    "        Q_action = model_target.env_step(state.unsqueeze(0))\n",
    "        \n",
    "        action = epsilon_greedy(Q_action, len_memory).cpu()\n",
    "        \n",
    "        memory.push(state.detach().cpu(), reward, action, np.logical_or(done_flag, life_loss))\n",
    "        #print('action', action, action.shape)\n",
    "        \n",
    "        state, reward, terminated, truncated, info = env.step([action.numpy()])\n",
    "        \n",
    "        state = preprocess(state)\n",
    "        eps_reward+=reward\n",
    "        reward = reward.clip(-1, 1)\n",
    "\n",
    "        state = torch.cat((stacked.clone(), state),1)\n",
    "        stacked = torch.cat((stacked[:,3:], state[:,-3:]),1)\n",
    "\n",
    "        \n",
    "        done_flag = np.logical_or(terminated, truncated)\n",
    "        lives = info['lives']\n",
    "        life_loss = (last_lives-lives).clip(min=0)\n",
    "        last_lives = lives\n",
    "\n",
    "        \n",
    "        n = int(initial_n * (final_n/initial_n)**(min(grad_step,schedule_max_step) / schedule_max_step))\n",
    "        n = np.array(n).item()\n",
    "        \n",
    "        memory.priority[len_memory] = memory.max_priority()\n",
    "        \n",
    "\n",
    "        if len_memory>2000:\n",
    "            for i in range(2):\n",
    "                optimize(step, grad_step, n)\n",
    "                target_model_ema(model, model_target)\n",
    "                grad_step+=1\n",
    "\n",
    "        \n",
    "        if ((step+1)%10000)==0:\n",
    "            save_checkpoint(model, model_target, optimizer, step,\n",
    "                            'checkpoints/atari_last.pth')\n",
    "        \n",
    "            \n",
    "        \n",
    "        if grad_step>reset_every:\n",
    "            #eval()\n",
    "            print('Reseting on step', step, grad_step)\n",
    "            \n",
    "            seed_np_torch(random.randint(SEED-1000, SEED+1000))\n",
    "            random_model = DQN(n_actions).cuda()\n",
    "            model.hard_reset(random_model)\n",
    "            \n",
    "            seed_np_torch(random.randint(SEED-1000, SEED+1000))\n",
    "            random_model = DQN(n_actions).cuda()\n",
    "            model_target.hard_reset(random_model)\n",
    "            seed_np_torch(SEED)\n",
    "            \n",
    "            random_model=None\n",
    "            grad_step=0\n",
    "\n",
    "            actor_modules=[model.prediction, model.projection, model.a, model.v]\n",
    "            params_ac=[]\n",
    "            for module in actor_modules:\n",
    "                for param in module.parameters():\n",
    "                    params_ac.append(param)\n",
    "                    \n",
    "\n",
    "            perception_modules=[model.encoder_cnn, model.transition]\n",
    "            params_wm=[]\n",
    "            for module in perception_modules:\n",
    "                for param in module.parameters():\n",
    "                    params_wm.append(param)\n",
    "            \n",
    "            optimizer_aux = torch.optim.AdamW(params_wm, lr=lr, weight_decay=0.1, eps=1.5e-4)\n",
    "            copy_states(optimizer, optimizer_aux)\n",
    "            optimizer = torch.optim.AdamW(chain(params_wm, params_ac),\n",
    "                                lr=lr, weight_decay=0.1, eps=1.5e-4)\n",
    "            copy_states(optimizer_aux, optimizer)\n",
    "            \n",
    "        \n",
    "        \n",
    "        step+=1\n",
    "        \n",
    "        log_t = done_flag.astype(float).nonzero()[0]\n",
    "        \n",
    "        if len(log_t)>0:\n",
    "            for log in log_t:\n",
    "                wandb.log({'eps_reward': eps_reward[log].sum()})\n",
    "                scores.append(eps_reward[log].clone())\n",
    "            eps_reward[log_t]=0\n",
    "\n",
    "save_checkpoint(model, model_target, optimizer, step, f'checkpoints/{env_name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87344597-e733-451c-8a5f-2a00b5511061",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_to_eval=True\n",
    "\n",
    "if load_to_eval:\n",
    "    model.load_state_dict(torch.load(f'checkpoints/{env_name}.pth')['model_state_dict'])\n",
    "    model_target.load_state_dict(torch.load(f'checkpoints/{env_name}.pth')['model_target_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12d36218-ab48-42d9-a7ba-fabb66cc758f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init state torch.Size([1, 3, 96, 72])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [21:33<00:00, 12.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Mean 30610.0\n",
      "Inter Quantile Mean 29620.0\n",
      "Inter Quantile STD 1441.2296337304674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_envs=1\n",
    "\n",
    "#env = gym.vector.make(f\"{env_name}NoFrameskip-v4\", num_envs=num_envs, render_mode='human')\n",
    "env = gym.vector.make(f\"{env_name}NoFrameskip-v4\", num_envs=num_envs)\n",
    "env = MaxLast2FrameSkipWrapper(env,seed=SEED)\n",
    "\n",
    "def eval_phase(eval_runs=50, max_eval_steps=27000, num_envs=1):\n",
    "    progress_bar = tqdm.tqdm(total=eval_runs)\n",
    "    \n",
    "    scores=[]\n",
    "    \n",
    "    state, info = env.reset()\n",
    "    state = preprocess(state)\n",
    "    print(f\"init state {state.shape}\")\n",
    "    stacked = state.repeat_interleave(3,1)\n",
    "    state = torch.cat((stacked.clone(), state),1)\n",
    "    \n",
    "    \n",
    "    eps_reward=torch.tensor([0]*num_envs, dtype=torch.float)\n",
    "    \n",
    "    reward=np.array([0]*num_envs)\n",
    "    terminated=np.array([False]*num_envs)\n",
    "\n",
    "    last_lives=np.array([0]*num_envs)\n",
    "\n",
    "    finished_envs=np.array([False]*num_envs)\n",
    "    done_flag=0\n",
    "    last_grad_update=0\n",
    "    eval_run=0\n",
    "    step=np.array([0]*num_envs)\n",
    "    while eval_run<eval_runs:\n",
    "        #seed_np_torch(SEED+eval_run)\n",
    "        env.seed=SEED+eval_run\n",
    "        model_target.train()\n",
    "        \n",
    "        \n",
    "        Q_action = model_target.env_step(state.unsqueeze(0))\n",
    "        action = epsilon_greedy(Q_action.squeeze(), 5000, 0.0005, num_envs).cpu()\n",
    "        \n",
    "        state, reward, terminated, truncated, info = env.step([action.numpy()] if num_envs==1 else action.numpy())\n",
    "        done_flag = np.logical_or(terminated, truncated)\n",
    "        \n",
    "\n",
    "        state = preprocess(state)\n",
    "        eps_reward+=reward\n",
    "\n",
    "\n",
    "        \n",
    "        state = torch.cat((stacked.clone(), state),1)\n",
    "        stacked = torch.cat((stacked[:,3:], state[:,-3:]),1)\n",
    "        \n",
    "        \n",
    "        step+=1\n",
    "        \n",
    "        log_t = done_flag.astype(float).nonzero()[0]\n",
    "        if len(log_t)>0:# or (step>max_eval_steps).any():\n",
    "            progress_bar.update(1)\n",
    "            for log in log_t:\n",
    "                #wandb.log({'eval_eps_reward': eps_reward[log].sum()})\n",
    "                if finished_envs[log]==False:\n",
    "                    scores.append(eps_reward[log].clone())\n",
    "                    eval_run+=1\n",
    "                    #finished_envs[log]=True\n",
    "                step[log]=0\n",
    "                \n",
    "            eps_reward[log_t]=0            \n",
    "            for i, log in enumerate(step>max_eval_steps):\n",
    "                if log==True and finished_envs[i]==False:\n",
    "                    scores.append(eps_reward[i].clone())\n",
    "                    step[i]=0\n",
    "                    eval_run+=1\n",
    "                    eps_reward[i]=0\n",
    "                    #finished_envs[i]=True\n",
    "            \n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "def eval(eval_runs=50, max_eval_steps=27000, num_envs=1):\n",
    "    assert num_envs==1, 'The code for num eval envs > 1 is messed up.'\n",
    "    \n",
    "    scores = eval_phase(eval_runs, max_eval_steps, num_envs)    \n",
    "    scores = torch.stack(scores)\n",
    "    scores, _ = scores.sort()\n",
    "    \n",
    "    _25th = eval_runs//4\n",
    "\n",
    "    iq = scores[_25th:-_25th]\n",
    "    iqm = iq.mean()\n",
    "    iqs = iq.std()\n",
    "\n",
    "    print(f\"Scores Mean {scores.mean()}\")\n",
    "    print(f\"Inter Quantile Mean {iqm}\")\n",
    "    print(f\"Inter Quantile STD {iqs}\")\n",
    "\n",
    "    \n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.plot(scores)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "scores = eval(eval_runs=100, num_envs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cddb4f-7fdd-4b4b-8e62-33d92f4313df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cefa2a-c6d7-4a51-8cdd-e22d14355750",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
