{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57cb10b8-6556-487a-80d5-7f5b165b996a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\diffusers\\utils\\outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msnykralafk\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\sneep\\Python\\bbf\\wandb\\run-20240301_173306-wsqiwyau</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/snykralafk/Atari-100k-BBF/runs/wsqiwyau' target=\"_blank\">BBF-Hero</a></strong> to <a href='https://wandb.ai/snykralafk/Atari-100k-BBF' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/snykralafk/Atari-100k-BBF' target=\"_blank\">https://wandb.ai/snykralafk/Atari-100k-BBF</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/snykralafk/Atari-100k-BBF/runs/wsqiwyau' target=\"_blank\">https://wandb.ai/snykralafk/Atari-100k-BBF/runs/wsqiwyau</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count, chain\n",
    "import tqdm\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "\n",
    "from nosaveddata.nsd_utils.networks import params_count, params_and_grad_norm, seed_np_torch\n",
    "from nosaveddata.nsd_utils.einstein import Rearrange\n",
    "\n",
    "from nosaveddata.builders.mlp import *\n",
    "from nosaveddata.builders.weight_init import *\n",
    "from nosaveddata.builders.resnet import IMPALA_Resnet, DQN_Conv\n",
    "\n",
    "\n",
    "from utils.experience_replay import *\n",
    "\n",
    "\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "import wandb\n",
    "\n",
    "\n",
    "# Environment configuration\n",
    "env_name = 'Jamesbond'\n",
    "SEED = 8052\n",
    "\n",
    "\n",
    "wandb.init(\n",
    "    project=\"Atari-100k-BBF\",\n",
    "    name=f\"BBF-{env_name}\",\n",
    "\n",
    "    #id='rotdmtc5',\n",
    "    #resume='must',\n",
    "\n",
    "    config={\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"architecture\": \"BBF\",\n",
    "        \"dataset\": \"Assault\",\n",
    "        \"epochs\": 100,\n",
    "    },\n",
    "\n",
    "    reinit=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Optimization\n",
    "batch_size = 32\n",
    "lr=1e-4\n",
    "\n",
    "eps=1e-8\n",
    "\n",
    "\n",
    "# Target network EMA rate\n",
    "critic_ema_decay=0.995\n",
    "\n",
    "\n",
    "# Return function\n",
    "initial_gamma=torch.tensor(1-0.97).log()\n",
    "final_gamma=torch.tensor(1-0.997).log()\n",
    "\n",
    "initial_n = 10\n",
    "final_n = 3\n",
    "\n",
    "num_buckets=51\n",
    "\n",
    "\n",
    "# Reset Schedule and Buffer\n",
    "reset_every=40000 # grad steps, not steps.\n",
    "schedule_max_step=reset_every//4\n",
    "total_steps=100000\n",
    "\n",
    "prefetch_cap=1 # actually, no prefetch is being done\n",
    "\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'reward', 'action', 'c_flag'))\n",
    "memory = PrioritizedReplay_nSteps_Sqrt(100005, total_steps=schedule_max_step, prefetch_cap=prefetch_cap)\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint(net, model_target, optimizer, step, path):\n",
    "    torch.save({\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'model_target_state_dict': model_target.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'step': step,\n",
    "            }, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c831907e-0868-4915-bc34-3d1dd1fe363c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\gymnasium\\vector\\__init__.py:53: UserWarning: \u001b[33mWARN: `gymnasium.vector.make(...)` is deprecated and will be replaced by `gymnasium.make_vec(...)` in v1.0\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/weipu-zhang/STORM/blob/main/env_wrapper.py\n",
    "class MaxLast2FrameSkipWrapper(gym.Wrapper):\n",
    "    def __init__(self, env, skip=4, seed=0):\n",
    "        super().__init__(env)\n",
    "        self.seed = seed\n",
    "        self.skip = skip\n",
    "        self.env.action_space.seed(seed)\n",
    "        \n",
    "    def reset(self, **kwargs):\n",
    "        kwargs[\"seed\"] = self.seed\n",
    "        obs, _ = self.env.reset(**kwargs)\n",
    "        return obs, _\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0\n",
    "        self.obs_buffer = deque(maxlen=2)\n",
    "        for _ in range(self.skip):\n",
    "            obs, reward, done, truncated, info = self.env.step(action)\n",
    "            self.obs_buffer.append(obs)\n",
    "            total_reward += reward\n",
    "\n",
    "            terminated = np.logical_or(done, truncated)\n",
    "            #if terminated.any():\n",
    "            #    for i in range(len(terminated)):\n",
    "            #       obs[i] = self.reset()[0][i]\n",
    "            if done or truncated:\n",
    "                break\n",
    "        if len(self.obs_buffer) == 1:\n",
    "            obs = self.obs_buffer[0]\n",
    "        else:\n",
    "            obs = np.max(np.stack(self.obs_buffer), axis=0)\n",
    "        return obs, total_reward, done, truncated, info\n",
    "        # Life loss is calculated on the training code\n",
    "\n",
    "env = gym.vector.make(f\"{env_name}NoFrameskip-v4\", num_envs=1)\n",
    "env = MaxLast2FrameSkipWrapper(env,seed=SEED)\n",
    "\n",
    "\n",
    "#n_actions = env.action_space.n\n",
    "n_actions = env.action_space[0].n\n",
    "\n",
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "seed_np_torch(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8d429f2-aee0-4c6b-b221-d2a8b09b0e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 36.37M\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 36.37M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def renormalize(tensor, has_batch=False):\n",
    "    shape = tensor.shape\n",
    "    tensor = tensor.view(tensor.shape[0], -1)\n",
    "    max_value,_ = torch.max(tensor, -1, keepdim=True)\n",
    "    min_value,_ = torch.min(tensor, -1, keepdim=True)\n",
    "    return ((tensor - min_value) / (max_value - min_value + 1e-5)).view(shape)\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, n_actions, hiddens=2048, mlp_layers=1, scale_width=4,\n",
    "                 n_atoms=51, Vmin=-10, Vmax=10):\n",
    "        super().__init__()\n",
    "        self.support = torch.linspace(Vmin, Vmax, n_atoms).cuda()\n",
    "        \n",
    "        self.hiddens=hiddens\n",
    "        self.scale_width=scale_width\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "        \n",
    "        self.encoder_cnn = IMPALA_Resnet(scale_width=scale_width, norm=False, init=init_xavier, act=self.act)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Single layer dense that maps the flattened encoded representation into hiddens.\n",
    "        self.projection = MLP(13824, med_hiddens=hiddens, out_hiddens=hiddens,\n",
    "                              last_init=init_xavier, layers=1)\n",
    "        self.prediction = MLP(hiddens, out_hiddens=hiddens, layers=1, last_init=init_xavier)\n",
    "                                              \n",
    "        self.transition = nn.Sequential(DQN_Conv(128+n_actions, 128, 3, 1, 1, norm=False, init=init_xavier, act=self.act),\n",
    "                                        DQN_Conv(128, 128, 3, 1, 1, norm=False, init=init_xavier, act=self.act))\n",
    "\n",
    "        # Single layer dense that maps hiddens into the output dim according to:\n",
    "        # 1. https://arxiv.org/pdf/1707.06887.pdf -- Distributional Reinforcement Learning\n",
    "        # 2. https://arxiv.org/pdf/1511.06581.pdf -- Dueling DQN\n",
    "        self.a = MLP(hiddens, out_hiddens=n_actions*num_buckets, layers=1, in_act=self.act, last_init=init_xavier)\n",
    "        self.v = MLP(hiddens, out_hiddens=num_buckets, layers=1, in_act=self.act, last_init=init_xavier)\n",
    "    \n",
    "        params_count(self, 'DQN')\n",
    "    \n",
    "    def forward(self, X, y_action):\n",
    "        X, z = self.encode(X)\n",
    "        \n",
    "        \n",
    "        q, action = self.q_head(X)\n",
    "        z_pred = self.get_transition(z, y_action)\n",
    "\n",
    "        return q, action, X[:,1:].clone().detach(), z_pred\n",
    "    \n",
    "\n",
    "    def env_step(self, X):\n",
    "        with torch.no_grad():\n",
    "            X, _ = self.encode(X)\n",
    "            _, action = self.q_head(X)\n",
    "            \n",
    "            return action.detach()\n",
    "    \n",
    "\n",
    "    def encode(self, X):\n",
    "        batch, seq = X.shape[:2]\n",
    "        self.batch = batch\n",
    "        self.seq = seq\n",
    "        X = self.encoder_cnn(X.contiguous().view(self.batch*self.seq, *(X.shape[2:])))\n",
    "        X = renormalize(X).contiguous().view(self.batch, self.seq, *X.shape[-3:])\n",
    "        X = X.contiguous().view(self.batch, self.seq, *X.shape[-3:])\n",
    "        z = X.clone()\n",
    "        X = X.flatten(-3,-1)\n",
    "        X = self.projection(X)\n",
    "        return X, z\n",
    "\n",
    "    def get_transition(self, z, action):\n",
    "        z = z.contiguous().view(-1, *z.shape[-3:])\n",
    "        \n",
    "        action = F.one_hot(action.clone(), n_actions).view(-1, n_actions)\n",
    "        action = action.view(-1, 5, n_actions, 1, 1).expand(-1, 5, n_actions, *z.shape[-2:])\n",
    "\n",
    "        \n",
    "        z_pred = torch.cat( (z, action[:,0]), 1)\n",
    "        z_pred = self.transition(z_pred)\n",
    "        z_pred = renormalize(z_pred)\n",
    "        \n",
    "        z_preds=[z_pred.clone()]\n",
    "        \n",
    "\n",
    "        for k in range(4):\n",
    "            z_pred = torch.cat( (z_pred, action[:,k+1]), 1)\n",
    "            z_pred = self.transition(z_pred)\n",
    "            z_pred = renormalize(z_pred)\n",
    "            \n",
    "            z_preds.append(z_pred)\n",
    "        \n",
    "        \n",
    "        z_pred = torch.stack(z_preds,1)\n",
    "\n",
    "        z_pred = self.projection(z_pred.flatten(-3,-1)).view(self.batch,5,-1)\n",
    "        z_pred = self.prediction(z_pred)\n",
    "        \n",
    "        return z_pred\n",
    "\n",
    "    \n",
    "    def q_head(self, X):\n",
    "        q = self.dueling_dqn(X)\n",
    "        action = (q*self.support).sum(-1).argmax(-1)\n",
    "        \n",
    "        return q, action\n",
    "\n",
    "    def get_max_action(self, X):\n",
    "        with torch.no_grad():\n",
    "            X, _ = self.encode(X)\n",
    "            q = self.dueling_dqn(X)\n",
    "            \n",
    "            action = (q*self.support).sum(-1).argmax(-1)\n",
    "            return action\n",
    "\n",
    "    def evaluate(self, X, action):\n",
    "        with torch.no_grad():\n",
    "            X, _ = self.encode(X)\n",
    "            \n",
    "            q = self.dueling_dqn(X)\n",
    "            \n",
    "            action = action[:,:,None,None].expand_as(q)[:,:,0][:,:,None]\n",
    "            q = q.gather(-2,action)\n",
    "            \n",
    "            return q\n",
    "\n",
    "    def dueling_dqn(self, X):\n",
    "        X = F.relu(X)\n",
    "        \n",
    "        a = self.a(X).view(self.batch, -1, n_actions, num_buckets)\n",
    "        v = self.v(X).view(self.batch, -1, 1, num_buckets)\n",
    "        \n",
    "        q = v + a - a.mean(-2,keepdim=True)\n",
    "        q = F.softmax(q,-1)\n",
    "        \n",
    "        return q\n",
    "    \n",
    "    def network_ema(self, rand_network, target_network, alpha=0.5):\n",
    "        for param, param_target in zip(rand_network.parameters(), target_network.parameters()):\n",
    "            param_target.data = alpha * param_target.data + (1 - alpha) * param.data.clone()\n",
    "\n",
    "    def hard_reset(self, random_model, alpha=0.5):\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            self.network_ema(random_model.encoder_cnn, self.encoder_cnn, alpha)\n",
    "            self.network_ema(random_model.transition, self.transition, alpha)\n",
    "\n",
    "            self.network_ema(random_model.projection, self.projection, 0)\n",
    "            self.network_ema(random_model.prediction, self.prediction, 0)\n",
    "\n",
    "            self.network_ema(random_model.a, self.a, 0)\n",
    "            self.network_ema(random_model.v, self.v, 0)\n",
    "\n",
    "\n",
    "\n",
    "def copy_states(source, target):\n",
    "    for key, _ in zip(source.state_dict()['state'].keys(), target.state_dict()['state'].keys()):\n",
    "\n",
    "        target.state_dict()['state'][key]['exp_avg_sq'] = copy.deepcopy(source.state_dict()['state'][key]['exp_avg_sq'])\n",
    "        target.state_dict()['state'][key]['exp_avg'] = copy.deepcopy(source.state_dict()['state'][key]['exp_avg'])\n",
    "        target.state_dict()['state'][key]['step'] = copy.deepcopy(source.state_dict()['state'][key]['step'])\n",
    "        \n",
    "def target_model_ema(model, model_target):\n",
    "    with torch.no_grad():\n",
    "        for param, param_target in zip(model.parameters(), model_target.parameters()):\n",
    "            param_target.data = critic_ema_decay * param_target.data + (1.0 - critic_ema_decay) * param.data.clone()\n",
    "\n",
    "\n",
    "    \n",
    "model=DQN(n_actions).cuda()\n",
    "model_target=DQN(n_actions).cuda()\n",
    "\n",
    "model_target.load_state_dict(model.state_dict())\n",
    "\n",
    "\n",
    "# Testing only\n",
    "#with torch.no_grad():\n",
    "#    q, action, X, z_pred = model(torch.randn(4,1,12,96,72, device='cuda', dtype=torch.float), torch.randint(0,n_actions,(4,5),device='cuda').long())\n",
    "#z = model.encode(torch.randn(4,5,12,96,72, device='cuda'))[0]\n",
    "\n",
    "# I believe the authors have actually miscalculated the params count on the paper.\n",
    "# My training time is lower than theirs while having more parameters, and the same architecture is used as is their original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ca1d0e5-d128-428b-bcbc-be68dccc005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "perception_modules=[model.encoder_cnn, model.transition]\n",
    "actor_modules=[model.prediction, model.projection, model.a, model.v]\n",
    "\n",
    "params_wm=[]\n",
    "for module in perception_modules:\n",
    "    for param in module.parameters():\n",
    "        if param.requires_grad==True: # They all require grad\n",
    "            params_wm.append(param)\n",
    "\n",
    "params_ac=[]\n",
    "for module in actor_modules:\n",
    "    for param in module.parameters():\n",
    "        if param.requires_grad==True:\n",
    "            params_ac.append(param)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(chain(params_wm, params_ac),\n",
    "                                lr=lr, weight_decay=0.1, eps=1.5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7f2a7d7-81c6-4c93-8cbe-1f15fa75af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "                         transforms.Resize((96,72)),\n",
    "                        ])\n",
    "\n",
    "\n",
    "def preprocess(state):\n",
    "    state=torch.tensor(state, dtype=torch.float, device='cuda') / 255\n",
    "    state=train_tfms(state.permute(0,3,1,2))\n",
    "    return state\n",
    "\n",
    "# https://github.com/google/dopamine/blob/master/dopamine/jax/agents/dqn/dqn_agent.py\n",
    "def linearly_decaying_epsilon(decay_period, step, warmup_steps, epsilon):\n",
    "    steps_left = decay_period + warmup_steps - step\n",
    "    bonus = (1.0 - epsilon) * steps_left / decay_period\n",
    "    bonus = np.clip(bonus, 0., 1. - epsilon)\n",
    "    return epsilon + bonus\n",
    "\n",
    "\n",
    "def epsilon_greedy(Q_action, step, final_eps=0, num_envs=1):\n",
    "    epsilon = linearly_decaying_epsilon(2001, step, 2000, final_eps)\n",
    "    \n",
    "    if random.random() < epsilon:\n",
    "        action = torch.randint(0, n_actions, (num_envs,), dtype=torch.int64, device='cuda').squeeze(0)\n",
    "    else:\n",
    "        action = Q_action.view(num_envs).squeeze(0).to(torch.int64)\n",
    "    return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6722829c-d4bc-4d9f-aa35-80f6133a4819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/google/dopamine/blob/master/dopamine/jax/agents/rainbow/rainbow_agent.py\n",
    "def project_distribution(supports, weights, target_support):\n",
    "    with torch.no_grad():\n",
    "        v_min, v_max = target_support[0], target_support[-1]\n",
    "        # `N` in Eq7.\n",
    "        num_dims = target_support.shape[-1]\n",
    "        # delta_z = `\\Delta z` in Eq7.\n",
    "        delta_z = (v_max - v_min) / (num_buckets-1)\n",
    "        # clipped_support = `[\\hat{T}_{z_j}]^{V_max}_{V_min}` in Eq7.\n",
    "        clipped_support = supports.clip(v_min, v_max)\n",
    "        # numerator = `|clipped_support - z_i|` in Eq7.\n",
    "        numerator = (clipped_support[:,None] - target_support[None,:,None].repeat_interleave(clipped_support.shape[0],0)).abs()\n",
    "        quotient = 1 - (numerator / delta_z)\n",
    "        # clipped_quotient = `[1 - numerator / (\\Delta z)]_0^1` in Eq7.\n",
    "        clipped_quotient = quotient.clip(0, 1)\n",
    "        # inner_prod = `\\sum_{j=0}^{N-1} clipped_quotient * p_j(x', \\pi(x'))` in Eq7.\n",
    "        inner_prod = (clipped_quotient * weights[:,None]).sum(-1)\n",
    "        #inner_prod = (clipped_quotient).sum(-1) * weights\n",
    "        return inner_prod.squeeze()\n",
    "\n",
    "\n",
    "mse = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "def optimize(step, grad_step, n):\n",
    "        \n",
    "    model.train()\n",
    "    model_target.train()\n",
    "\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.bfloat16, enabled=False):\n",
    "        with torch.no_grad():\n",
    "            states, next_states, rewards, action, c_flag, idxs, is_w = memory.sample(n, batch_size, grad_step)\n",
    "        terminal=1-c_flag\n",
    "        #print(f\"STUFF HERE {states.shape, rewards.shape, c_flag.shape, action.shape, n}\")\n",
    "    \n",
    "    \n",
    "        q, max_action, _, z_pred = model(states[:,0][:,None], action[:,:5].long())\n",
    "        z = model_target.encode(states[:,1:6])[0].detach()\n",
    "\n",
    "        \n",
    "        max_action  = model.get_max_action(next_states[:,n-1][:,None])\n",
    "        next_values = model_target.evaluate(next_states[:,n-1][:,None].contiguous(), max_action)\n",
    "        \n",
    "\n",
    "        action = action[:,0,None].expand(batch_size,num_buckets)\n",
    "        action=action[:,None]\n",
    "        with torch.no_grad():\n",
    "            gammas_one=torch.ones(batch_size,n,1,dtype=torch.float,device='cuda')\n",
    "            gamma_step = 1-torch.tensor(( (schedule_max_step - min(grad_step, schedule_max_step)) / schedule_max_step) * (initial_gamma-final_gamma) + final_gamma).exp()\n",
    "            gammas=gammas_one*gamma_step\n",
    "\n",
    "            \n",
    "            returns = []\n",
    "            for t in range(n):\n",
    "                ret = 0\n",
    "                for u in reversed(range(t, n)):\n",
    "                    ret += torch.prod(c_flag[:,t+1:u+1],-2)*torch.prod(gammas[:,t:u],-2)*rewards[:,u+1]\n",
    "                returns.append(ret)\n",
    "            returns = torch.stack(returns,1)\n",
    "        \n",
    "        plot_vs = returns.clone().sum(-1)\n",
    "        \n",
    "        same_traj = (torch.prod(c_flag[:,:n],-2)).squeeze()\n",
    "        \n",
    "        returns = returns[:,0]\n",
    "        returns = returns + torch.prod(gammas[0,:10],-2).squeeze()*same_traj[:,None]*model.support[None,:]\n",
    "        returns = returns.squeeze()\n",
    "        \n",
    "        next_values = next_values[:,0]\n",
    "\n",
    "        log_probs = torch.log(q[:,0].gather(-2, action)[:,None] + eps).contiguous()\n",
    "        \n",
    "        \n",
    "        dist = project_distribution(returns, next_values.squeeze(), model.support)\n",
    "        \n",
    "        loss = -(dist*(log_probs.squeeze())).sum(-1).view(batch_size,-1).sum(-1)\n",
    "        dqn_loss = loss.clone().mean()\n",
    "        td_error = (loss + torch.nan_to_num((dist*torch.log(dist))).sum(-1)).mean()\n",
    "\n",
    "        \n",
    "        batched_loss = loss.clone()\n",
    "        \n",
    "        \n",
    "        z = F.normalize(z, 2, dim=-1, eps=1e-5)\n",
    "        z_pred = F.normalize(z_pred, 2, dim=-1, eps=1e-5)\n",
    "\n",
    "        \n",
    "        recon_loss = (mse(z_pred.contiguous().view(-1,2048), z.contiguous().view(-1,2048))).sum(-1)\n",
    "        recon_loss = 5*(recon_loss.view(batch_size, -1).mean(-1))*same_traj\n",
    "        \n",
    "        \n",
    "        loss += recon_loss\n",
    "        \n",
    "        loss = (loss*is_w).mean() # mean across batch axis\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    param_norm, grad_norm = params_and_grad_norm(model)\n",
    "    #scaler.scale(loss).backward()\n",
    "    #scaler.unscale_(optimizer)\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "    #scaler.step(optimizer)\n",
    "    #scaler.update()\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #memory.set_priority(idxs, batched_loss)\n",
    "    memory.set_priority(idxs, batched_loss, same_traj)\n",
    "    \n",
    "    \n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    wandb.log({'loss': loss, 'dqn_loss': dqn_loss, 'recon_loss': recon_loss.mean(), 'lr': lr, 'returns': plot_vs.mean(),\n",
    "               'buffer rewards': rewards.mean(0).sum(), 'is_w': is_w.mean(),\n",
    "               'gamma': gamma_step, 'td_error': td_error, 'param_norm': param_norm.sum(), 'grad_norm': grad_norm.sum()})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scores=[]\n",
    "memory.free()\n",
    "step=0\n",
    "#model.share_memory()\n",
    "grad_step=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05991348-a11a-43bd-882f-02df107fc543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1995/100000 [00:08<05:54, 276.68it/s]C:\\Users\\sneep\\AppData\\Local\\Temp\\ipykernel_15388\\1152238539.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gamma_step = 1-torch.tensor(( (schedule_max_step - min(grad_step, schedule_max_step)) / schedule_max_step) * (initial_gamma-final_gamma) + final_gamma).exp()\n",
      " 22%|██▏       | 22002/100000 [42:31<2:51:25,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting on step 22001 40002\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 36.37M\n",
      "IMPALA ResNet Parameters: 1.56M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22003/100000 [42:33<14:12:56,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Parameters: 36.37M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42003/100000 [1:29:25<2:29:26,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting on step 42002 40002\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 36.37M\n",
      "IMPALA ResNet Parameters: 1.56M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42004/100000 [1:29:27<10:43:01,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Parameters: 36.37M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62004/100000 [2:21:10<1:44:07,  6.08it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting on step 62003 40002\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 36.37M\n",
      "IMPALA ResNet Parameters: 1.56M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62005/100000 [2:21:12<7:15:37,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Parameters: 36.37M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 82005/100000 [4:03:02<1:37:33,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting on step 82004 40002\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 36.37M\n",
      "IMPALA ResNet Parameters: 1.56M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 82006/100000 [4:03:06<6:37:11,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Parameters: 36.37M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [5:04:43<00:00,  4.25it/s] "
     ]
    }
   ],
   "source": [
    "step=0\n",
    "\n",
    "progress_bar = tqdm.tqdm(total=total_steps)\n",
    "\n",
    "while step<(10):\n",
    "    state, info = env.reset()\n",
    "    state = preprocess(state)\n",
    "\n",
    "    stacked = state.repeat_interleave(3,1)\n",
    "    state = torch.cat((stacked.clone(), state),1)\n",
    "    \n",
    "    \n",
    "    eps_reward=torch.tensor([0], dtype=torch.float)\n",
    "    \n",
    "    reward=np.array([0])\n",
    "    done_flag=np.array([False])\n",
    "    terminated=np.array([False])\n",
    "\n",
    "    last_lives=np.array([0])\n",
    "    life_loss=np.array([0])\n",
    "    \n",
    "    last_grad_update=0\n",
    "    while step<(total_steps):\n",
    "        progress_bar.update(1)\n",
    "        model_target.train()\n",
    "        \n",
    "        len_memory = len(memory)\n",
    "        Q_action = model_target.env_step(state.unsqueeze(0))\n",
    "        \n",
    "        action = epsilon_greedy(Q_action, len_memory).cpu()\n",
    "        \n",
    "        memory.push(state.detach().cpu(), reward, action, np.logical_or(done_flag, life_loss))\n",
    "        #print('action', action, action.shape)\n",
    "        \n",
    "        state, reward, terminated, truncated, info = env.step([action.numpy()])\n",
    "        \n",
    "        state = preprocess(state)\n",
    "        eps_reward+=reward\n",
    "        reward = reward.clip(-1, 1)\n",
    "\n",
    "        state = torch.cat((stacked.clone(), state),1)\n",
    "        stacked = torch.cat((stacked[:,3:], state[:,-3:]),1)\n",
    "\n",
    "        \n",
    "        done_flag = np.logical_or(terminated, truncated)\n",
    "        lives = info['lives']\n",
    "        life_loss = (last_lives-lives).clip(min=0)\n",
    "        last_lives = lives\n",
    "\n",
    "        \n",
    "        n = int(initial_n * (final_n/initial_n)**(min(grad_step,schedule_max_step) / schedule_max_step))\n",
    "        n = np.array(n).item()\n",
    "        \n",
    "        memory.priority[len_memory] = memory.max_priority()\n",
    "        \n",
    "\n",
    "        if len_memory>2000:\n",
    "            for i in range(2):\n",
    "                optimize(step, grad_step, n)\n",
    "                target_model_ema(model, model_target)\n",
    "                grad_step+=1\n",
    "\n",
    "        \n",
    "        if ((step+1)%10000)==0:\n",
    "            save_checkpoint(model, model_target, optimizer, step,\n",
    "                            'checkpoints/atari_last.pth')\n",
    "        \n",
    "            \n",
    "        \n",
    "        if grad_step>reset_every:\n",
    "            #eval()\n",
    "            print('Reseting on step', step, grad_step)\n",
    "            \n",
    "            seed_np_torch(random.randint(SEED-1000, SEED+1000)+step)\n",
    "            random_model = DQN(n_actions).cuda()\n",
    "            model.hard_reset(random_model)\n",
    "            \n",
    "            seed_np_torch(random.randint(SEED-1000, SEED+1000)+step)\n",
    "            random_model = DQN(n_actions).cuda()\n",
    "            model_target.hard_reset(random_model)\n",
    "            seed_np_torch(SEED)\n",
    "            \n",
    "            random_model=None\n",
    "            grad_step=0\n",
    "\n",
    "            actor_modules=[model.prediction, model.projection, model.a, model.v]\n",
    "            params_ac=[]\n",
    "            for module in actor_modules:\n",
    "                for param in module.parameters():\n",
    "                    params_ac.append(param)\n",
    "                    \n",
    "\n",
    "            perception_modules=[model.encoder_cnn, model.transition]\n",
    "            params_wm=[]\n",
    "            for module in perception_modules:\n",
    "                for param in module.parameters():\n",
    "                    params_wm.append(param)\n",
    "            \n",
    "            optimizer_aux = torch.optim.AdamW(params_wm, lr=lr, weight_decay=0.1, eps=1.5e-4)\n",
    "            copy_states(optimizer, optimizer_aux)\n",
    "            optimizer = torch.optim.AdamW(chain(params_wm, params_ac),\n",
    "                                lr=lr, weight_decay=0.1, eps=1.5e-4)\n",
    "            copy_states(optimizer_aux, optimizer)\n",
    "        \n",
    "        \n",
    "        \n",
    "        step+=1\n",
    "        \n",
    "        log_t = done_flag.astype(float).nonzero()[0]\n",
    "        \n",
    "        if len(log_t)>0:\n",
    "            for log in log_t:\n",
    "                wandb.log({'eps_reward': eps_reward[log].sum()})\n",
    "                scores.append(eps_reward[log].clone())\n",
    "            eps_reward[log_t]=0\n",
    "\n",
    "save_checkpoint(model, model_target, optimizer, step, f'checkpoints/{env_name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87344597-e733-451c-8a5f-2a00b5511061",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_to_eval=True\n",
    "\n",
    "if load_to_eval:\n",
    "    model.load_state_dict(torch.load(f'checkpoints/{env_name}.pth')['model_state_dict'])\n",
    "    model_target.load_state_dict(torch.load(f'checkpoints/{env_name}.pth')['model_target_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12d36218-ab48-42d9-a7ba-fabb66cc758f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\gymnasium\\vector\\__init__.py:53: UserWarning: \u001b[33mWARN: `gymnasium.vector.make(...)` is deprecated and will be replaced by `gymnasium.make_vec(...)` in v1.0\u001b[0m\n",
      "  gym.logger.warn(\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init state torch.Size([1, 3, 96, 72])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 1/100 [00:11<18:37, 11.28s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:22<18:33, 11.36s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [00:33<18:18, 11.33s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [00:45<18:00, 11.26s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [00:56<17:52, 11.29s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [01:07<17:36, 11.24s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [01:18<17:24, 11.23s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [01:29<17:09, 11.19s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [01:41<17:05, 11.27s/it]\u001b[A\n",
      " 10%|█         | 10/100 [01:54<17:38, 11.76s/it]\u001b[A\n",
      " 11%|█         | 11/100 [02:05<17:05, 11.52s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [02:16<16:45, 11.43s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [02:27<16:31, 11.40s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [02:39<16:16, 11.35s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [02:50<16:01, 11.31s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [03:01<15:52, 11.34s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [03:12<15:32, 11.23s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [03:23<15:19, 11.21s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [03:35<15:09, 11.23s/it]\u001b[A\n",
      " 20%|██        | 20/100 [03:45<14:49, 11.11s/it]\u001b[A\n",
      " 21%|██        | 21/100 [03:57<14:39, 11.13s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [04:08<14:31, 11.17s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [04:19<14:30, 11.31s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [04:31<14:24, 11.38s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [04:42<14:08, 11.32s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [04:53<13:53, 11.26s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [05:04<13:27, 11.07s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [05:14<12:56, 10.79s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [05:24<12:27, 10.53s/it]\u001b[A\n",
      " 30%|███       | 30/100 [05:34<12:10, 10.43s/it]\u001b[A\n",
      " 31%|███       | 31/100 [05:45<12:09, 10.57s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [05:57<12:16, 10.83s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [06:08<12:14, 10.96s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [06:19<12:07, 11.02s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [06:31<12:08, 11.21s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [06:37<10:16,  9.64s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [06:48<10:47, 10.28s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [06:59<10:53, 10.53s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [07:13<11:29, 11.30s/it]\u001b[A\n",
      " 40%|████      | 40/100 [07:26<11:49, 11.82s/it]\u001b[A\n",
      " 41%|████      | 41/100 [07:37<11:29, 11.69s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [07:48<11:06, 11.50s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [08:00<10:56, 11.51s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [08:11<10:48, 11.58s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [08:22<10:20, 11.28s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [08:32<09:49, 10.92s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [08:42<09:25, 10.66s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [08:50<08:26,  9.75s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [09:00<08:28,  9.97s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [09:07<07:24,  8.89s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [09:17<07:44,  9.48s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [09:29<07:59, 10.00s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [09:40<08:04, 10.31s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [09:51<08:03, 10.51s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [10:02<08:06, 10.81s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [10:13<07:54, 10.79s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [10:23<07:34, 10.57s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [10:33<07:17, 10.41s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [10:44<07:10, 10.49s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [10:55<07:04, 10.62s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [11:06<07:00, 10.77s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [11:17<06:54, 10.91s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [11:29<06:51, 11.12s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [11:40<06:43, 11.20s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [11:51<06:32, 11.22s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [12:02<06:20, 11.20s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [12:13<06:09, 11.18s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [12:25<06:01, 11.30s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [12:36<05:44, 11.11s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [12:46<05:23, 10.77s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [12:56<05:07, 10.60s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [13:06<04:52, 10.43s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [13:16<04:40, 10.39s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [13:27<04:33, 10.51s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [13:38<04:23, 10.56s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [13:48<04:14, 10.61s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [14:01<04:19, 11.29s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [14:12<04:05, 11.17s/it]\u001b[A\n",
      " 79%|███████▉  | 79/100 [14:23<03:54, 11.16s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [14:35<03:43, 11.19s/it]\u001b[A\n",
      " 81%|████████  | 81/100 [14:41<03:03,  9.66s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [14:52<03:01, 10.08s/it]\u001b[A\n",
      " 83%|████████▎ | 83/100 [15:03<02:57, 10.42s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [15:14<02:50, 10.64s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [15:25<02:41, 10.79s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [15:37<02:33, 10.96s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [15:47<02:21, 10.92s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [15:58<02:10, 10.89s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [16:10<02:01, 11.02s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [16:21<01:51, 11.17s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [16:33<01:41, 11.31s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [16:44<01:30, 11.31s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [16:55<01:18, 11.26s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [17:06<01:07, 11.23s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [17:17<00:55, 11.17s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [17:28<00:43, 10.99s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [17:39<00:33, 11.02s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [17:46<00:19,  9.70s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [17:57<00:10, 10.19s/it]\u001b[A\n",
      "100%|██████████| 100/100 [18:08<00:00, 10.89s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Mean 3040.0\n",
      "Inter Quantile Mean 3020.0\n",
      "Inter Quantile STD 0.0\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/Hero-8048.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 109\u001b[0m\n\u001b[0;32m    105\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Scores Mean \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscores\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Inter Quantile Mean \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miqm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Inter Quantile STD \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miqs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scores\n\u001b[1;32m--> 109\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(eval_runs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, num_envs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[9], line 104\u001b[0m, in \u001b[0;36meval\u001b[1;34m(eval_runs, max_eval_steps, num_envs)\u001b[0m\n\u001b[0;32m    100\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReward\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    101\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(scores)\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSEED\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    105\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Scores Mean \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscores\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Inter Quantile Mean \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miqm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Inter Quantile STD \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miqs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python_\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/Hero-8048.txt'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_envs=1\n",
    "\n",
    "#env = gym.vector.make(f\"{env_name}NoFrameskip-v4\", num_envs=num_envs, render_mode='human')\n",
    "env = gym.vector.make(f\"{env_name}NoFrameskip-v4\", num_envs=num_envs)\n",
    "env = MaxLast2FrameSkipWrapper(env,seed=SEED)\n",
    "\n",
    "def eval_phase(eval_runs=50, max_eval_steps=27000, num_envs=1):\n",
    "    progress_bar = tqdm.tqdm(total=eval_runs)\n",
    "    \n",
    "    scores=[]\n",
    "    \n",
    "    state, info = env.reset()\n",
    "    state = preprocess(state)\n",
    "    print(f\"init state {state.shape}\")\n",
    "    stacked = state.repeat_interleave(3,1)\n",
    "    state = torch.cat((stacked.clone(), state),1)\n",
    "    \n",
    "    \n",
    "    eps_reward=torch.tensor([0]*num_envs, dtype=torch.float)\n",
    "    \n",
    "    reward=np.array([0]*num_envs)\n",
    "    terminated=np.array([False]*num_envs)\n",
    "\n",
    "    last_lives=np.array([0]*num_envs)\n",
    "\n",
    "    finished_envs=np.array([False]*num_envs)\n",
    "    done_flag=0\n",
    "    last_grad_update=0\n",
    "    eval_run=0\n",
    "    step=np.array([0]*num_envs)\n",
    "    while eval_run<eval_runs:\n",
    "        #seed_np_torch(SEED+eval_run)\n",
    "        env.seed=SEED+eval_run\n",
    "        model_target.train()\n",
    "        \n",
    "        \n",
    "        Q_action = model_target.env_step(state.unsqueeze(0))\n",
    "        action = epsilon_greedy(Q_action.squeeze(), 5000, 0.0005, num_envs).cpu()\n",
    "        \n",
    "        state, reward, terminated, truncated, info = env.step([action.numpy()] if num_envs==1 else action.numpy())\n",
    "        done_flag = np.logical_or(terminated, truncated)\n",
    "        \n",
    "\n",
    "        state = preprocess(state)\n",
    "        eps_reward+=reward\n",
    "\n",
    "\n",
    "        \n",
    "        state = torch.cat((stacked.clone(), state),1)\n",
    "        stacked = torch.cat((stacked[:,3:], state[:,-3:]),1)\n",
    "        \n",
    "        \n",
    "        step+=1\n",
    "        \n",
    "        log_t = done_flag.astype(float).nonzero()[0]\n",
    "        if len(log_t)>0:# or (step>max_eval_steps).any():\n",
    "            progress_bar.update(1)\n",
    "            for log in log_t:\n",
    "                #wandb.log({'eval_eps_reward': eps_reward[log].sum()})\n",
    "                if finished_envs[log]==False:\n",
    "                    scores.append(eps_reward[log].clone())\n",
    "                    eval_run+=1\n",
    "                    #finished_envs[log]=True\n",
    "                step[log]=0\n",
    "                \n",
    "            eps_reward[log_t]=0            \n",
    "            for i, log in enumerate(step>max_eval_steps):\n",
    "                if log==True and finished_envs[i]==False:\n",
    "                    scores.append(eps_reward[i].clone())\n",
    "                    step[i]=0\n",
    "                    eval_run+=1\n",
    "                    eps_reward[i]=0\n",
    "                    #finished_envs[i]=True\n",
    "            \n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "def eval(eval_runs=50, max_eval_steps=27000, num_envs=1):\n",
    "    assert num_envs==1, 'The code for num eval envs > 1 is messed up.'\n",
    "    \n",
    "    scores = eval_phase(eval_runs, max_eval_steps, num_envs)    \n",
    "    scores = torch.stack(scores)\n",
    "    scores, _ = scores.sort()\n",
    "    \n",
    "    _25th = eval_runs//4\n",
    "\n",
    "    iq = scores[_25th:-_25th]\n",
    "    iqm = iq.mean()\n",
    "    iqs = iq.std()\n",
    "\n",
    "    print(f\"Scores Mean {scores.mean()}\")\n",
    "    print(f\"Inter Quantile Mean {iqm}\")\n",
    "    print(f\"Inter Quantile STD {iqs}\")\n",
    "\n",
    "    \n",
    "    plt.xlabel('Episode (Sorted by Reward)')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.plot(scores)\n",
    "\n",
    "    \n",
    "    with open(f'results/{env_name}-{SEED}.txt', 'w') as f:\n",
    "        f.write(f\" Scores Mean {scores.mean()}\\n Inter Quantile Mean {iqm}\\n Inter Quantile STD {iqs}\")\n",
    "    \n",
    "    return scores\n",
    "\n",
    "scores = eval(eval_runs=100, num_envs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cddb4f-7fdd-4b4b-8e62-33d92f4313df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cefa2a-c6d7-4a51-8cdd-e22d14355750",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
