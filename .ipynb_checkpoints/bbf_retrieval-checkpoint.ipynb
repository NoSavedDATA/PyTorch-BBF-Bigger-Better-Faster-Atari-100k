{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57cb10b8-6556-487a-80d5-7f5b165b996a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\diffusers\\utils\\outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msnykralafk\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\sneep\\Python\\bbf\\wandb\\run-20240408_103937-37u3puk3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/snykralafk/Atari-100k-BBF/runs/37u3puk3' target=\"_blank\">BBF-retrieval-Assault</a></strong> to <a href='https://wandb.ai/snykralafk/Atari-100k-BBF' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/snykralafk/Atari-100k-BBF' target=\"_blank\">https://wandb.ai/snykralafk/Atari-100k-BBF</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/snykralafk/Atari-100k-BBF/runs/37u3puk3' target=\"_blank\">https://wandb.ai/snykralafk/Atari-100k-BBF/runs/37u3puk3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count, chain\n",
    "import tqdm\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "from nosaveddata.nsd_utils.save_hypers import Hypers, nsd_Module\n",
    "from nosaveddata.nsd_utils.nsd_csv import add_to_csv\n",
    "from nosaveddata.nsd_utils.optim import Lookahead\n",
    "from nosaveddata.nsd_utils.networks import params_count, params_and_grad_norm, seed_np_torch\n",
    "from nosaveddata.nsd_utils.einstein import Rearrange\n",
    "\n",
    "from nosaveddata.builders.mlp import *\n",
    "from nosaveddata.builders.weight_init import *\n",
    "from nosaveddata.builders.resnet import IMPALA_Resnet, DQN_Conv, IMPALA_YY\n",
    "\n",
    "\n",
    "from utils.experience_replay_retrieval import *\n",
    "\n",
    "\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "import wandb\n",
    "\n",
    "\n",
    "# Environment configuration\n",
    "#env_name = 'Kangaroo'\n",
    "#SEED = 8712\n",
    "\n",
    "env_name = 'Assault'\n",
    "SEED = 7783\n",
    "\n",
    "\n",
    "wandb.init(\n",
    "    project=\"Atari-100k-BBF\",\n",
    "    name=f\"BBF-retrieval-{env_name}\",\n",
    "\n",
    "    #id='rotdmtc5',\n",
    "    #resume='must',\n",
    "\n",
    "    config={\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"architecture\": \"BBF\",\n",
    "        \"dataset\": \"Assault\",\n",
    "        \"epochs\": 100,\n",
    "    },\n",
    "\n",
    "    reinit=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Optimization\n",
    "batch_size = 32\n",
    "lr=1e-4\n",
    "\n",
    "eps=1e-8\n",
    "\n",
    "\n",
    "# Target network EMA rate\n",
    "critic_ema_decay=0.995\n",
    "\n",
    "\n",
    "# Return function\n",
    "initial_gamma=torch.tensor(1-0.97).log()\n",
    "final_gamma=torch.tensor(1-0.997).log()\n",
    "\n",
    "initial_n = 10\n",
    "final_n = 3\n",
    "\n",
    "num_buckets=51\n",
    "\n",
    "# Reset Schedule and Buffer\n",
    "reset_every=40000 # grad steps, not steps.\n",
    "schedule_max_step=reset_every//4\n",
    "total_steps=102000\n",
    "\n",
    "prefetch_cap=1 # actually, no prefetch is being done\n",
    "\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'reward', 'action', 'c_flag'))\n",
    "memory = PrioritizedReplay_nSteps_Sqrt(total_steps+5, total_steps=schedule_max_step, prefetch_cap=prefetch_cap)\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint(net, model_target, optimizer, step, path):\n",
    "    torch.save({\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'model_target_state_dict': model_target.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'step': step,\n",
    "            }, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c831907e-0868-4915-bc34-3d1dd1fe363c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\gymnasium\\vector\\__init__.py:53: UserWarning: \u001b[33mWARN: `gymnasium.vector.make(...)` is deprecated and will be replaced by `gymnasium.make_vec(...)` in v1.0\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# Adapted from: https://github.com/weipu-zhang/STORM/blob/main/env_wrapper.py\n",
    "class MaxLast2FrameSkipWrapper(Hypers, gym.Wrapper):\n",
    "    def __init__(self, env, skip=4, noops=30, seed=0):\n",
    "        super().__init__(env=env)\n",
    "        self.env.action_space.seed(seed)\n",
    "        \n",
    "    def reset(self, **kwargs):\n",
    "        kwargs[\"seed\"] = self.seed\n",
    "        obs, _ = self.env.reset(**kwargs)\n",
    "\n",
    "        return obs, _\n",
    "        \n",
    "    def noop_steps(self, states):\n",
    "        noops = random.randint(0,self.noops)\n",
    "        \n",
    "        for i in range(noops):\n",
    "            state = self.step(np.array([0]))[0]\n",
    "            state = preprocess(state)\n",
    "            states.append(state)\n",
    "        return states\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0\n",
    "        self.obs_buffer = deque(maxlen=2)\n",
    "        for _ in range(self.skip):\n",
    "            obs, reward, done, truncated, info = self.env.step(action)\n",
    "            self.obs_buffer.append(obs)\n",
    "            total_reward += reward\n",
    "\n",
    "            terminated = np.logical_or(done, truncated)\n",
    "            #if terminated.any():\n",
    "            #    for i in range(len(terminated)):\n",
    "            #       obs[i] = self.reset()[0][i]\n",
    "            if done or truncated:\n",
    "                break\n",
    "        if len(self.obs_buffer) == 1:\n",
    "            obs = self.obs_buffer[0]\n",
    "        else:\n",
    "            obs = np.max(np.stack(self.obs_buffer), axis=0)\n",
    "        return obs, total_reward, done, truncated, info\n",
    "        # Life loss is calculated on the training code\n",
    "\n",
    "env = gym.vector.make(f\"{env_name}NoFrameskip-v4\", num_envs=1)\n",
    "env = MaxLast2FrameSkipWrapper(env,seed=SEED)\n",
    "\n",
    "\n",
    "#n_actions = env.action_space.n\n",
    "n_actions = env.action_space[0].n\n",
    "\n",
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "seed_np_torch(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8d429f2-aee0-4c6b-b221-d2a8b09b0e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 35.21M\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 35.21M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def renormalize(tensor, has_batch=False):\n",
    "    shape = tensor.shape\n",
    "    tensor = tensor.view(tensor.shape[0], -1)\n",
    "    max_value,_ = torch.max(tensor, -1, keepdim=True)\n",
    "    min_value,_ = torch.min(tensor, -1, keepdim=True)\n",
    "    return ((tensor - min_value) / (max_value - min_value + 1e-5)).view(shape)\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, n_actions, hiddens=2048, mlp_layers=1, scale_width=4, init_cnn=init_xavier,\n",
    "                 n_atoms=51, Vmin=-10, Vmax=10):\n",
    "        super().__init__()\n",
    "        self.support = torch.linspace(Vmin, Vmax, n_atoms).cuda()\n",
    "        \n",
    "        self.hiddens=hiddens\n",
    "        self.scale_width=scale_width\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "        \n",
    "        self.encoder_cnn = IMPALA_Resnet(scale_width=scale_width, norm=False, init=init_cnn, act=self.act)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Single layer dense that maps the flattened encoded representation into hiddens.\n",
    "        self.projection = MLP(3456*scale_width, med_hiddens=hiddens, out_hiddens=hiddens,\n",
    "                              last_init=init_xavier, layers=1)\n",
    "        self.prediction = MLP(hiddens, out_hiddens=hiddens, layers=1, last_init=init_xavier)\n",
    "        self.G = MLP(hiddens, out_hiddens=1, layers=1, last_init=init_zeros)\n",
    "        self.critical_s_mlp = MLP(hiddens, out_hiddens=1, layers=1, out_act=nn.Sigmoid(), last_init=init_xavier)\n",
    "                                              \n",
    "        self.transition = nn.Sequential(DQN_Conv(32*scale_width+n_actions, 32*scale_width, 3, 1, 1, norm=False, init=init_xavier, act=self.act),\n",
    "                                        DQN_Conv(32*scale_width, 32*scale_width, 3, 1, 1, norm=False, init=init_xavier, act=self.act))\n",
    "\n",
    "        # Single layer dense that maps hiddens into the output dim according to:\n",
    "        # 1. https://arxiv.org/pdf/1707.06887.pdf -- Distributional Reinforcement Learning\n",
    "        # 2. https://arxiv.org/pdf/1511.06581.pdf -- Dueling DQN\n",
    "        self.a = MLP(hiddens, out_hiddens=n_actions*num_buckets, layers=1, in_act=self.act, last_init=init_xavier)\n",
    "        self.v = MLP(hiddens, out_hiddens=num_buckets, layers=1, in_act=self.act, last_init=init_xavier)\n",
    "    \n",
    "        params_count(self, 'DQN')\n",
    "    \n",
    "    def forward(self, X, y_action):\n",
    "        X, z = self.encode(X)\n",
    "        \n",
    "        \n",
    "        q, action = self.q_head(X)\n",
    "        z_pred = self.get_transition(z, y_action)\n",
    "        G_pred = self.G(X)\n",
    "\n",
    "        return q, action, X[:,1:].clone().detach(), z_pred, G_pred\n",
    "    \n",
    "\n",
    "    def env_step(self, X):\n",
    "        with torch.no_grad():\n",
    "            X, _ = self.encode(X)\n",
    "            _, action = self.q_head(X)\n",
    "            \n",
    "            return action.detach()\n",
    "    \n",
    "    def encode(self, X):\n",
    "        batch, seq = X.shape[:2]\n",
    "        self.batch = batch\n",
    "        self.seq = seq\n",
    "        X = self.encoder_cnn(X.contiguous().view(self.batch*self.seq, *(X.shape[2:])))\n",
    "        X = renormalize(X).contiguous().view(self.batch, self.seq, *X.shape[-3:])\n",
    "        X = X.contiguous().view(self.batch, self.seq, *X.shape[-3:])\n",
    "        z = X.clone()\n",
    "        X = X.flatten(-3,-1)\n",
    "        X = self.projection(X)\n",
    "        return X, z\n",
    "\n",
    "    def pred_G(self, X):\n",
    "        X, _ = self.encode(X)\n",
    "        \n",
    "        return self.G(X)\n",
    "        \n",
    "    def pred_critical_states(self, X):\n",
    "        X, _ = self.encode(X)\n",
    "        \n",
    "        return self.critical_s_mlp(X)\n",
    "    \n",
    "    def get_transition(self, z, action):\n",
    "        z = z.contiguous().view(-1, *z.shape[-3:])\n",
    "        \n",
    "        action = F.one_hot(action.clone(), n_actions).view(-1, n_actions)\n",
    "        action = action.view(-1, 5, n_actions, 1, 1).expand(-1, 5, n_actions, *z.shape[-2:])\n",
    "\n",
    "        z_pred = torch.cat( (z, action[:,0]), 1)\n",
    "        z_pred = self.transition(z_pred)\n",
    "        z_pred = renormalize(z_pred)\n",
    "        \n",
    "        z_preds=[z_pred.clone()]\n",
    "        \n",
    "\n",
    "        for k in range(4):\n",
    "            z_pred = torch.cat( (z_pred, action[:,k+1]), 1)\n",
    "            z_pred = self.transition(z_pred)\n",
    "            z_pred = renormalize(z_pred)\n",
    "            \n",
    "            z_preds.append(z_pred)\n",
    "        \n",
    "        \n",
    "        z_pred = torch.stack(z_preds,1)\n",
    "\n",
    "        z_pred = self.projection(z_pred.flatten(-3,-1)).view(self.batch,5,-1)\n",
    "        z_pred = self.prediction(z_pred)\n",
    "        \n",
    "        return z_pred\n",
    "\n",
    "    \n",
    "    def q_head(self, X):\n",
    "        q = self.dueling_dqn(X)\n",
    "        action = (q*self.support).sum(-1).argmax(-1)\n",
    "        \n",
    "        return q, action\n",
    "\n",
    "    def get_max_action(self, X):\n",
    "        with torch.no_grad():\n",
    "            X, _ = self.encode(X)\n",
    "            q = self.dueling_dqn(X)\n",
    "            \n",
    "            action = (q*self.support).sum(-1).argmax(-1)\n",
    "            return action\n",
    "\n",
    "    def evaluate(self, X, action):\n",
    "        with torch.no_grad():\n",
    "            X, _ = self.encode(X)\n",
    "            \n",
    "            q = self.dueling_dqn(X)\n",
    "            \n",
    "            action = action[:,:,None,None].expand_as(q)[:,:,0][:,:,None]\n",
    "            q = q.gather(-2,action)\n",
    "            \n",
    "            return q\n",
    "\n",
    "    def dueling_dqn(self, X):\n",
    "        X = F.relu(X)\n",
    "        \n",
    "        a = self.a(X).view(self.batch, -1, n_actions, num_buckets)\n",
    "        v = self.v(X).view(self.batch, -1, 1, num_buckets)\n",
    "        \n",
    "        q = v + a - a.mean(-2,keepdim=True)\n",
    "        q = F.softmax(q,-1)\n",
    "        \n",
    "        return q\n",
    "    \n",
    "    def network_ema(self, rand_network, target_network, alpha=0.5):\n",
    "        for param, param_target in zip(rand_network.parameters(), target_network.parameters()):\n",
    "            param_target.data = alpha * param_target.data + (1 - alpha) * param.data.clone()\n",
    "\n",
    "    def hard_reset(self, random_model, alpha=0.8):\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            self.network_ema(random_model.encoder_cnn, self.encoder_cnn, alpha)\n",
    "            self.network_ema(random_model.transition, self.transition, alpha)\n",
    "\n",
    "            self.network_ema(random_model.projection, self.projection, 0)\n",
    "            self.network_ema(random_model.prediction, self.prediction, 0)\n",
    "\n",
    "            self.network_ema(random_model.a, self.a, 0)\n",
    "            self.network_ema(random_model.v, self.v, 0)\n",
    "\n",
    "\n",
    "\n",
    "def copy_states(source, target):\n",
    "    for key, _ in zip(source.state_dict()['state'].keys(), target.state_dict()['state'].keys()):\n",
    "\n",
    "        target.state_dict()['state'][key]['exp_avg_sq'] = copy.deepcopy(source.state_dict()['state'][key]['exp_avg_sq'])\n",
    "        target.state_dict()['state'][key]['exp_avg'] = copy.deepcopy(source.state_dict()['state'][key]['exp_avg'])\n",
    "        target.state_dict()['state'][key]['step'] = copy.deepcopy(source.state_dict()['state'][key]['step'])\n",
    "        \n",
    "def target_model_ema(model, model_target):\n",
    "    with torch.no_grad():\n",
    "        for param, param_target in zip(model.parameters(), model_target.parameters()):\n",
    "            #param_target.data = critic_ema_decay * param_target.data + (1.0 - critic_ema_decay) * param.data.clone()\n",
    "            param_target.data.mul(critic_ema_decay).add_(param.data.clone().mul(1.0 - critic_ema_decay))\n",
    "\n",
    "\n",
    "    \n",
    "model=DQN(n_actions,init_cnn=init_partial_dirac).cuda()\n",
    "model_target=DQN(n_actions,init_cnn=init_partial_dirac).cuda()\n",
    "\n",
    "model_target.load_state_dict(model.state_dict())\n",
    "\n",
    "\n",
    "# Testing only\n",
    "#with torch.no_grad():\n",
    "#    q, action, X, z_pred = model(torch.randn(4,1,12,96,72, device='cuda', dtype=torch.float), torch.randint(0,n_actions,(4,5),device='cuda').long())\n",
    "#z = model.encode(torch.randn(4,5,12,96,72, device='cuda'))[0]\n",
    "\n",
    "# I believe the authors have actually miscalculated the params count on the paper.\n",
    "# My training time is lower than theirs while having more parameters, and the same architecture is used as is their original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ca1d0e5-d128-428b-bcbc-be68dccc005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "perception_modules=[model.encoder_cnn, model.transition]\n",
    "actor_modules=[model.prediction, model.projection, model.a, model.v, model.critical_s_mlp, model.G]\n",
    "\n",
    "params_wm=[]\n",
    "for module in perception_modules:\n",
    "    for param in module.parameters():\n",
    "        if param.requires_grad==True:\n",
    "            params_wm.append(param)\n",
    "\n",
    "params_ac=[]\n",
    "for module in actor_modules:\n",
    "    for param in module.parameters():\n",
    "        if param.requires_grad==True:\n",
    "            params_ac.append(param)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(chain(params_wm, params_ac),\n",
    "                                lr=lr, weight_decay=0.1, eps=1.5e-4)\n",
    "lookahead = Lookahead(model, reset_every+10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7f2a7d7-81c6-4c93-8cbe-1f15fa75af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "                         transforms.Resize((96,72)),\n",
    "                        ])\n",
    "\n",
    "\n",
    "def preprocess(state):\n",
    "    state=torch.tensor(state, dtype=torch.float, device='cuda') / 255\n",
    "    state=train_tfms(state.permute(0,3,1,2))\n",
    "    return state\n",
    "\n",
    "# https://github.com/google/dopamine/blob/master/dopamine/jax/agents/dqn/dqn_agent.py\n",
    "def linearly_decaying_epsilon(decay_period, step, warmup_steps, epsilon):\n",
    "    steps_left = decay_period + warmup_steps - step\n",
    "    bonus = (1.0 - epsilon) * steps_left / decay_period\n",
    "    bonus = np.clip(bonus, 0., 1. - epsilon)\n",
    "    return epsilon + bonus\n",
    "\n",
    "\n",
    "def epsilon_greedy(Q_action, step, final_eps=0, num_envs=1):\n",
    "    epsilon = linearly_decaying_epsilon(2001, step, 2000, final_eps)\n",
    "    \n",
    "    if random.random() < epsilon:\n",
    "        action = torch.randint(0, n_actions, (num_envs,), dtype=torch.int64, device='cuda').squeeze(0)\n",
    "    else:\n",
    "        action = Q_action.view(num_envs).squeeze(0).to(torch.int64)\n",
    "    return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6722829c-d4bc-4d9f-aa35-80f6133a4819",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# https://github.com/google/dopamine/blob/master/dopamine/jax/agents/rainbow/rainbow_agent.py\n",
    "def project_distribution(supports, weights, target_support):\n",
    "    with torch.no_grad():\n",
    "        v_min, v_max = target_support[0], target_support[-1]\n",
    "        # `N` in Eq7.\n",
    "        num_dims = target_support.shape[-1]\n",
    "        # delta_z = `\\Delta z` in Eq7.\n",
    "        delta_z = (v_max - v_min) / (num_buckets-1)\n",
    "        # clipped_support = `[\\hat{T}_{z_j}]^{V_max}_{V_min}` in Eq7.\n",
    "        clipped_support = supports.clip(v_min, v_max)\n",
    "        # numerator = `|clipped_support - z_i|` in Eq7.\n",
    "        numerator = (clipped_support[:,None] - target_support[None,:,None].repeat_interleave(clipped_support.shape[0],0)).abs()\n",
    "        quotient = 1 - (numerator / delta_z)\n",
    "        # clipped_quotient = `[1 - numerator / (\\Delta z)]_0^1` in Eq7.\n",
    "        clipped_quotient = quotient.clip(0, 1)\n",
    "        # inner_prod = `\\sum_{j=0}^{N-1} clipped_quotient * p_j(x', \\pi(x'))` in Eq7.\n",
    "        inner_prod = (clipped_quotient * weights[:,None]).sum(-1)\n",
    "        #inner_prod = (clipped_quotient).sum(-1) * weights\n",
    "        return inner_prod.squeeze()\n",
    "\n",
    "mse = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "#The remaining hyper-parameters λs, λr, and λv are set to 1, 5 × 10−3 and 2 respectively.\n",
    "\n",
    "\n",
    "def optimize(step, grad_step, n):\n",
    "        \n",
    "    model.train()\n",
    "    model_target.train()\n",
    "\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.bfloat16, enabled=False):\n",
    "        with torch.no_grad():\n",
    "            states, next_states, rewards, action, c_flag, idxs, is_w = memory.sample(n*5, batch_size, grad_step)\n",
    "\n",
    "            #critical_s_pred = model.pred_critical_states(states[:,1:max(n,5)])*(c_flag[:,1:max(n,5)].cumprod(-1))\n",
    "            critical_s_pred = model.pred_critical_states(states[:,1:n])*(c_flag[:,1:n].cumprod(-1))\n",
    "            \n",
    "            critical_s_pred = critical_s_pred.squeeze().argmax(-1)+1\n",
    "            \n",
    "            \n",
    "        terminal=1-c_flag\n",
    "        \n",
    "    \n",
    "    \n",
    "        q, max_action, _, z_pred, G_pred  = model(states[:,0][:,None], action[:,:5].long())\n",
    "        z = model_target.encode(states[:,1:6])[0].detach()\n",
    "\n",
    "        '''\n",
    "        crit_returns = critical_s_pred-1+n\n",
    "        #crit_returns[crit_returns<n] = n\n",
    "        crit_returns = 1-F.one_hot(crit_returns, max(n+1,6)*2)[:,:max(n,5)*2]\n",
    "        \n",
    "        crit_returns = (crit_returns*torch.ones_like(crit_returns))\n",
    "        crit_returns = crit_returns.cumprod(-1)[...,None]\n",
    "        #crit_returns = crit_returns.repeat_interleave(2,1)\n",
    "        '''\n",
    "        \n",
    "        crit_returns = critical_s_pred-1#+n\n",
    "        crit_returns = 1-F.one_hot(crit_returns, n+1)[:,:n]\n",
    "        \n",
    "        crit_returns = (crit_returns*torch.ones_like(crit_returns))\n",
    "        crit_returns = crit_returns.cumprod(-1)[...,None]\n",
    "        \n",
    "        \n",
    "        max_action  = model.get_max_action(next_states[torch.arange(batch_size),critical_s_pred][:,None])\n",
    "        next_values = model_target.evaluate(next_states[torch.arange(batch_size),critical_s_pred][:,None].contiguous(), max_action)\n",
    "        \n",
    "\n",
    "        action = action[:,0,None].expand(batch_size,num_buckets)\n",
    "        action=action[:,None]\n",
    "        with torch.no_grad():\n",
    "            gammas_one=torch.ones(batch_size,n,1,dtype=torch.float,device='cuda')\n",
    "            gamma_step = 1-torch.tensor(( (schedule_max_step - min(grad_step, schedule_max_step)) / schedule_max_step) * (initial_gamma-final_gamma) + final_gamma).exp()\n",
    "            gammas=gammas_one*gamma_step\n",
    "            \n",
    "            gammas_crit=gammas_one*0.997\n",
    "\n",
    "            \n",
    "            returns_crit = []\n",
    "            for t in range(2):\n",
    "                ret = 0\n",
    "                for u in reversed(range(t, n)):\n",
    "                    ret += torch.prod(c_flag[:,t+1:u+1],-2)*torch.prod(gammas_crit[:,t:u],-2)*rewards[:,u+1]\n",
    "                returns_crit.append(ret)\n",
    "                \n",
    "            returns_crit = torch.stack(returns_crit,1).squeeze()\n",
    "            \n",
    "            returns = []\n",
    "            #for t in range(max(n,5)):\n",
    "            for t in range(2):\n",
    "                ret = 0\n",
    "                for u in reversed(range(t, n*2)):\n",
    "                    #print(f\"{c_flag.shape, c_flag[:,t+1:u+1].shape, crit_returns.shape, torch.prod(crit_returns[:,t:u],-2).shape}\")\n",
    "                    ret += torch.prod(c_flag[:,t+1:u+1],-2)*torch.prod(gammas[:,t:u],-2)*torch.prod(crit_returns[:,t:u],-2)*rewards[:,u+1]\n",
    "                    #ret += torch.prod(c_flag[:,t+1:u+1],-2)*torch.prod(gammas[:,t:u],-2)*rewards[:,u+1]\n",
    "                returns.append(ret)\n",
    "                \n",
    "            returns = torch.stack(returns,1)\n",
    "        \n",
    "        plot_vs = returns.clone().sum(-1)\n",
    "        \n",
    "        same_traj = (torch.prod(c_flag[:,:n],-2)).squeeze()\n",
    "        \n",
    "        returns = returns[:,0]\n",
    "        returns_crit = returns_crit[:,0]\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        returns = returns + torch.prod(gammas[0,:10],-2).squeeze()*same_traj[:,None]*model.support[None,:]\n",
    "        returns = returns.squeeze()\n",
    "        \n",
    "        next_values = next_values[:,0]\n",
    "\n",
    "        log_probs = torch.log(q[:,0].gather(-2, action)[:,None] + eps).contiguous()\n",
    "        \n",
    "        \n",
    "        dist = project_distribution(returns, next_values.squeeze(), model.support)\n",
    "        \n",
    "        loss = -(dist*(log_probs.squeeze())).sum(-1).view(batch_size,-1).sum(-1)\n",
    "        dqn_loss = loss.clone().mean()\n",
    "        td_error = (loss + torch.nan_to_num((dist*torch.log(dist))).sum(-1)).mean()\n",
    "\n",
    "        \n",
    "        batched_loss = loss.clone()\n",
    "\n",
    "        #loss += G_loss\n",
    "        \n",
    "        z = F.normalize(z, 2, dim=-1, eps=1e-5)\n",
    "        z_pred = F.normalize(z_pred, 2, dim=-1, eps=1e-5)\n",
    "\n",
    "        \n",
    "        recon_loss = (mse(z_pred.contiguous().view(-1,2048), z.contiguous().view(-1,2048))).sum(-1)\n",
    "        recon_loss = 5*(recon_loss.view(batch_size, -1).mean(-1))*same_traj\n",
    "        \n",
    "        \n",
    "        loss += recon_loss\n",
    "        G_loss = mse(G_pred.squeeze(), returns_crit.squeeze())\n",
    "        \n",
    "        loss += G_loss\n",
    "\n",
    "        states = states[:,0][:,None]\n",
    "        \n",
    "        critical_states = model.pred_critical_states(states).squeeze()[...,None,None,None,None]\n",
    "        \n",
    "        importance_preservation = mse(model_target.pred_G(states*critical_states).squeeze(), returns_crit).sum(-1)\n",
    "        reverse = -mse(model_target.pred_G(states*(1-critical_states)).squeeze(), returns_crit).sum(-1)\n",
    "        compactness = critical_states.squeeze().sum(-1)\n",
    "\n",
    "        \n",
    "        mask = critical_states.squeeze()[:,None]\n",
    "        Ort_loss_matrix = torch.abs(mask.mm(mask.t())).cuda()\n",
    "        Ort_loss_matrix = (torch.ones_like(Ort_loss_matrix) - torch.eye(Ort_loss_matrix.size(0)).cuda()) * Ort_loss_matrix\n",
    "        orthogonal_loss = torch.mean(torch.triu(Ort_loss_matrix, diagonal=1))\n",
    "\n",
    "        loss += importance_preservation + 2*reverse + 5e-3*compactness + 5e-4*orthogonal_loss\n",
    "        \n",
    "        \n",
    "        loss = (loss*is_w).mean() # mean across batch axis\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    param_norm, grad_norm = params_and_grad_norm(model)\n",
    "    #scaler.scale(loss).backward()\n",
    "    #scaler.unscale_(optimizer)\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "    #scaler.step(optimizer)\n",
    "    #scaler.update()\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #memory.set_priority(idxs, batched_loss)\n",
    "    memory.set_priority(idxs, batched_loss, same_traj)\n",
    "    \n",
    "    \n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    wandb.log({'loss': loss, 'dqn_loss': dqn_loss, 'recon_loss': recon_loss.mean(), 'lr': lr, 'returns': plot_vs.mean(),\n",
    "               'buffer rewards': rewards.mean(0).sum(), 'is_w': is_w.mean(), 'Importance Preservation': importance_preservation.mean(),\n",
    "               'gamma': gamma_step, 'td_error': td_error, 'param_norm': param_norm.sum(), 'grad_norm': grad_norm.sum()})\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scores=[]\n",
    "\n",
    "memory.free()\n",
    "\n",
    "step=0\n",
    "grad_step=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05991348-a11a-43bd-882f-02df107fc543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1997/102000 [00:06<05:15, 316.69it/s]C:\\Users\\sneep\\AppData\\Local\\Temp\\ipykernel_10564\\780506258.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gamma_step = 1-torch.tensor(( (schedule_max_step - min(grad_step, schedule_max_step)) / schedule_max_step) * (initial_gamma-final_gamma) + final_gamma).exp()\n",
      " 22%|██▏       | 22002/102000 [1:41:14<6:29:56,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting on step 22001 40002\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 35.21M\n",
      "IMPALA ResNet Parameters: 1.56M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22003/102000 [1:41:17<19:15:55,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Parameters: 35.21M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 42003/102000 [3:25:39<4:59:03,  3.34it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting on step 42002 40002\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 35.21M\n",
      "IMPALA ResNet Parameters: 1.56M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 42004/102000 [3:25:41<14:48:02,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Parameters: 35.21M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 62004/102000 [6:03:59<5:14:28,  2.12it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting on step 62003 40002\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 35.21M\n",
      "IMPALA ResNet Parameters: 1.56M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 62005/102000 [6:04:12<48:55:09,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Parameters: 35.21M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 82005/102000 [8:58:32<2:46:37,  2.00it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting on step 82004 40002\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 35.21M\n",
      "IMPALA ResNet Parameters: 1.56M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 82006/102000 [8:58:50<31:43:51,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Parameters: 35.21M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102000/102000 [11:54:48<00:00,  1.95it/s] "
     ]
    }
   ],
   "source": [
    "step=0\n",
    "\n",
    "progress_bar = tqdm.tqdm(total=total_steps)\n",
    "\n",
    "while step<(10):\n",
    "    state, info = env.reset()\n",
    "    state = preprocess(state)\n",
    "\n",
    "    states = deque(maxlen=4)\n",
    "    for i in range(4):\n",
    "        states.append(state)\n",
    "    \n",
    "    \n",
    "    eps_reward=torch.tensor([0], dtype=torch.float)\n",
    "    \n",
    "    reward=np.array([0])\n",
    "    done_flag=np.array([False])\n",
    "    terminated=np.array([False])\n",
    "\n",
    "    last_lives=np.array([0])\n",
    "    life_loss=np.array([0])\n",
    "    resetted=np.array([0])\n",
    "    \n",
    "    last_grad_update=0\n",
    "    while step<(total_steps):\n",
    "        progress_bar.update(1)\n",
    "        model_target.train()\n",
    "        \n",
    "        len_memory = len(memory)\n",
    "        \n",
    "        #if resetted[0]>0:\n",
    "        #    states = env.noop_steps(states)\n",
    "            \n",
    "        Q_action = model_target.env_step(torch.cat(list(states),-3).unsqueeze(0))\n",
    "        \n",
    "        action = epsilon_greedy(Q_action, len_memory).cpu()\n",
    "        \n",
    "        memory.push(torch.cat(list(states),-3).detach().cpu(), torch.tensor(reward,dtype=torch.float), action,\n",
    "                    torch.tensor(np.logical_or(done_flag, life_loss),dtype=torch.bool))\n",
    "        #print('action', action, action.shape)\n",
    "        \n",
    "        state, reward, terminated, truncated, info = env.step([action.numpy()])\n",
    "        state = preprocess(state)\n",
    "        states.append(state)\n",
    "        \n",
    "        eps_reward+=reward\n",
    "        reward = reward.clip(-1, 1)\n",
    "\n",
    "\n",
    "        \n",
    "        done_flag = np.logical_or(terminated, truncated)\n",
    "        lives = info['lives']\n",
    "        life_loss = (last_lives-lives).clip(min=0)\n",
    "        resetted = (lives-last_lives).clip(min=0)\n",
    "        last_lives = lives\n",
    "\n",
    "        \n",
    "        n = int(initial_n * (final_n/initial_n)**(min(grad_step,schedule_max_step) / schedule_max_step))\n",
    "        n = np.array(n).item()\n",
    "        \n",
    "        memory.priority[len_memory] = memory.max_priority()\n",
    "        \n",
    "\n",
    "        if len_memory>2000:\n",
    "            #optimize_critical_states(step, grad_step, n)\n",
    "            for i in range(2):\n",
    "                optimize(step, grad_step, n)\n",
    "                target_model_ema(model, model_target)\n",
    "                lookahead.update_fixed_decay(model, 0.5, grad_step)\n",
    "                grad_step+=1\n",
    "            \n",
    "\n",
    "        \n",
    "        if ((step+1)%10000)==0:\n",
    "            save_checkpoint(model, model_target, optimizer, step,\n",
    "                            'checkpoints/atari_last.pth')\n",
    "        \n",
    "            \n",
    "        \n",
    "        if grad_step>reset_every:\n",
    "            #eval()\n",
    "            print('Reseting on step', step, grad_step)\n",
    "            \n",
    "            #seed_np_torch(random.randint(SEED-1000, SEED+1000)+step)\n",
    "            random_model = DQN(n_actions).cuda()\n",
    "            model.hard_reset(random_model)\n",
    "            \n",
    "            #seed_np_torch(random.randint(SEED-1000, SEED+1000)+step)\n",
    "            random_model = DQN(n_actions).cuda()\n",
    "            model_target.hard_reset(random_model)\n",
    "            seed_np_torch(SEED)\n",
    "            \n",
    "            random_model=None\n",
    "            grad_step=0\n",
    "\n",
    "            actor_modules=[model.prediction, model.projection, model.a, model.v, model.critical_s_mlp, model.G]\n",
    "            params_ac=[]\n",
    "            for module in actor_modules:\n",
    "                for param in module.parameters():\n",
    "                    if param.requires_grad==True:\n",
    "                        params_ac.append(param)\n",
    "                    \n",
    "\n",
    "            perception_modules=[model.encoder_cnn, model.transition]\n",
    "            params_wm=[]\n",
    "            for module in perception_modules:\n",
    "                for param in module.parameters():\n",
    "                    if param.requires_grad==True:\n",
    "                        params_wm.append(param)\n",
    "            \n",
    "            optimizer_aux = torch.optim.AdamW(params_wm, lr=lr, weight_decay=0.1, eps=1.5e-4)\n",
    "            copy_states(optimizer, optimizer_aux)\n",
    "            optimizer = torch.optim.AdamW(chain(params_wm, params_ac),\n",
    "                                lr=lr, weight_decay=0.1, eps=1.5e-4)\n",
    "            copy_states(optimizer_aux, optimizer)\n",
    "            lookahead = Lookahead(model, reset_every+10)\n",
    "        \n",
    "        \n",
    "        \n",
    "        step+=1\n",
    "        \n",
    "        log_t = done_flag.astype(float).nonzero()[0]\n",
    "        \n",
    "        if len(log_t)>0:\n",
    "            for log in log_t:\n",
    "                wandb.log({'eps_reward': eps_reward[log].sum()})\n",
    "                scores.append(eps_reward[log].clone())\n",
    "            eps_reward[log_t]=0\n",
    "\n",
    "save_checkpoint(model, model_target, optimizer, step, f'checkpoints/{env_name}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87344597-e733-451c-8a5f-2a00b5511061",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_to_eval=False\n",
    "\n",
    "if load_to_eval:\n",
    "    model.load_state_dict(torch.load(f'checkpoints/{env_name}.pth')['model_state_dict'])\n",
    "    model_target.load_state_dict(torch.load(f'checkpoints/{env_name}.pth')['model_target_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12d36218-ab48-42d9-a7ba-fabb66cc758f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init state torch.Size([1, 3, 96, 72])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 1/100 [00:02<03:54,  2.36s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:04<03:58,  2.43s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [00:08<04:43,  2.92s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [00:12<05:25,  3.39s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [00:16<05:29,  3.47s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [00:19<05:13,  3.33s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [00:22<05:11,  3.35s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [00:28<06:13,  4.06s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [00:34<07:10,  4.73s/it]\u001b[A\n",
      " 10%|█         | 10/100 [00:41<08:13,  5.48s/it]\u001b[A\n",
      " 11%|█         | 11/100 [00:46<08:02,  5.42s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:50<07:00,  4.78s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:54<06:46,  4.67s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:57<05:58,  4.16s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [01:00<05:20,  3.77s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [01:04<05:25,  3.88s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [01:06<04:48,  3.48s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [01:10<04:44,  3.47s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [01:13<04:31,  3.35s/it]\u001b[A\n",
      " 20%|██        | 20/100 [01:16<04:28,  3.35s/it]\u001b[A\n",
      " 21%|██        | 21/100 [01:20<04:28,  3.40s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [01:23<04:27,  3.43s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [01:27<04:29,  3.50s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [01:31<04:35,  3.62s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [01:35<04:35,  3.67s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [01:38<04:31,  3.67s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [01:42<04:23,  3.62s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [01:45<04:15,  3.54s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [01:49<04:13,  3.57s/it]\u001b[A\n",
      " 30%|███       | 30/100 [01:52<04:04,  3.49s/it]\u001b[A\n",
      " 31%|███       | 31/100 [01:56<04:06,  3.57s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [02:00<04:15,  3.76s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [02:04<04:13,  3.79s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [02:08<04:15,  3.87s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [02:12<04:20,  4.01s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [02:16<04:16,  4.01s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [02:21<04:26,  4.23s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [02:27<04:44,  4.58s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [02:30<04:12,  4.14s/it]\u001b[A\n",
      " 40%|████      | 40/100 [02:34<04:15,  4.26s/it]\u001b[A\n",
      " 41%|████      | 41/100 [02:39<04:24,  4.48s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [02:43<04:02,  4.19s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [02:46<03:41,  3.89s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [02:49<03:31,  3.77s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [02:54<03:39,  4.00s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [02:58<03:32,  3.93s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [03:02<03:27,  3.91s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [03:06<03:37,  4.18s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [03:10<03:19,  3.92s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [03:13<03:04,  3.69s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [03:18<03:19,  4.06s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [03:21<03:06,  3.89s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [03:26<03:16,  4.18s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [03:30<03:09,  4.11s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [03:34<03:04,  4.10s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [03:39<03:08,  4.29s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [03:43<03:01,  4.23s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [03:47<03:00,  4.29s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [03:52<03:04,  4.49s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [03:56<02:44,  4.11s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [04:00<02:48,  4.33s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [04:04<02:41,  4.24s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [04:08<02:33,  4.15s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [04:12<02:24,  4.01s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [04:16<02:16,  3.90s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [04:20<02:17,  4.06s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [04:24<02:10,  3.95s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [04:27<01:58,  3.69s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [04:31<02:00,  3.88s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [04:36<02:03,  4.13s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [04:39<01:53,  3.92s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [04:43<01:47,  3.84s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [04:47<01:41,  3.75s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [04:53<01:56,  4.48s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [04:56<01:41,  4.05s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [04:59<01:32,  3.86s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [05:02<01:24,  3.66s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [05:05<01:12,  3.28s/it]\u001b[A\n",
      " 79%|███████▉  | 79/100 [05:08<01:09,  3.29s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [05:11<01:03,  3.16s/it]\u001b[A\n",
      " 81%|████████  | 81/100 [05:14<00:56,  2.97s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [05:17<00:58,  3.24s/it]\u001b[A\n",
      " 83%|████████▎ | 83/100 [05:21<00:57,  3.37s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [05:27<01:04,  4.06s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [05:31<01:03,  4.26s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [05:36<01:02,  4.44s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [05:43<01:04,  4.97s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [05:46<00:54,  4.52s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [05:51<00:50,  4.62s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [05:54<00:42,  4.25s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [05:58<00:37,  4.11s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [06:02<00:32,  4.06s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [06:05<00:26,  3.76s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [06:08<00:21,  3.63s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [06:12<00:18,  3.67s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [06:15<00:14,  3.57s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [06:19<00:11,  3.68s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [06:23<00:07,  3.63s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [06:26<00:03,  3.55s/it]\u001b[A\n",
      "100%|██████████| 100/100 [06:31<00:00,  3.92s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Mean 827.45\n",
      "Inter Quantile Mean 804.64\n",
      "Inter Quantile STD 33.7371351142074\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_envs=1\n",
    "\n",
    "#env = gym.vector.make(f\"{env_name}NoFrameskip-v4\", num_envs=num_envs, render_mode='human')\n",
    "env = gym.vector.make(f\"{env_name}NoFrameskip-v4\", num_envs=num_envs)\n",
    "env = MaxLast2FrameSkipWrapper(env,seed=SEED)\n",
    "\n",
    "def eval_phase(eval_runs=50, max_eval_steps=27000, num_envs=1):\n",
    "    progress_bar = tqdm.tqdm(total=eval_runs)\n",
    "    \n",
    "    scores=[]\n",
    "    \n",
    "    state, info = env.reset()\n",
    "    state = preprocess(state)\n",
    "    print(f\"init state {state.shape}\")\n",
    "    \n",
    "    states = deque(maxlen=4)\n",
    "    for i in range(4):\n",
    "        states.append(state)\n",
    "    \n",
    "    \n",
    "    eps_reward=torch.tensor([0]*num_envs, dtype=torch.float)\n",
    "    \n",
    "    reward=np.array([0]*num_envs)\n",
    "    terminated=np.array([False]*num_envs)\n",
    "    \n",
    "    last_lives=np.array([0]*num_envs)\n",
    "    life_loss=np.array([0]*num_envs)\n",
    "    resetted=np.array([0])\n",
    "\n",
    "    finished_envs=np.array([False]*num_envs)\n",
    "    done_flag=0\n",
    "    last_grad_update=0\n",
    "    eval_run=0\n",
    "    step=np.array([0]*num_envs)\n",
    "    while eval_run<eval_runs:\n",
    "        #seed_np_torch(SEED+eval_run)\n",
    "        env.seed=SEED+eval_run\n",
    "        model_target.train()\n",
    "        \n",
    "        #if resetted[0]>0:\n",
    "        #    states = env.noop_steps(states)\n",
    "        \n",
    "        Q_action = model_target.env_step(torch.cat(list(states),-3).unsqueeze(0))\n",
    "        action = epsilon_greedy(Q_action.squeeze(), 5000, 0.0005, num_envs).cpu()\n",
    "        \n",
    "        state, reward, terminated, truncated, info = env.step([action.numpy()] if num_envs==1 else action.numpy())\n",
    "        state = preprocess(state)\n",
    "        states.append(state)\n",
    "        \n",
    "        eps_reward+=reward\n",
    "\n",
    "        \n",
    "        done_flag = np.logical_or(terminated, truncated)\n",
    "        lives = info['lives']\n",
    "        life_loss = (last_lives-lives).clip(min=0)\n",
    "        resetted = (lives-last_lives).clip(min=0)\n",
    "        last_lives = lives        \n",
    "        \n",
    "        step+=1\n",
    "        \n",
    "        log_t = done_flag.astype(float).nonzero()[0]\n",
    "        if len(log_t)>0:# or (step>max_eval_steps).any():\n",
    "            progress_bar.update(1)\n",
    "            for log in log_t:\n",
    "                \n",
    "                if finished_envs[log]==False:\n",
    "                    scores.append(eps_reward[log].clone())\n",
    "                    eval_run+=1\n",
    "                    #finished_envs[log]=True\n",
    "                step[log]=0\n",
    "                \n",
    "            eps_reward[log_t]=0            \n",
    "            for i, log in enumerate(step>max_eval_steps):\n",
    "                if log==True and finished_envs[i]==False:\n",
    "                    scores.append(eps_reward[i].clone())\n",
    "                    step[i]=0\n",
    "                    eval_run+=1\n",
    "                    eps_reward[i]=0\n",
    "                    #finished_envs[i]=True\n",
    "            \n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "def eval(eval_runs=50, max_eval_steps=27000, num_envs=1):\n",
    "    assert num_envs==1, 'The code for num eval envs > 1 is messed up.'\n",
    "    \n",
    "    scores = eval_phase(eval_runs, max_eval_steps, num_envs)    \n",
    "    scores = torch.stack(scores)\n",
    "    scores, _ = scores.sort()\n",
    "    \n",
    "    _25th = eval_runs//4\n",
    "\n",
    "    iq = scores[_25th:-_25th]\n",
    "    iqm = iq.mean()\n",
    "    iqs = iq.std()\n",
    "\n",
    "    print(f\"Scores Mean {scores.mean()}\")\n",
    "    print(f\"Inter Quantile Mean {iqm}\")\n",
    "    print(f\"Inter Quantile STD {iqs}\")\n",
    "\n",
    "    \n",
    "    plt.xlabel('Episode (Sorted by Reward)')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.plot(scores)\n",
    "    \n",
    "    new_row = {'env_name': env_name, 'mean': scores.mean().item(), 'iqm': iqm.item(), 'std': iqs.item(), 'seed': SEED}\n",
    "    add_to_csv('results.csv', new_row)\n",
    "\n",
    "    with open(f'results/{env_name}-{SEED}.txt', 'w') as f:\n",
    "        f.write(f\" Scores Mean {scores.mean()}\\n Inter Quantile Mean {iqm}\\n Inter Quantile STD {iqs}\")\n",
    "    \n",
    "    \n",
    "    return scores\n",
    "\n",
    "scores = eval(eval_runs=100, num_envs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57556912-f811-4eb5-9030-f8f77e3962ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
