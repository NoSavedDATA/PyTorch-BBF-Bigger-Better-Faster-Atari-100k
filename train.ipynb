{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57cb10b8-6556-487a-80d5-7f5b165b996a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\diffusers\\utils\\outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msnykralafk\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\sneep\\Python\\bbf\\wandb\\run-20240219_222619-4kszhyr6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/snykralafk/Atari-100k/runs/4kszhyr6' target=\"_blank\">BBF</a></strong> to <a href='https://wandb.ai/snykralafk/Atari-100k' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/snykralafk/Atari-100k' target=\"_blank\">https://wandb.ai/snykralafk/Atari-100k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/snykralafk/Atari-100k/runs/4kszhyr6' target=\"_blank\">https://wandb.ai/snykralafk/Atari-100k/runs/4kszhyr6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count, chain\n",
    "import tqdm\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "\n",
    "from nosaveddata.builders.mlp import *\n",
    "from nosaveddata.builders.weight_init import *\n",
    "from nosaveddata.nsd_utils.networks import params_count, params_and_grad_norm, seed_np_torch\n",
    "from nosaveddata.builders.resnet import IMPALA_Resnet, DQN_Conv\n",
    "\n",
    "\n",
    "from utils.experience_replay import *\n",
    "\n",
    "\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "\n",
    "\n",
    "import wandb\n",
    "wandb.init(\n",
    "    project=\"Atari-100k\",\n",
    "    name=f\"BBF\",\n",
    "\n",
    "    #id='rotdmtc5',\n",
    "    #resume='must',\n",
    "\n",
    "    config={\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"architecture\": \"BBF\",\n",
    "        \"dataset\": \"Assault\",\n",
    "        \"epochs\": 100,\n",
    "    },\n",
    "\n",
    "    reinit=False\n",
    ")\n",
    "\n",
    "\n",
    "# Environment configuration\n",
    "env_name = 'Assault'\n",
    "SEED = 7783\n",
    "\n",
    "\n",
    "# Optimization\n",
    "batch_size = 32\n",
    "lr=1e-4\n",
    "\n",
    "eps=1e-8\n",
    "\n",
    "\n",
    "# Target network EMA rate\n",
    "critic_ema_decay=0.995\n",
    "\n",
    "\n",
    "# Return function\n",
    "initial_gamma=torch.tensor(1-0.97).log()\n",
    "final_gamma=torch.tensor(1-0.997).log()\n",
    "\n",
    "initial_n = 10\n",
    "final_n = 3\n",
    "\n",
    "num_buckets=51\n",
    "\n",
    "\n",
    "# Reset Schedule and Buffer\n",
    "reset_every=40000 # grad steps, not steps.\n",
    "schedule_max_step=reset_every//4\n",
    "total_steps=100000\n",
    "\n",
    "prefetch_cap=1 # actually, no prefetch is being done\n",
    "\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'reward', 'action', 'c_flag'))\n",
    "memory = PrioritizedReplay_nSteps_Sqrt(100005, total_steps=schedule_max_step, prefetch_cap=prefetch_cap)\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint(net, model_target, optimizer, step, path):\n",
    "    torch.save({\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'model_target_state_dict': model_target.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'step': step,\n",
    "            }, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c831907e-0868-4915-bc34-3d1dd1fe363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxLast2FrameSkipWrapper(gym.Wrapper):\n",
    "    def __init__(self, env, skip=4, seed=0):\n",
    "        super().__init__(env)\n",
    "        self.seed = seed\n",
    "        self.skip = skip\n",
    "        self.env.action_space.seed(seed)\n",
    "        \n",
    "    def reset(self, **kwargs):\n",
    "        kwargs[\"seed\"] = self.seed\n",
    "        obs, _ = self.env.reset(**kwargs)\n",
    "        return obs, _\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0\n",
    "        self.obs_buffer = deque(maxlen=2)\n",
    "        for _ in range(self.skip):\n",
    "            obs, reward, done, truncated, info = self.env.step(action)\n",
    "            self.obs_buffer.append(obs)\n",
    "            total_reward += reward\n",
    "\n",
    "            terminated = np.logical_or(done, truncated)\n",
    "            #if terminated.any():\n",
    "            #    for i in range(len(terminated)):\n",
    "            #       obs[i] = self.reset()[0][i]\n",
    "            if done or truncated:\n",
    "                break\n",
    "        if len(self.obs_buffer) == 1:\n",
    "            obs = self.obs_buffer[0]\n",
    "        else:\n",
    "            obs = np.max(np.stack(self.obs_buffer), axis=0)\n",
    "        return obs, total_reward, done, truncated, info\n",
    "\n",
    "\n",
    "env = gym.vector.make(f\"{env_name}NoFrameskip-v4\", num_envs=1)\n",
    "env = MaxLast2FrameSkipWrapper(env,seed=SEED)\n",
    "\n",
    "\n",
    "#n_actions = env.action_space.n\n",
    "n_actions = env.action_space[0].n\n",
    "\n",
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "seed_np_torch(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8d429f2-aee0-4c6b-b221-d2a8b09b0e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 35.21M\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 35.21M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def renormalize(tensor, has_batch=False):\n",
    "    shape = tensor.shape\n",
    "    tensor = tensor.view(tensor.shape[0], -1)\n",
    "    max_value,_ = torch.max(tensor, -1, keepdim=True)\n",
    "    min_value,_ = torch.min(tensor, -1, keepdim=True)\n",
    "    return ((tensor - min_value) / (max_value - min_value + 1e-5)).view(shape)\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, n_actions, hiddens=2048, mlp_layers=1, scale_width=4,\n",
    "                 n_atoms=51, Vmin=-10, Vmax=10):\n",
    "        super().__init__()\n",
    "        self.support = torch.linspace(Vmin, Vmax, n_atoms).cuda()\n",
    "        \n",
    "        self.hiddens=hiddens\n",
    "        self.scale_width=scale_width\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "        \n",
    "        self.encoder_cnn = IMPALA_Resnet(scale_width=scale_width, norm=False, init=init_relu, act=self.act)\n",
    "        \n",
    "        \n",
    "        #self.projection = MLP(10368, med_hiddens=hiddens, out_hiddens=hiddens,\n",
    "        self.projection = MLP(13824, med_hiddens=hiddens, out_hiddens=hiddens,\n",
    "                              in_act=nn.Identity(), init=init_xavier,\n",
    "                              last_init=init_relu, layers=1)\n",
    "        self.prediction = MLP(hiddens, out_hiddens=hiddens, layers=1, last_init=init_relu)\n",
    "                                              \n",
    "        self.transition = nn.Sequential(DQN_Conv(128+n_actions, 128, 3, 1, 1, norm=False, init=init_xavier, act=self.act),\n",
    "                                        DQN_Conv(128, 128, 3, 1, 1, norm=False, init=init_relu, act=self.act))\n",
    "\n",
    "\n",
    "        self.a = MLP(hiddens, out_hiddens=n_actions*num_buckets, layers=1, in_act=self.act, last_init=init_orth)\n",
    "        self.v = MLP(hiddens, out_hiddens=num_buckets, layers=1, in_act=self.act, last_init=init_orth)\n",
    "    \n",
    "        params_count(self, 'DQN')\n",
    "    \n",
    "    def forward(self, X, y_action):\n",
    "        X, z = self.encode(X)\n",
    "        \n",
    "        \n",
    "        q, action = self.q_head(X)\n",
    "        z_pred = self.get_transition(z, y_action)\n",
    "\n",
    "        return q, action, X[:,1:].clone().detach(), z_pred\n",
    "    \n",
    "\n",
    "    def env_step(self, X):\n",
    "        with torch.no_grad():\n",
    "            X, _ = self.encode(X)\n",
    "            _, action = self.q_head(X)\n",
    "            \n",
    "            return action.detach()\n",
    "    \n",
    "\n",
    "    def encode(self, X):\n",
    "        batch, seq = X.shape[:2]\n",
    "        self.batch = batch\n",
    "        self.seq = seq\n",
    "        X = self.encoder_cnn(X.contiguous().view(self.batch*self.seq, *(X.shape[2:])))\n",
    "        X = renormalize(X).contiguous().view(self.batch, self.seq, *X.shape[-3:])\n",
    "        X = X.contiguous().view(self.batch, self.seq, *X.shape[-3:])\n",
    "        z = X.clone()\n",
    "        X = X.flatten(-3,-1)\n",
    "        X = self.projection(X)\n",
    "        return X, z\n",
    "\n",
    "    def get_transition(self, z, action):\n",
    "        z = z.contiguous().view(-1, *z.shape[-3:])\n",
    "        \n",
    "        action = F.one_hot(action.clone(), n_actions).view(-1, n_actions)\n",
    "        action = action.view(-1, 5, n_actions, 1, 1).expand(-1, 5, n_actions, *z.shape[-2:])\n",
    "\n",
    "        \n",
    "        z_pred = torch.cat( (z, action[:,0]), 1)\n",
    "        z_pred = self.transition(z_pred)\n",
    "        z_pred = renormalize(z_pred)\n",
    "        \n",
    "        z_preds=[z_pred.clone()]\n",
    "        \n",
    "\n",
    "        for k in range(4):\n",
    "            z_pred = torch.cat( (z_pred, action[:,k+1]), 1)\n",
    "            z_pred = self.transition(z_pred)\n",
    "            z_pred = renormalize(z_pred)\n",
    "            \n",
    "            z_preds.append(z_pred)\n",
    "        \n",
    "        \n",
    "        z_pred = torch.stack(z_preds,1)\n",
    "\n",
    "        z_pred = self.projection(z_pred.flatten(-3,-1)).view(self.batch,5,-1)\n",
    "        z_pred = self.prediction(z_pred)\n",
    "        \n",
    "        return z_pred\n",
    "\n",
    "    \n",
    "    def q_head(self, X):\n",
    "        q = self.dueling_dqn(X)\n",
    "        action = (q*self.support).sum(-1).argmax(-1)\n",
    "        \n",
    "        return q, action\n",
    "\n",
    "    def get_max_action(self, X):\n",
    "        with torch.no_grad():\n",
    "            X, _ = self.encode(X)\n",
    "            q = self.dueling_dqn(X)\n",
    "            \n",
    "            action = (q*self.support).sum(-1).argmax(-1)\n",
    "            return action\n",
    "\n",
    "    def evaluate(self, X, action):\n",
    "        with torch.no_grad():\n",
    "            X, _ = self.encode(X)\n",
    "            \n",
    "            q = self.dueling_dqn(X)\n",
    "            \n",
    "            action = action[:,:,None,None].expand_as(q)[:,:,0][:,:,None]\n",
    "            q = q.gather(-2,action)\n",
    "            \n",
    "            return q\n",
    "\n",
    "    def dueling_dqn(self, X):\n",
    "        X = F.relu(X)\n",
    "        \n",
    "        a = self.a(X).view(self.batch, -1, n_actions, num_buckets)\n",
    "        v = self.v(X).view(self.batch, -1, 1, num_buckets)\n",
    "        \n",
    "        q = v + a - a.mean(-2,keepdim=True)\n",
    "        q = F.softmax(q,-1)\n",
    "        \n",
    "        return q\n",
    "    \n",
    "    def network_ema(self, rand_network, target_network, alpha=0.5):\n",
    "        for param, param_target in zip(rand_network.parameters(), target_network.parameters()):\n",
    "            param_target.data = alpha * param_target.data + (1 - alpha) * param.data.clone()\n",
    "\n",
    "    def hard_reset(self, random_model, alpha=0.5):\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            self.network_ema(random_model.encoder_cnn, self.encoder_cnn, alpha)\n",
    "            self.network_ema(random_model.transition, self.transition, alpha)\n",
    "\n",
    "            self.network_ema(random_model.projection, self.projection, 0)\n",
    "            self.network_ema(random_model.prediction, self.prediction, 0)\n",
    "\n",
    "            self.network_ema(random_model.a, self.a, 0)\n",
    "            self.network_ema(random_model.v, self.v, 0)\n",
    "\n",
    "\n",
    "\n",
    "def copy_states(source, target):\n",
    "    for key, _ in zip(source.state_dict()['state'].keys(), target.state_dict()['state'].keys()):\n",
    "\n",
    "        target.state_dict()['state'][key]['exp_avg_sq'] = copy.deepcopy(source.state_dict()['state'][key]['exp_avg_sq'])\n",
    "        target.state_dict()['state'][key]['exp_avg'] = copy.deepcopy(source.state_dict()['state'][key]['exp_avg'])\n",
    "        target.state_dict()['state'][key]['step'] = copy.deepcopy(source.state_dict()['state'][key]['step'])\n",
    "        \n",
    "def target_model_ema(model, model_target):\n",
    "    with torch.no_grad():\n",
    "        for param, param_target in zip(model.parameters(), model_target.parameters()):\n",
    "            param_target.data = critic_ema_decay * param_target.data + (1.0 - critic_ema_decay) * param.data.clone()\n",
    "\n",
    "\n",
    "    \n",
    "model=DQN(n_actions).cuda()\n",
    "model_target=DQN(n_actions).cuda()\n",
    "\n",
    "model_target.load_state_dict(model.state_dict())\n",
    "\n",
    "\n",
    "# Testing only\n",
    "#with torch.no_grad():\n",
    "#    q, action, X, z_pred = model(torch.randn(4,1,12,96,72, device='cuda', dtype=torch.float), torch.randint(0,n_actions,(4,5),device='cuda').long())\n",
    "#z = model.encode(torch.randn(4,5,12,96,72, device='cuda'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ca1d0e5-d128-428b-bcbc-be68dccc005c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model number of parameters: 35.21M\n",
      "\n"
     ]
    }
   ],
   "source": [
    "perception_modules=[model.encoder_cnn, model.transition]\n",
    "actor_modules=[model.prediction, model.projection, model.a, model.v]\n",
    "\n",
    "params_wm=[]\n",
    "for module in perception_modules:\n",
    "    for param in module.parameters():\n",
    "        if param.requires_grad==True: # They all require grad\n",
    "            params_wm.append(param)\n",
    "\n",
    "params_ac=[]\n",
    "for module in actor_modules:\n",
    "    for param in module.parameters():\n",
    "        if param.requires_grad==True:\n",
    "            params_ac.append(param)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(chain(params_wm, params_ac),\n",
    "                                lr=lr, weight_decay=0.1, eps=1.5e-4)\n",
    "\n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr*1.2,\n",
    "#                     total_steps=100000//initial_n//batch_size*16)\n",
    "\n",
    "\n",
    "params_to_count = [p for p in model.parameters() if p.requires_grad]\n",
    "print()\n",
    "print(f'Model number of parameters: {sum(p.numel() for p in params_to_count)/1e6:.2f}M')\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7f2a7d7-81c6-4c93-8cbe-1f15fa75af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "                         transforms.Resize((96,72)),\n",
    "                        ])\n",
    "\n",
    "\n",
    "def preprocess(state):\n",
    "    state=torch.tensor(state, dtype=torch.float, device='cuda') / 255\n",
    "    state=train_tfms(state.permute(0,3,1,2))\n",
    "    return state\n",
    "\n",
    "\n",
    "def linearly_decaying_epsilon(decay_period, step, warmup_steps, epsilon):\n",
    "    steps_left = decay_period + warmup_steps - step\n",
    "    bonus = (1.0 - epsilon) * steps_left / decay_period\n",
    "    bonus = np.clip(bonus, 0., 1. - epsilon)\n",
    "    return epsilon + bonus\n",
    "\n",
    "\n",
    "def epsilon_greedy(Q_action, step, final_eps=0, num_envs=1):\n",
    "    epsilon = linearly_decaying_epsilon(2001, step, 2000, final_eps)\n",
    "    \n",
    "    if random.random() < epsilon:\n",
    "        action = torch.randint(0, n_actions, (num_envs,), dtype=torch.int64, device='cuda').squeeze(0)\n",
    "    else:\n",
    "        action = Q_action.view(num_envs).squeeze(0).to(torch.int64)\n",
    "    return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6722829c-d4bc-4d9f-aa35-80f6133a4819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/google/dopamine/blob/master/dopamine/jax/agents/rainbow/rainbow_agent.py\n",
    "def project_distribution(supports, weights, target_support):\n",
    "    with torch.no_grad():\n",
    "        v_min, v_max = target_support[0], target_support[-1]\n",
    "        # `N` in Eq7.\n",
    "        num_dims = target_support.shape[-1]\n",
    "        # delta_z = `\\Delta z` in Eq7.\n",
    "        delta_z = (v_max - v_min) / (num_buckets-1)\n",
    "        # clipped_support = `[\\hat{T}_{z_j}]^{V_max}_{V_min}` in Eq7.\n",
    "        clipped_support = supports.clip(v_min, v_max)\n",
    "        # numerator = `|clipped_support - z_i|` in Eq7.\n",
    "        numerator = (clipped_support[:,None] - target_support[None,:,None].repeat_interleave(clipped_support.shape[0],0)).abs()\n",
    "        quotient = 1 - (numerator / delta_z)\n",
    "        # clipped_quotient = `[1 - numerator / (\\Delta z)]_0^1` in Eq7.\n",
    "        clipped_quotient = quotient.clip(0, 1)\n",
    "        # inner_prod = `\\sum_{j=0}^{N-1} clipped_quotient * p_j(x', \\pi(x'))` in Eq7.\n",
    "        inner_prod = (clipped_quotient * weights[:,None]).sum(-1)\n",
    "        #inner_prod = (clipped_quotient).sum(-1) * weights\n",
    "        return inner_prod.squeeze()\n",
    "\n",
    "\n",
    "mse = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "def optimize(step, grad_step, n):\n",
    "        \n",
    "    model.train()\n",
    "    #model_target.eval()\n",
    "    model_target.train()\n",
    "\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.bfloat16, enabled=False):\n",
    "        with torch.no_grad():\n",
    "            states, next_states, rewards, action, c_flag, idxs, is_w = memory.sample(n, batch_size, grad_step)\n",
    "        terminal=1-c_flag\n",
    "        #print(f\"STUFF HERE {states.shape, rewards.shape, c_flag.shape, action.shape, n}\")\n",
    "    \n",
    "    \n",
    "        q, max_action, z, z_pred = model(states[:,0][:,None], action[:,:5].long())\n",
    "        z = model_target.encode(states[:,1:6])[0].detach()\n",
    "\n",
    "        # They actually use n-1 for next states.\n",
    "        max_action  = model.get_max_action(next_states[:,n][:,None])\n",
    "        next_values = model_target.evaluate(next_states[:,n][:,None].contiguous(), max_action)\n",
    "        \n",
    "\n",
    "        action = action[:,0,None].expand(batch_size,num_buckets)\n",
    "        action=action[:,None]\n",
    "        with torch.no_grad():\n",
    "            gammas_one=torch.ones(batch_size,n,1,dtype=torch.float,device='cuda')\n",
    "            gamma_step = 1-torch.tensor(( (schedule_max_step - min(grad_step, schedule_max_step)) / schedule_max_step) * (initial_gamma-final_gamma) + final_gamma).exp()\n",
    "            gammas=gammas_one*gamma_step\n",
    "\n",
    "            \n",
    "            returns = []\n",
    "            for t in range(n):\n",
    "                ret = 0\n",
    "                for u in reversed(range(t, n)):\n",
    "                    ret += torch.prod(c_flag[:,t+1:u+1],-2)*torch.prod(gammas[:,t:u],-2)*rewards[:,u+1]\n",
    "                returns.append(ret)\n",
    "            returns = torch.stack(returns,1)\n",
    "        \n",
    "        plot_vs = returns.clone().sum(-1)\n",
    "        \n",
    "        same_traj = (torch.prod(c_flag[:,:n],-2)).squeeze()\n",
    "        \n",
    "        returns = returns[:,0]\n",
    "        returns = returns + torch.prod(gammas[0,:10],-2).squeeze()*same_traj[:,None]*model.support[None,:]\n",
    "        returns = returns.squeeze()\n",
    "        \n",
    "        next_values = next_values[:,0]\n",
    "\n",
    "        log_probs = torch.log(q[:,0].gather(-2, action)[:,None] + eps).contiguous()\n",
    "        \n",
    "        \n",
    "        dist = project_distribution(returns, next_values.squeeze(), model.support)\n",
    "        \n",
    "        loss = -(dist*(log_probs.squeeze())).sum(-1).view(batch_size,-1).sum(-1)\n",
    "        dqn_loss = loss.clone().mean()\n",
    "        td_error = (loss + torch.nan_to_num((dist*torch.log(dist))).sum(-1)).mean()\n",
    "\n",
    "        \n",
    "        batched_loss = loss.clone()\n",
    "        \n",
    "        \n",
    "        z = F.normalize(z, 2, dim=-1, eps=1e-5)\n",
    "        z_pred = F.normalize(z_pred, 2, dim=-1, eps=1e-5)\n",
    "\n",
    "        #z_mask = z_mask[:,:,:5]\n",
    "        #z_mask = z_mask.contiguous().view(5,-1).cuda()\n",
    "        #recon_loss = (mse(z_pred.contiguous().view(5,-1,2048), z.contiguous().view(-1,2048).unsqueeze(0).repeat_interleave(5,0))).sum(-1)*z_mask\n",
    "        #recon_loss = 5*((recon_loss.mean(0).view(batch_size,-1))*same_traj[:,None]).sum(-1)\n",
    "        \n",
    "        recon_loss = (mse(z_pred.contiguous().view(-1,2048), z.contiguous().view(-1,2048))).sum(-1)\n",
    "        recon_loss = 5*(recon_loss.view(batch_size, -1).mean(-1))*same_traj\n",
    "        \n",
    "        \n",
    "        loss += recon_loss\n",
    "        \n",
    "        loss = (loss*is_w).mean() # mean across batch axis\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    param_norm, grad_norm = params_and_grad_norm(model)\n",
    "    #scaler.scale(loss).backward()\n",
    "    #scaler.unscale_(optimizer)\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "    #scaler.step(optimizer)\n",
    "    #scaler.update()\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #memory.set_priority(idxs, batched_loss)\n",
    "    memory.set_priority(idxs, batched_loss, same_traj)\n",
    "    \n",
    "    \n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    wandb.log({'loss': loss, 'dqn_loss': dqn_loss, 'recon_loss': recon_loss.mean(), 'lr': lr, 'returns': plot_vs.mean(),\n",
    "               'rewards': rewards.mean(0).sum(), 'is_w': is_w.mean(),\n",
    "               'gamma': gamma_step, 'td_error': td_error, 'param_norm': param_norm.sum(), 'grad_norm': grad_norm.sum()})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scores=[]\n",
    "memory.free()\n",
    "step=0\n",
    "#model.share_memory()\n",
    "grad_step=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05991348-a11a-43bd-882f-02df107fc543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1975/100002 [00:07<05:14, 311.72it/s]C:\\Users\\sneep\\AppData\\Local\\Temp\\ipykernel_5152\\2221393133.py:96: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gamma_step = 1-torch.tensor(( (schedule_max_step - min(grad_step, schedule_max_step)) / schedule_max_step) * (initial_gamma-final_gamma) + final_gamma).exp()\n",
      "  6%|▋         | 6438/100002 [11:31<3:33:54,  7.29it/s]\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "step=0\n",
    "\n",
    "progress_bar = tqdm.tqdm(total=100002)\n",
    "\n",
    "while step<(10):\n",
    "    state, info = env.reset()\n",
    "    state = preprocess(state)\n",
    "\n",
    "    stacked = state.repeat_interleave(3,1)\n",
    "    state = torch.cat((stacked.clone(), state),1)\n",
    "    \n",
    "    \n",
    "    eps_reward=torch.tensor([0], dtype=torch.float)\n",
    "    \n",
    "    reward=np.array([0])\n",
    "    done_flag=np.array([False])\n",
    "    terminated=np.array([False])\n",
    "\n",
    "    last_lives=np.array([0])\n",
    "    life_loss=np.array([0])\n",
    "    \n",
    "    last_grad_update=0\n",
    "    while step<(total_steps):\n",
    "        progress_bar.update(1)\n",
    "        model_target.train()\n",
    "        \n",
    "        len_memory = len(memory)\n",
    "        Q_action = model_target.env_step(state.unsqueeze(0))\n",
    "        \n",
    "        action = epsilon_greedy(Q_action, len_memory).cpu()\n",
    "        \n",
    "        memory.push(state.detach().cpu(), reward, action, np.logical_or(done_flag, life_loss))\n",
    "        #print('action', action, action.shape)\n",
    "        \n",
    "        state, reward, terminated, truncated, info = env.step([action.numpy()])\n",
    "        \n",
    "        state = preprocess(state)\n",
    "        eps_reward+=reward\n",
    "        reward = reward.clip(-1, 1)\n",
    "\n",
    "        state = torch.cat((stacked.clone(), state),1)\n",
    "        stacked = torch.cat((stacked[:,3:], state[:,-3:]),1)\n",
    "\n",
    "        \n",
    "        done_flag = np.logical_or(terminated, truncated)\n",
    "        lives = info['lives']\n",
    "        life_loss = (last_lives-lives).clip(min=0)\n",
    "        last_lives = lives\n",
    "\n",
    "        \n",
    "        n = int(initial_n * (final_n/initial_n)**(min(grad_step,schedule_max_step) / schedule_max_step))\n",
    "        n = np.array(n).item()\n",
    "        \n",
    "        memory.priority[len_memory] = memory.max_priority()\n",
    "        \n",
    "\n",
    "        if len_memory>2000:\n",
    "            for i in range(2):\n",
    "                optimize(step, grad_step, n)\n",
    "                target_model_ema(model, model_target)\n",
    "                grad_step+=1\n",
    "\n",
    "        \n",
    "        if ((step+1)%10000)==0:\n",
    "            save_checkpoint(model, model_target, optimizer, step,\n",
    "                            'checkpoints/atari_last.pth')\n",
    "        \n",
    "            \n",
    "        \n",
    "        if grad_step>reset_every:\n",
    "            #eval()\n",
    "            print('Reseting on step', step, grad_step)\n",
    "            \n",
    "            seed_np_torch(random.randint(SEED-1000, SEED+1000))\n",
    "            random_model = DQN(n_actions).cuda()\n",
    "            model.hard_reset(random_model)\n",
    "            \n",
    "            seed_np_torch(random.randint(SEED-1000, SEED+1000))\n",
    "            random_model = DQN(n_actions).cuda()\n",
    "            model_target.hard_reset(random_model)\n",
    "            seed_np_torch(SEED)\n",
    "            \n",
    "            random_model=None\n",
    "            grad_step=0\n",
    "\n",
    "            actor_modules=[model.prediction, model.projection, model.a, model.v]\n",
    "            params_ac=[]\n",
    "            for module in actor_modules:\n",
    "                for param in module.parameters():\n",
    "                    params_ac.append(param)\n",
    "                    \n",
    "\n",
    "            perception_modules=[model.encoder_cnn, model.transition]\n",
    "            params_wm=[]\n",
    "            for module in perception_modules:\n",
    "                for param in module.parameters():\n",
    "                    params_wm.append(param)\n",
    "            \n",
    "            optimizer_aux = torch.optim.AdamW(params_wm, lr=lr, weight_decay=0.1, eps=1.5e-4)\n",
    "            copy_states(optimizer, optimizer_aux)\n",
    "            optimizer = torch.optim.AdamW(chain(params_wm, params_ac),\n",
    "                                lr=lr, weight_decay=0.1, eps=1.5e-4)\n",
    "            copy_states(optimizer_aux, optimizer)\n",
    "            \n",
    "        \n",
    "        \n",
    "        step+=1\n",
    "        \n",
    "        log_t = done_flag.astype(float).nonzero()[0]\n",
    "        \n",
    "        if len(log_t)>0:\n",
    "            for log in log_t:\n",
    "                wandb.log({'eps_reward': eps_reward[log].sum()})\n",
    "                scores.append(eps_reward[log].clone())\n",
    "            eps_reward[log_t]=0\n",
    "\n",
    "save_checkpoint(model, model_target, optimizer, step, f'checkpoints/{env_name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87344597-e733-451c-8a5f-2a00b5511061",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_to_eval=True\n",
    "\n",
    "if load_to_eval:\n",
    "    model.load_state_dict(torch.load(f'checkpoints/{env_name}.pth')['model_state_dict'])\n",
    "    model_target.load_state_dict(torch.load(f'checkpoints/{env_name}.pth')['model_target_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12d36218-ab48-42d9-a7ba-fabb66cc758f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init state torch.Size([1, 3, 96, 72])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|          | 1/100 [00:28<46:44, 28.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 2/100 [00:37<27:43, 16.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 3/100 [00:45<21:15, 13.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 4/100 [00:54<17:59, 11.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 5/100 [01:17<24:41, 15.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 6/100 [01:24<19:56, 12.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 7/100 [01:52<27:30, 17.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 8/100 [02:18<31:16, 20.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 9/100 [02:48<35:19, 23.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 10/100 [02:59<29:17, 19.53s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 11/100 [03:27<32:41, 22.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 12/100 [03:55<34:52, 23.78s/it]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 13/100 [04:21<35:38, 24.58s/it]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 14/100 [04:30<28:20, 19.78s/it]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 15/100 [04:44<25:34, 18.05s/it]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 16/100 [05:11<29:16, 20.91s/it]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 17/100 [05:25<25:46, 18.63s/it]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 18/100 [05:34<21:29, 15.73s/it]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 19/100 [05:56<23:57, 17.74s/it]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 20/100 [06:03<19:24, 14.56s/it]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 21/100 [06:29<23:43, 18.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 22/100 [06:40<20:22, 15.67s/it]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 23/100 [07:09<25:37, 19.96s/it]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 24/100 [07:36<27:52, 22.00s/it]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 25/100 [07:46<22:56, 18.36s/it]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 26/100 [07:55<19:17, 15.65s/it]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 27/100 [08:20<22:20, 18.36s/it]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 28/100 [08:29<18:26, 15.37s/it]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 29/100 [08:55<22:03, 18.64s/it]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 30/100 [09:03<18:12, 15.60s/it]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 31/100 [09:12<15:33, 13.53s/it]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 32/100 [09:30<16:41, 14.73s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 33/100 [09:37<13:58, 12.51s/it]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 34/100 [10:05<18:58, 17.26s/it]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 35/100 [10:24<19:17, 17.82s/it]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 36/100 [10:35<16:36, 15.57s/it]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 37/100 [11:03<20:27, 19.48s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 38/100 [11:12<16:39, 16.12s/it]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 39/100 [11:20<14:06, 13.88s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 40/100 [11:41<15:54, 15.91s/it]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 41/100 [11:50<13:36, 13.83s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 42/100 [12:18<17:32, 18.15s/it]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 43/100 [12:28<14:47, 15.58s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 44/100 [12:58<18:39, 19.99s/it]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 45/100 [13:30<21:43, 23.70s/it]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 46/100 [14:00<23:03, 25.63s/it]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 47/100 [14:25<22:27, 25.42s/it]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 48/100 [14:39<19:06, 22.05s/it]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 49/100 [15:23<24:14, 28.53s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 50/100 [16:03<26:43, 32.07s/it]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 51/100 [16:30<24:44, 30.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 52/100 [16:43<20:11, 25.23s/it]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 53/100 [16:57<17:01, 21.74s/it]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 54/100 [17:27<18:34, 24.23s/it]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 55/100 [17:41<15:50, 21.13s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 56/100 [18:03<15:44, 21.47s/it]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 57/100 [18:31<16:50, 23.50s/it]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 58/100 [19:07<18:57, 27.08s/it]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 59/100 [19:18<15:14, 22.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 60/100 [19:52<17:11, 25.79s/it]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 61/100 [20:02<13:49, 21.27s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 62/100 [20:10<10:53, 17.21s/it]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 63/100 [20:28<10:47, 17.49s/it]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 64/100 [20:37<08:59, 14.98s/it]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 65/100 [21:06<11:12, 19.21s/it]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 66/100 [21:37<12:48, 22.61s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 67/100 [21:50<10:48, 19.66s/it]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 68/100 [22:04<09:35, 18.00s/it]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 69/100 [22:34<11:15, 21.80s/it]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 70/100 [22:59<11:17, 22.57s/it]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 71/100 [23:24<11:19, 23.43s/it]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 72/100 [24:00<12:40, 27.17s/it]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 73/100 [24:17<10:49, 24.05s/it]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 74/100 [24:33<09:19, 21.52s/it]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 75/100 [24:43<07:33, 18.16s/it]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 76/100 [25:14<08:46, 21.93s/it]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 77/100 [25:23<06:59, 18.23s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 78/100 [26:00<08:42, 23.77s/it]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 79/100 [26:29<08:49, 25.22s/it]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 80/100 [26:43<07:22, 22.15s/it]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 81/100 [27:00<06:27, 20.38s/it]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 82/100 [27:09<05:09, 17.18s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 83/100 [27:45<06:23, 22.58s/it]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 84/100 [27:54<04:57, 18.61s/it]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 85/100 [28:29<05:50, 23.40s/it]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 86/100 [28:38<04:28, 19.15s/it]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 87/100 [28:48<03:33, 16.40s/it]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 88/100 [29:22<04:20, 21.74s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 89/100 [29:35<03:31, 19.21s/it]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 90/100 [30:03<03:38, 21.86s/it]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 91/100 [30:37<03:48, 25.39s/it]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 92/100 [31:09<03:38, 27.25s/it]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 93/100 [31:40<03:18, 28.37s/it]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 94/100 [31:49<02:15, 22.56s/it]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 95/100 [32:19<02:05, 25.07s/it]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 96/100 [32:42<01:37, 24.43s/it]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 97/100 [33:10<01:16, 25.51s/it]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 98/100 [33:20<00:41, 20.63s/it]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 99/100 [33:27<00:16, 16.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 100/100 [33:34<00:00, 20.15s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Mean 1918.73\n",
      "Inter Quantile Mean 1905.32\n",
      "Inter Quantile STD 764.6072872223161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_envs=1\n",
    "\n",
    "#env = gym.vector.make(f\"AssaultNoFrameskip-v4\", num_envs=num_envs, render_mode='human')\n",
    "env = gym.vector.make(f\"{env_name}NoFrameskip-v4\", num_envs=num_envs)\n",
    "env = MaxLast2FrameSkipWrapper(env,seed=SEED)\n",
    "\n",
    "def eval_phase(eval_runs=50, max_eval_steps=27000, num_envs=1):\n",
    "    progress_bar = tqdm.tqdm(total=eval_runs)\n",
    "    \n",
    "    scores=[]\n",
    "    \n",
    "    state, info = env.reset()\n",
    "    state = preprocess(state)\n",
    "    print(f\"init state {state.shape}\")\n",
    "    stacked = state.repeat_interleave(3,1)\n",
    "    state = torch.cat((stacked.clone(), state),1)\n",
    "    \n",
    "    \n",
    "    eps_reward=torch.tensor([0]*num_envs, dtype=torch.float)\n",
    "    \n",
    "    reward=np.array([0]*num_envs)\n",
    "    terminated=np.array([False]*num_envs)\n",
    "\n",
    "    last_lives=np.array([0]*num_envs)\n",
    "\n",
    "    finished_envs=np.array([False]*num_envs)\n",
    "    done_flag=0\n",
    "    last_grad_update=0\n",
    "    eval_run=0\n",
    "    step=np.array([0]*num_envs)\n",
    "    while eval_run<eval_runs:\n",
    "        seed_np_torch(SEED+eval_run)\n",
    "        #env.seed=SEED+eval_run\n",
    "\n",
    "        model.train()\n",
    "        model_target.train()\n",
    "        \n",
    "        Q_action = model_target.env_step(state.unsqueeze(0))\n",
    "        action = epsilon_greedy(Q_action.squeeze(), 5000, 0.0005, num_envs).cpu()\n",
    "        \n",
    "        state, reward, terminated, truncated, info = env.step([action.numpy()] if num_envs==1 else action.numpy())\n",
    "        done_flag = np.logical_or(terminated, truncated)\n",
    "        \n",
    "\n",
    "        state = preprocess(state)\n",
    "        eps_reward+=reward\n",
    "\n",
    "\n",
    "        \n",
    "        state = torch.cat((stacked.clone(), state),1)\n",
    "        stacked = torch.cat((stacked[:,3:], state[:,-3:]),1)\n",
    "        \n",
    "        \n",
    "        step+=1\n",
    "        \n",
    "        log_t = done_flag.astype(float).nonzero()[0]\n",
    "        if len(log_t)>0:# or (step>max_eval_steps).any():\n",
    "            progress_bar.update(1)\n",
    "            for log in log_t:\n",
    "                #wandb.log({'eval_eps_reward': eps_reward[log].sum()})\n",
    "                if finished_envs[log]==False:\n",
    "                    scores.append(eps_reward[log].clone())\n",
    "                    eval_run+=1\n",
    "                    #finished_envs[log]=True\n",
    "                step[log]=0\n",
    "                \n",
    "            eps_reward[log_t]=0            \n",
    "            for i, log in enumerate(step>max_eval_steps):\n",
    "                if log==True and finished_envs[i]==False:\n",
    "                    scores.append(eps_reward[i].clone())\n",
    "                    step[i]=0\n",
    "                    eval_run+=1\n",
    "                    eps_reward[i]=0\n",
    "                    #finished_envs[i]=True\n",
    "            \n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "def eval(eval_runs=50, max_eval_steps=27000, num_envs=1):\n",
    "    assert num_envs==1, 'The code for num eval envs > 1 is messed up.'\n",
    "    \n",
    "    scores = eval_phase(eval_runs, max_eval_steps, num_envs)    \n",
    "    scores = torch.stack(scores)\n",
    "    scores, _ = scores.sort()\n",
    "    \n",
    "    _25th = eval_runs//4\n",
    "\n",
    "    iq = scores[_25th:-_25th]\n",
    "    iqm = iq.mean()\n",
    "    iqs = iq.std()\n",
    "\n",
    "    print(f\"Scores Mean {scores.mean()}\")\n",
    "    print(f\"Inter Quantile Mean {iqm}\")\n",
    "    print(f\"Inter Quantile STD {iqs}\")\n",
    "\n",
    "    \n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.plot(scores)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "scores = eval(eval_runs=100, num_envs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cddb4f-7fdd-4b4b-8e62-33d92f4313df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
