{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57cb10b8-6556-487a-80d5-7f5b165b996a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\diffusers\\utils\\outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msnykralafk\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\sneep\\Python\\bbf\\wandb\\run-20240331_215631-lifi1art</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/snykralafk/Atari-100k-BBF/runs/lifi1art' target=\"_blank\">BBF-Asterix</a></strong> to <a href='https://wandb.ai/snykralafk/Atari-100k-BBF' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/snykralafk/Atari-100k-BBF' target=\"_blank\">https://wandb.ai/snykralafk/Atari-100k-BBF</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/snykralafk/Atari-100k-BBF/runs/lifi1art' target=\"_blank\">https://wandb.ai/snykralafk/Atari-100k-BBF/runs/lifi1art</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count, chain\n",
    "import tqdm\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "from nosaveddata.nsd_utils.save_hypers import Hypers, nsd_Module\n",
    "from nosaveddata.nsd_utils.nsd_csv import add_to_csv\n",
    "from nosaveddata.nsd_utils.networks import params_count, params_and_grad_norm, seed_np_torch\n",
    "from nosaveddata.nsd_utils.einstein import Rearrange\n",
    "\n",
    "from nosaveddata.builders.mlp import *\n",
    "from nosaveddata.builders.weight_init import *\n",
    "from nosaveddata.builders.resnet import IMPALA_Resnet, DQN_Conv, IMPALA_YY\n",
    "\n",
    "\n",
    "from utils.experience_replay import *\n",
    "\n",
    "\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "import wandb\n",
    "\n",
    "\n",
    "# Environment configuration\n",
    "#env_name = 'Kangaroo'\n",
    "#SEED = 8712\n",
    "\n",
    "env_name = 'Asterix'\n",
    "SEED = 7785\n",
    "\n",
    "\n",
    "wandb.init(\n",
    "    project=\"Atari-100k-BBF\",\n",
    "    name=f\"BBF-{env_name}\",\n",
    "\n",
    "    #id='rotdmtc5',\n",
    "    #resume='must',\n",
    "\n",
    "    config={\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"architecture\": \"BBF\",\n",
    "        \"dataset\": \"Assault\",\n",
    "        \"epochs\": 100,\n",
    "    },\n",
    "\n",
    "    reinit=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Optimization\n",
    "batch_size = 32\n",
    "lr=1e-4\n",
    "\n",
    "eps=1e-8\n",
    "\n",
    "\n",
    "# Target network EMA rate\n",
    "critic_ema_decay=0.995\n",
    "\n",
    "\n",
    "# Return function\n",
    "initial_gamma=torch.tensor(1-0.97).log()\n",
    "final_gamma=torch.tensor(1-0.997).log()\n",
    "\n",
    "initial_n = 10\n",
    "final_n = 3\n",
    "\n",
    "num_buckets=51\n",
    "\n",
    "\n",
    "# Reset Schedule and Buffer\n",
    "reset_every=40000 # grad steps, not steps.\n",
    "schedule_max_step=reset_every//4\n",
    "total_steps=102000\n",
    "\n",
    "prefetch_cap=1 # actually, no prefetch is being done\n",
    "\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'reward', 'action', 'c_flag'))\n",
    "memory = PrioritizedReplay_nSteps_Sqrt(total_steps+5, total_steps=schedule_max_step, prefetch_cap=prefetch_cap)\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint(net, model_target, optimizer, step, path):\n",
    "    torch.save({\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'model_target_state_dict': model_target.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'step': step,\n",
    "            }, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c831907e-0868-4915-bc34-3d1dd1fe363c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\gymnasium\\vector\\__init__.py:53: UserWarning: \u001b[33mWARN: `gymnasium.vector.make(...)` is deprecated and will be replaced by `gymnasium.make_vec(...)` in v1.0\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# Adapted from: https://github.com/weipu-zhang/STORM/blob/main/env_wrapper.py\n",
    "class MaxLast2FrameSkipWrapper(Hypers, gym.Wrapper):\n",
    "    def __init__(self, env, skip=4, noops=30, seed=0):\n",
    "        super().__init__(env=env)\n",
    "        self.env.action_space.seed(seed)\n",
    "        \n",
    "    def reset(self, **kwargs):\n",
    "        kwargs[\"seed\"] = self.seed\n",
    "        obs, _ = self.env.reset(**kwargs)\n",
    "\n",
    "        return obs, _\n",
    "        \n",
    "    def noop_steps(self, states):\n",
    "        noops = random.randint(0,self.noops)\n",
    "        \n",
    "        for i in range(noops):\n",
    "            state = self.step(np.array([0]))[0]\n",
    "            state = preprocess(state)\n",
    "            states.append(state)\n",
    "        return states\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0\n",
    "        self.obs_buffer = deque(maxlen=2)\n",
    "        for _ in range(self.skip):\n",
    "            obs, reward, done, truncated, info = self.env.step(action)\n",
    "            self.obs_buffer.append(obs)\n",
    "            total_reward += reward\n",
    "\n",
    "            terminated = np.logical_or(done, truncated)\n",
    "            #if terminated.any():\n",
    "            #    for i in range(len(terminated)):\n",
    "            #       obs[i] = self.reset()[0][i]\n",
    "            if done or truncated:\n",
    "                break\n",
    "        if len(self.obs_buffer) == 1:\n",
    "            obs = self.obs_buffer[0]\n",
    "        else:\n",
    "            obs = np.max(np.stack(self.obs_buffer), axis=0)\n",
    "        return obs, total_reward, done, truncated, info\n",
    "        # Life loss is calculated on the training code\n",
    "\n",
    "env = gym.vector.make(f\"{env_name}NoFrameskip-v4\", num_envs=1)\n",
    "env = MaxLast2FrameSkipWrapper(env,seed=SEED)\n",
    "\n",
    "\n",
    "#n_actions = env.action_space.n\n",
    "n_actions = env.action_space[0].n\n",
    "\n",
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "seed_np_torch(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8d429f2-aee0-4c6b-b221-d2a8b09b0e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 35.42M\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 35.42M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def renormalize(tensor, has_batch=False):\n",
    "    shape = tensor.shape\n",
    "    tensor = tensor.view(tensor.shape[0], -1)\n",
    "    max_value,_ = torch.max(tensor, -1, keepdim=True)\n",
    "    min_value,_ = torch.min(tensor, -1, keepdim=True)\n",
    "    return ((tensor - min_value) / (max_value - min_value + 1e-5)).view(shape)\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, n_actions, hiddens=2048, mlp_layers=1, scale_width=4,\n",
    "                 n_atoms=51, Vmin=-10, Vmax=10):\n",
    "        super().__init__()\n",
    "        self.support = torch.linspace(Vmin, Vmax, n_atoms).cuda()\n",
    "        \n",
    "        self.hiddens=hiddens\n",
    "        self.scale_width=scale_width\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "        \n",
    "        self.encoder_cnn = IMPALA_Resnet(scale_width=scale_width, norm=False, init=init_xavier, act=self.act)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Single layer dense that maps the flattened encoded representation into hiddens.\n",
    "        self.projection = MLP(13824, med_hiddens=hiddens, out_hiddens=hiddens,\n",
    "                              last_init=init_xavier, layers=1)\n",
    "        self.prediction = MLP(hiddens, out_hiddens=hiddens, layers=1, last_init=init_xavier)\n",
    "                                              \n",
    "        self.transition = nn.Sequential(DQN_Conv(128+n_actions, 128, 3, 1, 1, norm=False, init=init_xavier, act=self.act),\n",
    "                                        DQN_Conv(128, 128, 3, 1, 1, norm=False, init=init_xavier, act=self.act))\n",
    "\n",
    "        # Single layer dense that maps hiddens into the output dim according to:\n",
    "        # 1. https://arxiv.org/pdf/1707.06887.pdf -- Distributional Reinforcement Learning\n",
    "        # 2. https://arxiv.org/pdf/1511.06581.pdf -- Dueling DQN\n",
    "        self.a = MLP(hiddens, out_hiddens=n_actions*num_buckets, layers=1, in_act=self.act, last_init=init_xavier)\n",
    "        self.v = MLP(hiddens, out_hiddens=num_buckets, layers=1, in_act=self.act, last_init=init_xavier)\n",
    "    \n",
    "        params_count(self, 'DQN')\n",
    "    \n",
    "    def forward(self, X, y_action):\n",
    "        X, z = self.encode(X)\n",
    "        \n",
    "        \n",
    "        q, action = self.q_head(X)\n",
    "        z_pred = self.get_transition(z, y_action)\n",
    "\n",
    "        return q, action, X[:,1:].clone().detach(), z_pred\n",
    "    \n",
    "\n",
    "    def env_step(self, X):\n",
    "        with torch.no_grad():\n",
    "            X, _ = self.encode(X)\n",
    "            _, action = self.q_head(X)\n",
    "            \n",
    "            return action.detach()\n",
    "    \n",
    "\n",
    "    def encode(self, X):\n",
    "        batch, seq = X.shape[:2]\n",
    "        self.batch = batch\n",
    "        self.seq = seq\n",
    "        X = self.encoder_cnn(X.contiguous().view(self.batch*self.seq, *(X.shape[2:])))\n",
    "        X = renormalize(X).contiguous().view(self.batch, self.seq, *X.shape[-3:])\n",
    "        X = X.contiguous().view(self.batch, self.seq, *X.shape[-3:])\n",
    "        z = X.clone()\n",
    "        X = X.flatten(-3,-1)\n",
    "        X = self.projection(X)\n",
    "        return X, z\n",
    "\n",
    "    def get_transition(self, z, action):\n",
    "        z = z.contiguous().view(-1, *z.shape[-3:])\n",
    "        \n",
    "        action = F.one_hot(action.clone(), n_actions).view(-1, n_actions)\n",
    "        action = action.view(-1, 5, n_actions, 1, 1).expand(-1, 5, n_actions, *z.shape[-2:])\n",
    "\n",
    "        z_pred = torch.cat( (z, action[:,0]), 1)\n",
    "        z_pred = self.transition(z_pred)\n",
    "        z_pred = renormalize(z_pred)\n",
    "        \n",
    "        z_preds=[z_pred.clone()]\n",
    "        \n",
    "\n",
    "        for k in range(4):\n",
    "            z_pred = torch.cat( (z_pred, action[:,k+1]), 1)\n",
    "            z_pred = self.transition(z_pred)\n",
    "            z_pred = renormalize(z_pred)\n",
    "            \n",
    "            z_preds.append(z_pred)\n",
    "        \n",
    "        \n",
    "        z_pred = torch.stack(z_preds,1)\n",
    "\n",
    "        z_pred = self.projection(z_pred.flatten(-3,-1)).view(self.batch,5,-1)\n",
    "        z_pred = self.prediction(z_pred)\n",
    "        \n",
    "        return z_pred\n",
    "\n",
    "    \n",
    "    def q_head(self, X):\n",
    "        q = self.dueling_dqn(X)\n",
    "        action = (q*self.support).sum(-1).argmax(-1)\n",
    "        \n",
    "        return q, action\n",
    "\n",
    "    def get_max_action(self, X):\n",
    "        with torch.no_grad():\n",
    "            X, _ = self.encode(X)\n",
    "            q = self.dueling_dqn(X)\n",
    "            \n",
    "            action = (q*self.support).sum(-1).argmax(-1)\n",
    "            return action\n",
    "\n",
    "    def evaluate(self, X, action):\n",
    "        with torch.no_grad():\n",
    "            X, _ = self.encode(X)\n",
    "            \n",
    "            q = self.dueling_dqn(X)\n",
    "            \n",
    "            action = action[:,:,None,None].expand_as(q)[:,:,0][:,:,None]\n",
    "            q = q.gather(-2,action)\n",
    "            \n",
    "            return q\n",
    "\n",
    "    def dueling_dqn(self, X):\n",
    "        X = F.relu(X)\n",
    "        \n",
    "        a = self.a(X).view(self.batch, -1, n_actions, num_buckets)\n",
    "        v = self.v(X).view(self.batch, -1, 1, num_buckets)\n",
    "        \n",
    "        q = v + a - a.mean(-2,keepdim=True)\n",
    "        q = F.softmax(q,-1)\n",
    "        \n",
    "        return q\n",
    "    \n",
    "    def network_ema(self, rand_network, target_network, alpha=0.5):\n",
    "        for param, param_target in zip(rand_network.parameters(), target_network.parameters()):\n",
    "            param_target.data = alpha * param_target.data + (1 - alpha) * param.data.clone()\n",
    "\n",
    "    def hard_reset(self, random_model, alpha=0.5):\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            self.network_ema(random_model.encoder_cnn, self.encoder_cnn, alpha)\n",
    "            self.network_ema(random_model.transition, self.transition, alpha)\n",
    "\n",
    "            self.network_ema(random_model.projection, self.projection, 0)\n",
    "            self.network_ema(random_model.prediction, self.prediction, 0)\n",
    "\n",
    "            self.network_ema(random_model.a, self.a, 0)\n",
    "            self.network_ema(random_model.v, self.v, 0)\n",
    "\n",
    "\n",
    "\n",
    "def copy_states(source, target):\n",
    "    for key, _ in zip(source.state_dict()['state'].keys(), target.state_dict()['state'].keys()):\n",
    "\n",
    "        target.state_dict()['state'][key]['exp_avg_sq'] = copy.deepcopy(source.state_dict()['state'][key]['exp_avg_sq'])\n",
    "        target.state_dict()['state'][key]['exp_avg'] = copy.deepcopy(source.state_dict()['state'][key]['exp_avg'])\n",
    "        target.state_dict()['state'][key]['step'] = copy.deepcopy(source.state_dict()['state'][key]['step'])\n",
    "        \n",
    "def target_model_ema(model, model_target):\n",
    "    with torch.no_grad():\n",
    "        for param, param_target in zip(model.parameters(), model_target.parameters()):\n",
    "            param_target.data = critic_ema_decay * param_target.data + (1.0 - critic_ema_decay) * param.data.clone()\n",
    "\n",
    "\n",
    "    \n",
    "model=DQN(n_actions).cuda()\n",
    "model_target=DQN(n_actions).cuda()\n",
    "\n",
    "model_target.load_state_dict(model.state_dict())\n",
    "\n",
    "\n",
    "# Testing only\n",
    "#with torch.no_grad():\n",
    "#    q, action, X, z_pred = model(torch.randn(4,1,12,96,72, device='cuda', dtype=torch.float), torch.randint(0,n_actions,(4,5),device='cuda').long())\n",
    "#z = model.encode(torch.randn(4,5,12,96,72, device='cuda'))[0]\n",
    "\n",
    "# I believe the authors have actually miscalculated the params count on the paper.\n",
    "# My training time is lower than theirs while having more parameters, and the same architecture is used as is their original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ca1d0e5-d128-428b-bcbc-be68dccc005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "perception_modules=[model.encoder_cnn, model.transition]\n",
    "actor_modules=[model.prediction, model.projection, model.a, model.v]\n",
    "\n",
    "params_wm=[]\n",
    "for module in perception_modules:\n",
    "    for param in module.parameters():\n",
    "        if param.requires_grad==True: # They all require grad\n",
    "            params_wm.append(param)\n",
    "\n",
    "params_ac=[]\n",
    "for module in actor_modules:\n",
    "    for param in module.parameters():\n",
    "        if param.requires_grad==True:\n",
    "            params_ac.append(param)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(chain(params_wm, params_ac),\n",
    "                                lr=lr, weight_decay=0.1, eps=1.5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7f2a7d7-81c6-4c93-8cbe-1f15fa75af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "                         transforms.Resize((96,72)),\n",
    "                        ])\n",
    "\n",
    "\n",
    "def preprocess(state):\n",
    "    state=torch.tensor(state, dtype=torch.float, device='cuda') / 255\n",
    "    state=train_tfms(state.permute(0,3,1,2))\n",
    "    return state\n",
    "\n",
    "# https://github.com/google/dopamine/blob/master/dopamine/jax/agents/dqn/dqn_agent.py\n",
    "def linearly_decaying_epsilon(decay_period, step, warmup_steps, epsilon):\n",
    "    steps_left = decay_period + warmup_steps - step\n",
    "    bonus = (1.0 - epsilon) * steps_left / decay_period\n",
    "    bonus = np.clip(bonus, 0., 1. - epsilon)\n",
    "    return epsilon + bonus\n",
    "\n",
    "\n",
    "def epsilon_greedy(Q_action, step, final_eps=0, num_envs=1):\n",
    "    epsilon = linearly_decaying_epsilon(2001, step, 2000, final_eps)\n",
    "    \n",
    "    if random.random() < epsilon:\n",
    "        action = torch.randint(0, n_actions, (num_envs,), dtype=torch.int64, device='cuda').squeeze(0)\n",
    "    else:\n",
    "        action = Q_action.view(num_envs).squeeze(0).to(torch.int64)\n",
    "    return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6722829c-d4bc-4d9f-aa35-80f6133a4819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/google/dopamine/blob/master/dopamine/jax/agents/rainbow/rainbow_agent.py\n",
    "def project_distribution(supports, weights, target_support):\n",
    "    with torch.no_grad():\n",
    "        v_min, v_max = target_support[0], target_support[-1]\n",
    "        # `N` in Eq7.\n",
    "        num_dims = target_support.shape[-1]\n",
    "        # delta_z = `\\Delta z` in Eq7.\n",
    "        delta_z = (v_max - v_min) / (num_buckets-1)\n",
    "        # clipped_support = `[\\hat{T}_{z_j}]^{V_max}_{V_min}` in Eq7.\n",
    "        clipped_support = supports.clip(v_min, v_max)\n",
    "        # numerator = `|clipped_support - z_i|` in Eq7.\n",
    "        numerator = (clipped_support[:,None] - target_support[None,:,None].repeat_interleave(clipped_support.shape[0],0)).abs()\n",
    "        quotient = 1 - (numerator / delta_z)\n",
    "        # clipped_quotient = `[1 - numerator / (\\Delta z)]_0^1` in Eq7.\n",
    "        clipped_quotient = quotient.clip(0, 1)\n",
    "        # inner_prod = `\\sum_{j=0}^{N-1} clipped_quotient * p_j(x', \\pi(x'))` in Eq7.\n",
    "        inner_prod = (clipped_quotient * weights[:,None]).sum(-1)\n",
    "        #inner_prod = (clipped_quotient).sum(-1) * weights\n",
    "        return inner_prod.squeeze()\n",
    "\n",
    "\n",
    "mse = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "def optimize(step, grad_step, n):\n",
    "        \n",
    "    model.train()\n",
    "    model_target.train()\n",
    "\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.bfloat16, enabled=False):\n",
    "        with torch.no_grad():\n",
    "            states, next_states, rewards, action, c_flag, idxs, is_w = memory.sample(n, batch_size, grad_step)\n",
    "        terminal=1-c_flag\n",
    "        #print(f\"STUFF HERE {states.shape, rewards.shape, c_flag.shape, action.shape, n}\")\n",
    "    \n",
    "    \n",
    "        q, max_action, _, z_pred = model(states[:,0][:,None], action[:,:5].long())\n",
    "        z = model_target.encode(states[:,1:6])[0].detach()\n",
    "\n",
    "        \n",
    "        max_action  = model.get_max_action(next_states[:,n-1][:,None])\n",
    "        next_values = model_target.evaluate(next_states[:,n-1][:,None].contiguous(), max_action)\n",
    "        \n",
    "\n",
    "        action = action[:,0,None].expand(batch_size,num_buckets)\n",
    "        action=action[:,None]\n",
    "        with torch.no_grad():\n",
    "            gammas_one=torch.ones(batch_size,n,1,dtype=torch.float,device='cuda')\n",
    "            gamma_step = 1-torch.tensor(( (schedule_max_step - min(grad_step, schedule_max_step)) / schedule_max_step) * (initial_gamma-final_gamma) + final_gamma).exp()\n",
    "            gammas=gammas_one*gamma_step\n",
    "\n",
    "            \n",
    "            returns = []\n",
    "            for t in range(n):\n",
    "                ret = 0\n",
    "                for u in reversed(range(t, n)):\n",
    "                    ret += torch.prod(c_flag[:,t+1:u+1],-2)*torch.prod(gammas[:,t:u],-2)*rewards[:,u+1]\n",
    "                returns.append(ret)\n",
    "            returns = torch.stack(returns,1)\n",
    "        \n",
    "        plot_vs = returns.clone().sum(-1)\n",
    "        \n",
    "        same_traj = (torch.prod(c_flag[:,:n],-2)).squeeze()\n",
    "        \n",
    "        returns = returns[:,0]\n",
    "        returns = returns + torch.prod(gammas[0,:10],-2).squeeze()*same_traj[:,None]*model.support[None,:]\n",
    "        returns = returns.squeeze()\n",
    "        \n",
    "        next_values = next_values[:,0]\n",
    "\n",
    "        log_probs = torch.log(q[:,0].gather(-2, action)[:,None] + eps).contiguous()\n",
    "        \n",
    "        \n",
    "        dist = project_distribution(returns, next_values.squeeze(), model.support)\n",
    "        \n",
    "        loss = -(dist*(log_probs.squeeze())).sum(-1).view(batch_size,-1).sum(-1)\n",
    "        dqn_loss = loss.clone().mean()\n",
    "        td_error = (loss + torch.nan_to_num((dist*torch.log(dist))).sum(-1)).mean()\n",
    "\n",
    "        \n",
    "        batched_loss = loss.clone()\n",
    "        \n",
    "        \n",
    "        z = F.normalize(z, 2, dim=-1, eps=1e-5)\n",
    "        z_pred = F.normalize(z_pred, 2, dim=-1, eps=1e-5)\n",
    "\n",
    "        \n",
    "        recon_loss = (mse(z_pred.contiguous().view(-1,2048), z.contiguous().view(-1,2048))).sum(-1)\n",
    "        recon_loss = 5*(recon_loss.view(batch_size, -1).mean(-1))*same_traj\n",
    "        \n",
    "        \n",
    "        loss += recon_loss\n",
    "        \n",
    "        loss = (loss*is_w).mean() # mean across batch axis\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    param_norm, grad_norm = params_and_grad_norm(model)\n",
    "    #scaler.scale(loss).backward()\n",
    "    #scaler.unscale_(optimizer)\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "    #scaler.step(optimizer)\n",
    "    #scaler.update()\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #memory.set_priority(idxs, batched_loss)\n",
    "    memory.set_priority(idxs, batched_loss, same_traj)\n",
    "    \n",
    "    \n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    wandb.log({'loss': loss, 'dqn_loss': dqn_loss, 'recon_loss': recon_loss.mean(), 'lr': lr, 'returns': plot_vs.mean(),\n",
    "               'buffer rewards': rewards.mean(0).sum(), 'is_w': is_w.mean(),\n",
    "               'gamma': gamma_step, 'td_error': td_error, 'param_norm': param_norm.sum(), 'grad_norm': grad_norm.sum()})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scores=[]\n",
    "memory.free()\n",
    "step=0\n",
    "#model.share_memory()\n",
    "grad_step=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05991348-a11a-43bd-882f-02df107fc543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1991/102000 [00:14<13:35, 122.59it/s]C:\\Users\\sneep\\AppData\\Local\\Temp\\ipykernel_24696\\1152238539.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gamma_step = 1-torch.tensor(( (schedule_max_step - min(grad_step, schedule_max_step)) / schedule_max_step) * (initial_gamma-final_gamma) + final_gamma).exp()\n",
      " 22%|██▏       | 22002/102000 [1:00:14<4:08:12,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting on step 22001 40002\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 35.42M\n",
      "IMPALA ResNet Parameters: 1.56M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22003/102000 [1:00:32<122:30:55,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Parameters: 35.42M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 42003/102000 [1:48:56<2:12:30,  7.55it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting on step 42002 40002\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 35.42M\n",
      "IMPALA ResNet Parameters: 1.56M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 42004/102000 [1:48:58<11:00:39,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Parameters: 35.42M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 62004/102000 [2:34:09<1:30:57,  7.33it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting on step 62003 40002\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 35.42M\n",
      "IMPALA ResNet Parameters: 1.56M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 62005/102000 [2:34:11<6:57:44,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Parameters: 35.42M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 82005/102000 [3:39:05<1:13:46,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting on step 82004 40002\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 35.42M\n",
      "IMPALA ResNet Parameters: 1.56M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 82006/102000 [3:39:23<31:16:08,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Parameters: 35.42M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102000/102000 [5:01:00<00:00,  4.46it/s]  "
     ]
    }
   ],
   "source": [
    "step=0\n",
    "\n",
    "progress_bar = tqdm.tqdm(total=total_steps)\n",
    "\n",
    "while step<(10):\n",
    "    state, info = env.reset()\n",
    "    state = preprocess(state)\n",
    "\n",
    "    states = deque(maxlen=4)\n",
    "    for i in range(4):\n",
    "        states.append(state)\n",
    "    \n",
    "    \n",
    "    eps_reward=torch.tensor([0], dtype=torch.float)\n",
    "    \n",
    "    reward=np.array([0])\n",
    "    done_flag=np.array([False])\n",
    "    terminated=np.array([False])\n",
    "\n",
    "    last_lives=np.array([0])\n",
    "    life_loss=np.array([0])\n",
    "    resetted=np.array([0])\n",
    "    \n",
    "    last_grad_update=0\n",
    "    while step<(total_steps):\n",
    "        progress_bar.update(1)\n",
    "        model_target.train()\n",
    "        \n",
    "        len_memory = len(memory)\n",
    "        \n",
    "        #if resetted[0]>0:\n",
    "        #    states = env.noop_steps(states)\n",
    "            \n",
    "        Q_action = model_target.env_step(torch.cat(list(states),-3).unsqueeze(0))\n",
    "        \n",
    "        action = epsilon_greedy(Q_action, len_memory).cpu()\n",
    "        \n",
    "        memory.push(torch.cat(list(states),-3).detach().cpu(), reward, action, np.logical_or(done_flag, life_loss))\n",
    "        #print('action', action, action.shape)\n",
    "        \n",
    "        state, reward, terminated, truncated, info = env.step([action.numpy()])\n",
    "        state = preprocess(state)\n",
    "        states.append(state)\n",
    "        \n",
    "        eps_reward+=reward\n",
    "        reward = reward.clip(-1, 1)\n",
    "\n",
    "\n",
    "        \n",
    "        done_flag = np.logical_or(terminated, truncated)\n",
    "        lives = info['lives']\n",
    "        life_loss = (last_lives-lives).clip(min=0)\n",
    "        resetted = (lives-last_lives).clip(min=0)\n",
    "        last_lives = lives\n",
    "\n",
    "        \n",
    "        n = int(initial_n * (final_n/initial_n)**(min(grad_step,schedule_max_step) / schedule_max_step))\n",
    "        n = np.array(n).item()\n",
    "        \n",
    "        memory.priority[len_memory] = memory.max_priority()\n",
    "        \n",
    "\n",
    "        if len_memory>2000:\n",
    "            for i in range(2):\n",
    "                optimize(step, grad_step, n)\n",
    "                target_model_ema(model, model_target)\n",
    "                grad_step+=1\n",
    "\n",
    "        \n",
    "        if ((step+1)%10000)==0:\n",
    "            save_checkpoint(model, model_target, optimizer, step,\n",
    "                            'checkpoints/atari_last.pth')\n",
    "        \n",
    "            \n",
    "        \n",
    "        if grad_step>reset_every:\n",
    "            #eval()\n",
    "            print('Reseting on step', step, grad_step)\n",
    "            \n",
    "            #seed_np_torch(random.randint(SEED-1000, SEED+1000)+step)\n",
    "            random_model = DQN(n_actions).cuda()\n",
    "            model.hard_reset(random_model)\n",
    "            \n",
    "            #seed_np_torch(random.randint(SEED-1000, SEED+1000)+step)\n",
    "            random_model = DQN(n_actions).cuda()\n",
    "            model_target.hard_reset(random_model)\n",
    "            seed_np_torch(SEED)\n",
    "            \n",
    "            random_model=None\n",
    "            grad_step=0\n",
    "\n",
    "            actor_modules=[model.prediction, model.projection, model.a, model.v]\n",
    "            params_ac=[]\n",
    "            for module in actor_modules:\n",
    "                for param in module.parameters():\n",
    "                    params_ac.append(param)\n",
    "                    \n",
    "\n",
    "            perception_modules=[model.encoder_cnn, model.transition]\n",
    "            params_wm=[]\n",
    "            for module in perception_modules:\n",
    "                for param in module.parameters():\n",
    "                    params_wm.append(param)\n",
    "            \n",
    "            optimizer_aux = torch.optim.AdamW(params_wm, lr=lr, weight_decay=0.1, eps=1.5e-4)\n",
    "            copy_states(optimizer, optimizer_aux)\n",
    "            optimizer = torch.optim.AdamW(chain(params_wm, params_ac),\n",
    "                                lr=lr, weight_decay=0.1, eps=1.5e-4)\n",
    "            copy_states(optimizer_aux, optimizer)\n",
    "        \n",
    "        \n",
    "        \n",
    "        step+=1\n",
    "        \n",
    "        log_t = done_flag.astype(float).nonzero()[0]\n",
    "        \n",
    "        if len(log_t)>0:\n",
    "            for log in log_t:\n",
    "                wandb.log({'eps_reward': eps_reward[log].sum()})\n",
    "                scores.append(eps_reward[log].clone())\n",
    "            eps_reward[log_t]=0\n",
    "\n",
    "save_checkpoint(model, model_target, optimizer, step, f'checkpoints/{env_name}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87344597-e733-451c-8a5f-2a00b5511061",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_to_eval=False\n",
    "\n",
    "if load_to_eval:\n",
    "    model.load_state_dict(torch.load(f'checkpoints/{env_name}.pth')['model_state_dict'])\n",
    "    model_target.load_state_dict(torch.load(f'checkpoints/{env_name}.pth')['model_target_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12d36218-ab48-42d9-a7ba-fabb66cc758f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init state torch.Size([1, 3, 96, 72])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 1/100 [00:04<07:57,  4.83s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:11<09:38,  5.90s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [00:19<10:47,  6.68s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [00:26<11:03,  6.91s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [00:34<11:22,  7.19s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [00:41<11:16,  7.20s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [00:53<13:34,  8.76s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [01:02<13:33,  8.84s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [01:10<13:14,  8.74s/it]\u001b[A\n",
      " 10%|█         | 10/100 [01:18<12:41,  8.46s/it]\u001b[A\n",
      " 11%|█         | 11/100 [01:26<12:21,  8.33s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [01:33<11:43,  8.00s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [01:54<16:56, 11.68s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [02:02<15:25, 10.76s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [02:13<15:11, 10.73s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [02:27<16:39, 11.90s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [02:36<14:55, 10.78s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [02:44<13:36,  9.96s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [02:51<12:20,  9.15s/it]\u001b[A\n",
      " 20%|██        | 20/100 [02:58<11:14,  8.43s/it]\u001b[A\n",
      " 21%|██        | 21/100 [03:05<10:43,  8.14s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [03:13<10:29,  8.07s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [03:26<12:24,  9.67s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [03:32<10:49,  8.55s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [03:40<10:19,  8.26s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [03:47<09:50,  7.98s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [03:54<09:24,  7.74s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [04:03<09:32,  7.95s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [04:10<09:14,  7.82s/it]\u001b[A\n",
      " 30%|███       | 30/100 [04:18<09:02,  7.75s/it]\u001b[A\n",
      " 31%|███       | 31/100 [04:24<08:24,  7.31s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [04:32<08:16,  7.30s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [04:42<09:19,  8.35s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [04:52<09:42,  8.83s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [04:59<08:53,  8.21s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [05:08<09:01,  8.46s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [05:17<09:08,  8.70s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [05:31<10:24, 10.07s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [05:50<13:08, 12.93s/it]\u001b[A\n",
      " 40%|████      | 40/100 [06:00<12:02, 12.04s/it]\u001b[A\n",
      " 41%|████      | 41/100 [06:11<11:28, 11.67s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [06:20<10:30, 10.88s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [06:49<15:23, 16.20s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [07:05<15:12, 16.29s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [07:13<12:31, 13.66s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [07:19<10:25, 11.58s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [07:25<08:40,  9.83s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [07:31<07:33,  8.72s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [07:36<06:20,  7.46s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [07:52<08:27, 10.16s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [07:59<07:32,  9.23s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [08:06<06:40,  8.35s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [08:13<06:19,  8.08s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [08:20<05:51,  7.63s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [08:27<05:43,  7.64s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [08:34<05:29,  7.49s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [08:42<05:21,  7.47s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [08:54<06:11,  8.84s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [09:13<08:06, 11.86s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [09:22<07:20, 11.00s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [09:31<06:43, 10.36s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [09:38<06:03,  9.57s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [09:47<05:47,  9.39s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [09:57<05:37,  9.38s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [10:15<07:00, 12.01s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [10:25<06:29, 11.47s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [10:34<05:55, 10.78s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [10:50<06:29, 12.18s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [10:57<05:33, 10.74s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [11:05<04:54,  9.83s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [11:12<04:21,  9.03s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [11:19<03:52,  8.29s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [11:25<03:32,  7.87s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [11:31<03:10,  7.31s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [11:39<03:04,  7.36s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [11:46<02:57,  7.38s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [11:54<02:49,  7.35s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [12:01<02:43,  7.41s/it]\u001b[A\n",
      " 79%|███████▉  | 79/100 [12:08<02:32,  7.25s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [12:14<02:14,  6.73s/it]\u001b[A\n",
      " 81%|████████  | 81/100 [12:21<02:10,  6.85s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [12:27<02:02,  6.79s/it]\u001b[A\n",
      " 83%|████████▎ | 83/100 [12:35<02:01,  7.12s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [12:44<02:01,  7.56s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [12:53<02:01,  8.11s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [13:03<01:59,  8.54s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [13:26<02:47, 12.90s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [13:48<03:07, 15.66s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [13:57<02:31, 13.73s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [14:07<02:05, 12.59s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [14:16<01:42, 11.38s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [14:26<01:27, 10.92s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [14:34<01:11, 10.19s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [14:44<01:00, 10.02s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [14:52<00:47,  9.43s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [14:59<00:34,  8.70s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [15:09<00:27,  9.28s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [15:23<00:21, 10.69s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [15:28<00:08,  8.90s/it]\u001b[A\n",
      "100%|██████████| 100/100 [15:35<00:00,  9.35s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Mean 4651.0\n",
      "Inter Quantile Mean 4100.0\n",
      "Inter Quantile STD 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_envs=1\n",
    "\n",
    "#env = gym.vector.make(f\"{env_name}NoFrameskip-v4\", num_envs=num_envs, render_mode='human')\n",
    "env = gym.vector.make(f\"{env_name}NoFrameskip-v4\", num_envs=num_envs)\n",
    "env = MaxLast2FrameSkipWrapper(env,seed=SEED)\n",
    "\n",
    "def eval_phase(eval_runs=50, max_eval_steps=27000, num_envs=1):\n",
    "    progress_bar = tqdm.tqdm(total=eval_runs)\n",
    "    \n",
    "    scores=[]\n",
    "    \n",
    "    state, info = env.reset()\n",
    "    state = preprocess(state)\n",
    "    print(f\"init state {state.shape}\")\n",
    "    \n",
    "    states = deque(maxlen=4)\n",
    "    for i in range(4):\n",
    "        states.append(state)\n",
    "    \n",
    "    \n",
    "    eps_reward=torch.tensor([0]*num_envs, dtype=torch.float)\n",
    "    \n",
    "    reward=np.array([0]*num_envs)\n",
    "    terminated=np.array([False]*num_envs)\n",
    "    \n",
    "    last_lives=np.array([0]*num_envs)\n",
    "    life_loss=np.array([0]*num_envs)\n",
    "    resetted=np.array([0])\n",
    "\n",
    "    finished_envs=np.array([False]*num_envs)\n",
    "    done_flag=0\n",
    "    last_grad_update=0\n",
    "    eval_run=0\n",
    "    step=np.array([0]*num_envs)\n",
    "    while eval_run<eval_runs:\n",
    "        #seed_np_torch(SEED+eval_run)\n",
    "        env.seed=SEED+eval_run\n",
    "        model_target.train()\n",
    "        \n",
    "        #if resetted[0]>0:\n",
    "        #    states = env.noop_steps(states)\n",
    "        \n",
    "        Q_action = model_target.env_step(torch.cat(list(states),-3).unsqueeze(0))\n",
    "        action = epsilon_greedy(Q_action.squeeze(), 5000, 0.0005, num_envs).cpu()\n",
    "        \n",
    "        state, reward, terminated, truncated, info = env.step([action.numpy()] if num_envs==1 else action.numpy())\n",
    "        state = preprocess(state)\n",
    "        states.append(state)\n",
    "        \n",
    "        eps_reward+=reward\n",
    "\n",
    "        \n",
    "        done_flag = np.logical_or(terminated, truncated)\n",
    "        lives = info['lives']\n",
    "        life_loss = (last_lives-lives).clip(min=0)\n",
    "        resetted = (lives-last_lives).clip(min=0)\n",
    "        last_lives = lives        \n",
    "        \n",
    "        step+=1\n",
    "        \n",
    "        log_t = done_flag.astype(float).nonzero()[0]\n",
    "        if len(log_t)>0:# or (step>max_eval_steps).any():\n",
    "            progress_bar.update(1)\n",
    "            for log in log_t:\n",
    "                #wandb.log({'eval_eps_reward': eps_reward[log].sum()})\n",
    "                if finished_envs[log]==False:\n",
    "                    scores.append(eps_reward[log].clone())\n",
    "                    eval_run+=1\n",
    "                    #finished_envs[log]=True\n",
    "                step[log]=0\n",
    "                \n",
    "            eps_reward[log_t]=0            \n",
    "            for i, log in enumerate(step>max_eval_steps):\n",
    "                if log==True and finished_envs[i]==False:\n",
    "                    scores.append(eps_reward[i].clone())\n",
    "                    step[i]=0\n",
    "                    eval_run+=1\n",
    "                    eps_reward[i]=0\n",
    "                    #finished_envs[i]=True\n",
    "            \n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "def eval(eval_runs=50, max_eval_steps=27000, num_envs=1):\n",
    "    assert num_envs==1, 'The code for num eval envs > 1 is messed up.'\n",
    "    \n",
    "    scores = eval_phase(eval_runs, max_eval_steps, num_envs)    \n",
    "    scores = torch.stack(scores)\n",
    "    scores, _ = scores.sort()\n",
    "    \n",
    "    _25th = eval_runs//4\n",
    "\n",
    "    iq = scores[_25th:-_25th]\n",
    "    iqm = iq.mean()\n",
    "    iqs = iq.std()\n",
    "\n",
    "    print(f\"Scores Mean {scores.mean()}\")\n",
    "    print(f\"Inter Quantile Mean {iqm}\")\n",
    "    print(f\"Inter Quantile STD {iqs}\")\n",
    "\n",
    "    \n",
    "    plt.xlabel('Episode (Sorted by Reward)')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.plot(scores)\n",
    "    \n",
    "    new_row = {'env_name': env_name, 'mean': scores.mean().item(), 'iqm': iqm.item(), 'std': iqs.item(), 'seed': SEED}\n",
    "    add_to_csv('results.csv', new_row)\n",
    "\n",
    "    with open(f'results/{env_name}-{SEED}.txt', 'w') as f:\n",
    "        f.write(f\" Scores Mean {scores.mean()}\\n Inter Quantile Mean {iqm}\\n Inter Quantile STD {iqs}\")\n",
    "    \n",
    "    \n",
    "    return scores\n",
    "\n",
    "scores = eval(eval_runs=100, num_envs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57556912-f811-4eb5-9030-f8f77e3962ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b57c70a-3cdb-4c49-a7f7-aa3c77a7e280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env_name,mean,iqm,std,seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Assault,2133.98,2180.88,445.01422,7783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assault,2047.26,1995.86,453.6222473218285,7784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assault,1977.31,2013.12,371.49469960786064,8223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alien,855.6,853.4,39.56,8219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alien,1246.8,1230.0,0.0,7779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alien,1036.6,987.6,32.36,7780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Amidar,112.52,110.0,0.0,7781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amidar,362.38,377.0,0.0,7782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Amidar,241.24,241.0,0.0,8001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Asterix,5694.0,5800.0,0.0,8226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         env_name,mean,iqm,std,seed\n",
       "0            Assault,2133.98,2180.88,445.01422,7783\n",
       "1    Assault,2047.26,1995.86,453.6222473218285,7784\n",
       "2   Assault,1977.31,2013.12,371.49469960786064,8223\n",
       "3                      Alien,855.6,853.4,39.56,8219\n",
       "4                      Alien,1246.8,1230.0,0.0,7779\n",
       "5                     Alien,1036.6,987.6,32.36,7780\n",
       "6                      Amidar,112.52,110.0,0.0,7781\n",
       "7                      Amidar,362.38,377.0,0.0,7782\n",
       "8                      Amidar,241.24,241.0,0.0,8001\n",
       "9                    Asterix,5694.0,5800.0,0.0,8226\n",
       "10                                              NaN\n",
       "11                                              NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "new_row = {'env_name': \"Amidar\", 'mean': 11.0, 'iqm': 11.0, 'std': 11.0, 'seed': 000}\n",
    "\n",
    "df = pd.read_csv('results.csv',sep=',')\n",
    "df.loc[len(df.index)] = new_row    \n",
    "#df.to_csv('results.csv', index=False)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b215ce8f-b10d-4ed3-8651-86ae074d14af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
