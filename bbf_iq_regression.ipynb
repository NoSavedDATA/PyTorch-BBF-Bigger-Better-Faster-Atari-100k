{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57cb10b8-6556-487a-80d5-7f5b165b996a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\diffusers\\utils\\outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msnykralafk\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\sneep\\Python\\bbf\\wandb\\run-20240405_200610-62905auk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/snykralafk/Atari-100k-BBF/runs/62905auk' target=\"_blank\">BBF-Assault</a></strong> to <a href='https://wandb.ai/snykralafk/Atari-100k-BBF' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/snykralafk/Atari-100k-BBF' target=\"_blank\">https://wandb.ai/snykralafk/Atari-100k-BBF</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/snykralafk/Atari-100k-BBF/runs/62905auk' target=\"_blank\">https://wandb.ai/snykralafk/Atari-100k-BBF/runs/62905auk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count, chain\n",
    "import tqdm\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "from nosaveddata.nsd_utils.save_hypers import Hypers, nsd_Module\n",
    "from nosaveddata.nsd_utils.nsd_csv import add_to_csv\n",
    "from nosaveddata.nsd_utils.networks import params_count, params_and_grad_norm, seed_np_torch\n",
    "from nosaveddata.nsd_utils.einstein import Rearrange\n",
    "\n",
    "from nosaveddata.builders.mlp import *\n",
    "from nosaveddata.builders.weight_init import *\n",
    "from nosaveddata.builders.resnet import IMPALA_Resnet, DQN_Conv, IMPALA_YY\n",
    "\n",
    "\n",
    "from utils.experience_replay import *\n",
    "\n",
    "\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "import wandb\n",
    "\n",
    "\n",
    "# Environment configuration\n",
    "#env_name = 'Kangaroo'\n",
    "#SEED = 8712\n",
    "\n",
    "env_name = 'Assault'\n",
    "SEED = 7783\n",
    "\n",
    "\n",
    "wandb.init(\n",
    "    project=\"Atari-100k-BBF\",\n",
    "    name=f\"BBF-{env_name}\",\n",
    "\n",
    "    #id='rotdmtc5',\n",
    "    #resume='must',\n",
    "\n",
    "    config={\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"architecture\": \"BBF\",\n",
    "        \"dataset\": \"Assault\",\n",
    "        \"epochs\": 100,\n",
    "    },\n",
    "\n",
    "    reinit=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Optimization\n",
    "batch_size = 32\n",
    "lr=1e-4\n",
    "\n",
    "eps=1e-8\n",
    "\n",
    "\n",
    "# Target network EMA rate\n",
    "critic_ema_decay=0.995\n",
    "\n",
    "\n",
    "# Return function\n",
    "initial_gamma=torch.tensor(1-0.97).log()\n",
    "final_gamma=torch.tensor(1-0.997).log()\n",
    "\n",
    "initial_n = 10\n",
    "final_n = 3\n",
    "\n",
    "num_buckets=200\n",
    "\n",
    "\n",
    "# Reset Schedule and Buffer\n",
    "reset_every=40000 # grad steps, not steps.\n",
    "schedule_max_step=reset_every//4\n",
    "total_steps=102000\n",
    "\n",
    "prefetch_cap=1 # actually, no prefetch is being done\n",
    "\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'reward', 'action', 'c_flag'))\n",
    "memory = PrioritizedReplay_nSteps_Sqrt(total_steps+5, total_steps=schedule_max_step, prefetch_cap=prefetch_cap)\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint(net, model_target, optimizer, step, path):\n",
    "    torch.save({\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'model_target_state_dict': model_target.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'step': step,\n",
    "            }, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c831907e-0868-4915-bc34-3d1dd1fe363c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sneep\\anaconda3\\envs\\python_\\Lib\\site-packages\\gymnasium\\vector\\__init__.py:53: UserWarning: \u001b[33mWARN: `gymnasium.vector.make(...)` is deprecated and will be replaced by `gymnasium.make_vec(...)` in v1.0\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# Adapted from: https://github.com/weipu-zhang/STORM/blob/main/env_wrapper.py\n",
    "class MaxLast2FrameSkipWrapper(Hypers, gym.Wrapper):\n",
    "    def __init__(self, env, skip=4, noops=30, seed=0):\n",
    "        super().__init__(env=env)\n",
    "        self.env.action_space.seed(seed)\n",
    "        \n",
    "    def reset(self, **kwargs):\n",
    "        kwargs[\"seed\"] = self.seed\n",
    "        obs, _ = self.env.reset(**kwargs)\n",
    "\n",
    "        return obs, _\n",
    "        \n",
    "    def noop_steps(self, states):\n",
    "        noops = random.randint(0,self.noops)\n",
    "        \n",
    "        for i in range(noops):\n",
    "            state = self.step(np.array([0]))[0]\n",
    "            state = preprocess(state)\n",
    "            states.append(state)\n",
    "        return states\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0\n",
    "        self.obs_buffer = deque(maxlen=2)\n",
    "        for _ in range(self.skip):\n",
    "            obs, reward, done, truncated, info = self.env.step(action)\n",
    "            self.obs_buffer.append(obs)\n",
    "            total_reward += reward\n",
    "\n",
    "            terminated = np.logical_or(done, truncated)\n",
    "            #if terminated.any():\n",
    "            #    for i in range(len(terminated)):\n",
    "            #       obs[i] = self.reset()[0][i]\n",
    "            if done or truncated:\n",
    "                break\n",
    "        if len(self.obs_buffer) == 1:\n",
    "            obs = self.obs_buffer[0]\n",
    "        else:\n",
    "            obs = np.max(np.stack(self.obs_buffer), axis=0)\n",
    "        return obs, total_reward, done, truncated, info\n",
    "        # Life loss is calculated on the training code\n",
    "\n",
    "env = gym.vector.make(f\"{env_name}NoFrameskip-v4\", num_envs=1)\n",
    "env = MaxLast2FrameSkipWrapper(env,seed=SEED)\n",
    "\n",
    "\n",
    "#n_actions = env.action_space.n\n",
    "n_actions = env.action_space[0].n\n",
    "\n",
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "seed_np_torch(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8d429f2-aee0-4c6b-b221-d2a8b09b0e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 37.65M\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 37.65M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def renormalize(tensor, has_batch=False):\n",
    "    shape = tensor.shape\n",
    "    tensor = tensor.view(tensor.shape[0], -1)\n",
    "    max_value,_ = torch.max(tensor, -1, keepdim=True)\n",
    "    min_value,_ = torch.min(tensor, -1, keepdim=True)\n",
    "    return ((tensor - min_value) / (max_value - min_value + 1e-5)).view(shape)\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, n_actions, hiddens=2048, mlp_layers=1, scale_width=4,\n",
    "                 n_atoms=num_buckets, Vmin=-10, Vmax=10):\n",
    "        super().__init__()\n",
    "        self.support = torch.linspace(Vmin, Vmax, n_atoms).cuda()\n",
    "        \n",
    "        self.hiddens=hiddens\n",
    "        self.scale_width=scale_width\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "        \n",
    "        self.encoder_cnn = IMPALA_Resnet(scale_width=scale_width, norm=False, init=init_xavier, act=self.act)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Single layer dense that maps the flattened encoded representation into hiddens.\n",
    "        self.projection = MLP(13824, med_hiddens=hiddens, out_hiddens=hiddens,\n",
    "                              last_init=init_xavier, layers=1)\n",
    "        self.prediction = MLP(hiddens, out_hiddens=hiddens, layers=1, last_init=init_xavier)\n",
    "                                              \n",
    "        self.transition = nn.Sequential(DQN_Conv(128+n_actions, 128, 3, 1, 1, norm=False, init=init_xavier, act=self.act),\n",
    "                                        DQN_Conv(128, 128, 3, 1, 1, norm=False, init=init_xavier, act=self.act))\n",
    "\n",
    "        # Single layer dense that maps hiddens into the output dim according to:\n",
    "        # 1. https://arxiv.org/pdf/1707.06887.pdf -- Distributional Reinforcement Learning\n",
    "        # 2. https://arxiv.org/pdf/1511.06581.pdf -- Dueling DQN\n",
    "        self.a = MLP(hiddens, out_hiddens=n_actions*num_buckets, layers=1, in_act=self.act, last_init=init_xavier)\n",
    "        self.v = MLP(hiddens, out_hiddens=num_buckets, layers=1, in_act=self.act, last_init=init_xavier)\n",
    "    \n",
    "        params_count(self, 'DQN')\n",
    "    \n",
    "    def forward(self, X, y_action):\n",
    "        X, z = self.encode(X)\n",
    "        \n",
    "        \n",
    "        q, action = self.q_head(X)\n",
    "        z_pred = self.get_transition(z, y_action)\n",
    "\n",
    "        return q, action, X[:,1:].clone().detach(), z_pred\n",
    "    \n",
    "\n",
    "    def env_step(self, X):\n",
    "        with torch.no_grad():\n",
    "            X, _ = self.encode(X)\n",
    "            _, action = self.q_head(X)\n",
    "            \n",
    "            return action.detach()\n",
    "    \n",
    "\n",
    "    def encode(self, X):\n",
    "        batch, seq = X.shape[:2]\n",
    "        self.batch = batch\n",
    "        self.seq = seq\n",
    "        X = self.encoder_cnn(X.contiguous().view(self.batch*self.seq, *(X.shape[2:])))\n",
    "        X = renormalize(X).contiguous().view(self.batch, self.seq, *X.shape[-3:])\n",
    "        X = X.contiguous().view(self.batch, self.seq, *X.shape[-3:])\n",
    "        z = X.clone()\n",
    "        X = X.flatten(-3,-1)\n",
    "        X = self.projection(X)\n",
    "        return X, z\n",
    "\n",
    "    def get_transition(self, z, action):\n",
    "        z = z.contiguous().view(-1, *z.shape[-3:])\n",
    "        \n",
    "        action = F.one_hot(action.clone(), n_actions).view(-1, n_actions)\n",
    "        action = action.view(-1, 5, n_actions, 1, 1).expand(-1, 5, n_actions, *z.shape[-2:])\n",
    "\n",
    "        z_pred = torch.cat( (z, action[:,0]), 1)\n",
    "        z_pred = self.transition(z_pred)\n",
    "        z_pred = renormalize(z_pred)\n",
    "        \n",
    "        z_preds=[z_pred.clone()]\n",
    "        \n",
    "\n",
    "        for k in range(4):\n",
    "            z_pred = torch.cat( (z_pred, action[:,k+1]), 1)\n",
    "            z_pred = self.transition(z_pred)\n",
    "            z_pred = renormalize(z_pred)\n",
    "            \n",
    "            z_preds.append(z_pred)\n",
    "        \n",
    "        \n",
    "        z_pred = torch.stack(z_preds,1)\n",
    "\n",
    "        z_pred = self.projection(z_pred.flatten(-3,-1)).view(self.batch,5,-1)\n",
    "        z_pred = self.prediction(z_pred)\n",
    "        \n",
    "        return z_pred\n",
    "\n",
    "    \n",
    "    def q_head(self, X):\n",
    "        q = self.dueling_dqn(X)\n",
    "        action = q.mean(-1).argmax(-1)\n",
    "        \n",
    "        return q, action\n",
    "\n",
    "    def get_max_action(self, X):\n",
    "        with torch.no_grad():\n",
    "            X, _ = self.encode(X)\n",
    "            q = self.dueling_dqn(X)\n",
    "            \n",
    "            action = q.mean(-1).argmax(-1)\n",
    "            return action\n",
    "\n",
    "    def evaluate(self, X, action):\n",
    "        with torch.no_grad():\n",
    "            X, _ = self.encode(X)\n",
    "            \n",
    "            q = self.dueling_dqn(X)\n",
    "            \n",
    "            action = action[:,:,None,None].expand_as(q)[:,:,0][:,:,None]\n",
    "            q = q.gather(-2,action)\n",
    "            \n",
    "            return q\n",
    "\n",
    "    def dueling_dqn(self, X):\n",
    "        X = F.relu(X)\n",
    "        \n",
    "        a = self.a(X).view(self.batch, -1, n_actions, num_buckets)\n",
    "        v = self.v(X).view(self.batch, -1, 1, num_buckets)\n",
    "        \n",
    "        q = v + a - a.mean(-2,keepdim=True)\n",
    "        \n",
    "        \n",
    "        return q\n",
    "    \n",
    "    def network_ema(self, rand_network, target_network, alpha=0.5):\n",
    "        for param, param_target in zip(rand_network.parameters(), target_network.parameters()):\n",
    "            param_target.data = alpha * param_target.data + (1 - alpha) * param.data.clone()\n",
    "\n",
    "    def hard_reset(self, random_model, alpha=0.5):\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            self.network_ema(random_model.encoder_cnn, self.encoder_cnn, alpha)\n",
    "            self.network_ema(random_model.transition, self.transition, alpha)\n",
    "\n",
    "            self.network_ema(random_model.projection, self.projection, 0)\n",
    "            self.network_ema(random_model.prediction, self.prediction, 0)\n",
    "\n",
    "            self.network_ema(random_model.a, self.a, 0)\n",
    "            self.network_ema(random_model.v, self.v, 0)\n",
    "\n",
    "\n",
    "\n",
    "def copy_states(source, target):\n",
    "    for key, _ in zip(source.state_dict()['state'].keys(), target.state_dict()['state'].keys()):\n",
    "\n",
    "        target.state_dict()['state'][key]['exp_avg_sq'] = copy.deepcopy(source.state_dict()['state'][key]['exp_avg_sq'])\n",
    "        target.state_dict()['state'][key]['exp_avg'] = copy.deepcopy(source.state_dict()['state'][key]['exp_avg'])\n",
    "        target.state_dict()['state'][key]['step'] = copy.deepcopy(source.state_dict()['state'][key]['step'])\n",
    "        \n",
    "def target_model_ema(model, model_target):\n",
    "    with torch.no_grad():\n",
    "        for param, param_target in zip(model.parameters(), model_target.parameters()):\n",
    "            param_target.data = critic_ema_decay * param_target.data + (1.0 - critic_ema_decay) * param.data.clone()\n",
    "\n",
    "\n",
    "    \n",
    "model=DQN(n_actions).cuda()\n",
    "model_target=DQN(n_actions).cuda()\n",
    "\n",
    "model_target.load_state_dict(model.state_dict())\n",
    "\n",
    "\n",
    "# Testing only\n",
    "#with torch.no_grad():\n",
    "#    q, action, X, z_pred = model(torch.randn(4,1,12,96,72, device='cuda', dtype=torch.float), torch.randint(0,n_actions,(4,5),device='cuda').long())\n",
    "#z = model.encode(torch.randn(4,5,12,96,72, device='cuda'))[0]\n",
    "\n",
    "# I believe the authors have actually miscalculated the params count on the paper.\n",
    "# My training time is lower than theirs while having more parameters, and the same architecture is used as is their original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ca1d0e5-d128-428b-bcbc-be68dccc005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "perception_modules=[model.encoder_cnn, model.transition]\n",
    "actor_modules=[model.prediction, model.projection, model.a, model.v]\n",
    "\n",
    "params_wm=[]\n",
    "for module in perception_modules:\n",
    "    for param in module.parameters():\n",
    "        if param.requires_grad==True: # They all require grad\n",
    "            params_wm.append(param)\n",
    "\n",
    "params_ac=[]\n",
    "for module in actor_modules:\n",
    "    for param in module.parameters():\n",
    "        if param.requires_grad==True:\n",
    "            params_ac.append(param)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(chain(params_wm, params_ac),\n",
    "                                lr=lr, weight_decay=0.1, eps=1.5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7f2a7d7-81c6-4c93-8cbe-1f15fa75af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "                         transforms.Resize((96,72)),\n",
    "                        ])\n",
    "\n",
    "\n",
    "def preprocess(state):\n",
    "    state=torch.tensor(state, dtype=torch.float, device='cuda') / 255\n",
    "    state=train_tfms(state.permute(0,3,1,2))\n",
    "    return state\n",
    "\n",
    "# https://github.com/google/dopamine/blob/master/dopamine/jax/agents/dqn/dqn_agent.py\n",
    "def linearly_decaying_epsilon(decay_period, step, warmup_steps, epsilon):\n",
    "    steps_left = decay_period + warmup_steps - step\n",
    "    bonus = (1.0 - epsilon) * steps_left / decay_period\n",
    "    bonus = np.clip(bonus, 0., 1. - epsilon)\n",
    "    return epsilon + bonus\n",
    "\n",
    "\n",
    "def epsilon_greedy(Q_action, step, final_eps=0, num_envs=1):\n",
    "    epsilon = linearly_decaying_epsilon(2001, step, 2000, final_eps)\n",
    "    \n",
    "    if random.random() < epsilon:\n",
    "        action = torch.randint(0, n_actions, (num_envs,), dtype=torch.int64, device='cuda').squeeze(0)\n",
    "    else:\n",
    "        action = Q_action.view(num_envs).squeeze(0).to(torch.int64)\n",
    "    return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6722829c-d4bc-4d9f-aa35-80f6133a4819",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "def huber(x, k=1.0):\n",
    "    return torch.where(x.abs() < k, 0.5 * x.pow(2), k * (x.abs() - 0.5 * k))\n",
    "tau = torch.Tensor((2 * np.arange(num_buckets) + 1) / (2.0 * num_buckets)).view(1, -1).cuda()\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "def optimize(step, grad_step, n):\n",
    "        \n",
    "    model.train()\n",
    "    model_target.train()\n",
    "\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.bfloat16, enabled=False):\n",
    "        with torch.no_grad():\n",
    "            states, next_states, rewards, action, c_flag, idxs, is_w = memory.sample(n, batch_size, grad_step)\n",
    "        terminal=1-c_flag\n",
    "        #print(f\"STUFF HERE {states.shape, rewards.shape, c_flag.shape, action.shape, n}\")\n",
    "    \n",
    "    \n",
    "        q, max_action, _, z_pred = model(states[:,0][:,None], action[:,:5].long())\n",
    "        z = model_target.encode(states[:,1:6])[0].detach()\n",
    "\n",
    "        \n",
    "        max_action  = model.get_max_action(next_states[:,n-1][:,None])\n",
    "        next_values = model_target.evaluate(next_states[:,n-1][:,None].contiguous(), max_action)\n",
    "        \n",
    "\n",
    "        action = action[:,0,None].expand(batch_size,num_buckets)\n",
    "        action=action[:,None]\n",
    "        with torch.no_grad():\n",
    "            gammas_one=torch.ones(batch_size,n,1,dtype=torch.float,device='cuda')\n",
    "            gamma_step = 1-torch.tensor(( (schedule_max_step - min(grad_step, schedule_max_step)) / schedule_max_step) * (initial_gamma-final_gamma) + final_gamma).exp()\n",
    "            gammas=gammas_one*gamma_step\n",
    "\n",
    "            \n",
    "            returns = []\n",
    "            for t in range(n):\n",
    "                ret = 0\n",
    "                for u in reversed(range(t, n)):\n",
    "                    ret += torch.prod(c_flag[:,t+1:u+1],-2)*torch.prod(gammas[:,t:u],-2)*rewards[:,u+1]\n",
    "                returns.append(ret)\n",
    "            returns = torch.stack(returns,1)\n",
    "        \n",
    "        \n",
    "        plot_vs = returns.clone().sum(-1)\n",
    "        \n",
    "        \n",
    "        same_traj = (torch.prod(c_flag[:,:n],-2)).squeeze()\n",
    "        next_values = next_values[:,0]\n",
    "        \n",
    "        returns = returns[:,0]\n",
    "        #returns = returns + torch.prod(gammas[0,:10],-2).squeeze()*same_traj[:,None]*model.support[None,:]\n",
    "        \n",
    "        Ttheta = returns[...,None] + torch.prod(gammas[0,:10],-2).squeeze() * same_traj[:,None,None] * next_values\n",
    "        Ttheta = Ttheta.squeeze()\n",
    "\n",
    "        Q = q[:,0].gather(-2, action)[:,None]\n",
    "\n",
    "\n",
    "        \n",
    "        diff = Ttheta.t()[..., None] - Q.squeeze()\n",
    "\n",
    "        loss = huber(diff) * (tau - (diff.detach() < 0).float()).abs()\n",
    "        loss = loss.mean(-1).T\n",
    "        loss = loss.view(batch_size, -1).mean(-1)\n",
    "        \n",
    "        \n",
    "        dqn_loss = loss.clone().mean()\n",
    "        \n",
    "\n",
    "        \n",
    "        batched_loss = loss.clone()\n",
    "        \n",
    "        \n",
    "        z = F.normalize(z, 2, dim=-1, eps=1e-5)\n",
    "        z_pred = F.normalize(z_pred, 2, dim=-1, eps=1e-5)\n",
    "\n",
    "        \n",
    "        recon_loss = (mse(z_pred.contiguous().view(-1,2048), z.contiguous().view(-1,2048))).sum(-1)\n",
    "        recon_loss = 5*(recon_loss.view(batch_size, -1).mean(-1))*same_traj\n",
    "        \n",
    "        \n",
    "        loss += recon_loss\n",
    "        \n",
    "        loss = (loss*is_w).mean() # mean across batch axis\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    param_norm, grad_norm = params_and_grad_norm(model)\n",
    "    #scaler.scale(loss).backward()\n",
    "    #scaler.unscale_(optimizer)\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "    #scaler.step(optimizer)\n",
    "    #scaler.update()\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #memory.set_priority(idxs, batched_loss)\n",
    "    memory.set_priority(idxs, batched_loss, same_traj)\n",
    "    \n",
    "    \n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    wandb.log({'loss': loss, 'dqn_loss': dqn_loss, 'recon_loss': recon_loss.mean(), 'lr': lr, 'returns': plot_vs.mean(),\n",
    "               'buffer rewards': rewards.mean(0).sum(), 'is_w': is_w.mean(),\n",
    "               'gamma': gamma_step, 'param_norm': param_norm.sum(), 'grad_norm': grad_norm.sum()})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scores=[]\n",
    "memory.free()\n",
    "step=0\n",
    "#model.share_memory()\n",
    "grad_step=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05991348-a11a-43bd-882f-02df107fc543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2000/102000 [00:16<11:56, 139.61it/s]C:\\Users\\sneep\\AppData\\Local\\Temp\\ipykernel_23136\\1072669187.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gamma_step = 1-torch.tensor(( (schedule_max_step - min(grad_step, schedule_max_step)) / schedule_max_step) * (initial_gamma-final_gamma) + final_gamma).exp()\n",
      " 22%|██▏       | 22002/102000 [59:48<3:56:58,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting on step 22001 40002\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 37.65M\n",
      "IMPALA ResNet Parameters: 1.56M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22003/102000 [1:00:14<171:01:36,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Parameters: 37.65M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 42003/102000 [2:03:47<3:12:25,  5.20it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting on step 42002 40002\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 37.65M\n",
      "IMPALA ResNet Parameters: 1.56M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 42004/102000 [2:04:10<117:42:04,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Parameters: 37.65M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 62004/102000 [3:16:35<2:28:50,  4.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting on step 62003 40002\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 37.65M\n",
      "IMPALA ResNet Parameters: 1.56M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 62005/102000 [3:17:09<113:58:25, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Parameters: 37.65M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 82005/102000 [4:41:46<1:20:54,  4.12it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting on step 82004 40002\n",
      "IMPALA ResNet Parameters: 1.56M\n",
      "DQN Parameters: 37.65M\n",
      "IMPALA ResNet Parameters: 1.56M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 82006/102000 [4:42:14<48:29:18,  8.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Parameters: 37.65M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102000/102000 [6:10:40<00:00,  4.45it/s]  "
     ]
    }
   ],
   "source": [
    "step=0\n",
    "\n",
    "progress_bar = tqdm.tqdm(total=total_steps)\n",
    "\n",
    "while step<(10):\n",
    "    state, info = env.reset()\n",
    "    state = preprocess(state)\n",
    "\n",
    "    states = deque(maxlen=4)\n",
    "    for i in range(4):\n",
    "        states.append(state)\n",
    "    \n",
    "    \n",
    "    eps_reward=torch.tensor([0], dtype=torch.float)\n",
    "    \n",
    "    reward=np.array([0])\n",
    "    done_flag=np.array([False])\n",
    "    terminated=np.array([False])\n",
    "\n",
    "    last_lives=np.array([0])\n",
    "    life_loss=np.array([0])\n",
    "    resetted=np.array([0])\n",
    "    \n",
    "    last_grad_update=0\n",
    "    while step<(total_steps):\n",
    "        progress_bar.update(1)\n",
    "        model_target.train()\n",
    "        \n",
    "        len_memory = len(memory)\n",
    "        \n",
    "        #if resetted[0]>0:\n",
    "        #    states = env.noop_steps(states)\n",
    "            \n",
    "        Q_action = model_target.env_step(torch.cat(list(states),-3).unsqueeze(0))\n",
    "        \n",
    "        action = epsilon_greedy(Q_action, len_memory).cpu()\n",
    "        \n",
    "        memory.push(torch.cat(list(states),-3).detach().cpu(), reward, action, np.logical_or(done_flag, life_loss))\n",
    "        #print('action', action, action.shape)\n",
    "        \n",
    "        state, reward, terminated, truncated, info = env.step([action.numpy()])\n",
    "        state = preprocess(state)\n",
    "        states.append(state)\n",
    "        \n",
    "        eps_reward+=reward\n",
    "        reward = reward.clip(-1, 1)\n",
    "\n",
    "\n",
    "        \n",
    "        done_flag = np.logical_or(terminated, truncated)\n",
    "        lives = info['lives']\n",
    "        life_loss = (last_lives-lives).clip(min=0)\n",
    "        resetted = (lives-last_lives).clip(min=0)\n",
    "        last_lives = lives\n",
    "\n",
    "        \n",
    "        n = int(initial_n * (final_n/initial_n)**(min(grad_step,schedule_max_step) / schedule_max_step))\n",
    "        n = np.array(n).item()\n",
    "        \n",
    "        memory.priority[len_memory] = memory.max_priority()\n",
    "        \n",
    "\n",
    "        if len_memory>2000:\n",
    "            for i in range(2):\n",
    "                optimize(step, grad_step, n)\n",
    "                target_model_ema(model, model_target)\n",
    "                grad_step+=1\n",
    "\n",
    "        \n",
    "        if ((step+1)%10000)==0:\n",
    "            save_checkpoint(model, model_target, optimizer, step,\n",
    "                            'checkpoints/atari_last.pth')\n",
    "        \n",
    "            \n",
    "        \n",
    "        if grad_step>reset_every:\n",
    "            #eval()\n",
    "            print('Reseting on step', step, grad_step)\n",
    "            \n",
    "            #seed_np_torch(random.randint(SEED-1000, SEED+1000)+step)\n",
    "            random_model = DQN(n_actions).cuda()\n",
    "            model.hard_reset(random_model)\n",
    "            \n",
    "            #seed_np_torch(random.randint(SEED-1000, SEED+1000)+step)\n",
    "            random_model = DQN(n_actions).cuda()\n",
    "            model_target.hard_reset(random_model)\n",
    "            seed_np_torch(SEED)\n",
    "            \n",
    "            random_model=None\n",
    "            grad_step=0\n",
    "\n",
    "            actor_modules=[model.prediction, model.projection, model.a, model.v]\n",
    "            params_ac=[]\n",
    "            for module in actor_modules:\n",
    "                for param in module.parameters():\n",
    "                    params_ac.append(param)\n",
    "                    \n",
    "\n",
    "            perception_modules=[model.encoder_cnn, model.transition]\n",
    "            params_wm=[]\n",
    "            for module in perception_modules:\n",
    "                for param in module.parameters():\n",
    "                    params_wm.append(param)\n",
    "            \n",
    "            optimizer_aux = torch.optim.AdamW(params_wm, lr=lr, weight_decay=0.1, eps=1.5e-4)\n",
    "            copy_states(optimizer, optimizer_aux)\n",
    "            optimizer = torch.optim.AdamW(chain(params_wm, params_ac),\n",
    "                                lr=lr, weight_decay=0.1, eps=1.5e-4)\n",
    "            copy_states(optimizer_aux, optimizer)\n",
    "        \n",
    "        \n",
    "        \n",
    "        step+=1\n",
    "        \n",
    "        log_t = done_flag.astype(float).nonzero()[0]\n",
    "        \n",
    "        if len(log_t)>0:\n",
    "            for log in log_t:\n",
    "                wandb.log({'eps_reward': eps_reward[log].sum()})\n",
    "                scores.append(eps_reward[log].clone())\n",
    "            eps_reward[log_t]=0\n",
    "\n",
    "save_checkpoint(model, model_target, optimizer, step, f'checkpoints/{env_name}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87344597-e733-451c-8a5f-2a00b5511061",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_to_eval=False\n",
    "\n",
    "if load_to_eval:\n",
    "    model.load_state_dict(torch.load(f'checkpoints/{env_name}.pth')['model_state_dict'])\n",
    "    model_target.load_state_dict(torch.load(f'checkpoints/{env_name}.pth')['model_target_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12d36218-ab48-42d9-a7ba-fabb66cc758f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init state torch.Size([1, 3, 96, 72])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 1/100 [00:04<07:52,  4.78s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:08<06:27,  3.95s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [00:12<06:20,  3.92s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [00:16<06:54,  4.32s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [00:21<06:51,  4.33s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [00:25<06:44,  4.30s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [00:29<06:30,  4.20s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [00:35<07:06,  4.64s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [00:40<07:26,  4.91s/it]\u001b[A\n",
      " 10%|█         | 10/100 [00:46<07:45,  5.18s/it]\u001b[A\n",
      " 11%|█         | 11/100 [00:51<07:40,  5.17s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:56<07:33,  5.15s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [01:02<07:32,  5.20s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [01:06<07:14,  5.05s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [01:11<07:01,  4.96s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [01:16<07:05,  5.06s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [01:22<07:07,  5.15s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [01:26<06:34,  4.81s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [01:31<06:54,  5.12s/it]\u001b[A\n",
      " 20%|██        | 20/100 [01:37<07:00,  5.26s/it]\u001b[A\n",
      " 21%|██        | 21/100 [01:43<07:04,  5.38s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [01:48<07:06,  5.47s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [01:56<07:39,  5.97s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [02:01<07:19,  5.78s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [02:07<07:30,  6.01s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [02:14<07:36,  6.17s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [02:20<07:26,  6.11s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [02:26<07:11,  5.99s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [02:32<07:04,  5.98s/it]\u001b[A\n",
      " 30%|███       | 30/100 [02:37<06:48,  5.84s/it]\u001b[A\n",
      " 31%|███       | 31/100 [02:43<06:36,  5.75s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [02:47<05:58,  5.28s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [02:52<05:57,  5.34s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [02:58<06:00,  5.46s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [03:03<05:53,  5.44s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [03:09<05:58,  5.60s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [03:14<05:34,  5.31s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [03:21<06:06,  5.91s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [03:29<06:28,  6.38s/it]\u001b[A\n",
      " 40%|████      | 40/100 [03:35<06:21,  6.36s/it]\u001b[A\n",
      " 41%|████      | 41/100 [03:40<05:46,  5.87s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [03:45<05:35,  5.78s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [03:51<05:18,  5.60s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [03:55<04:45,  5.10s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [04:00<04:42,  5.14s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [04:05<04:39,  5.18s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [04:10<04:27,  5.04s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [04:14<04:13,  4.87s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [04:19<04:13,  4.97s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [04:23<03:54,  4.68s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [04:29<03:59,  4.89s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [04:35<04:08,  5.17s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [04:39<03:58,  5.07s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [04:45<03:56,  5.14s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [04:50<03:49,  5.10s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [04:55<03:49,  5.22s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [05:00<03:42,  5.17s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [05:05<03:29,  4.98s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [05:10<03:30,  5.14s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [05:18<03:58,  5.97s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [05:23<03:39,  5.62s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [05:28<03:24,  5.37s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [05:35<03:36,  5.85s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [05:42<03:39,  6.10s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [05:47<03:29,  5.98s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [05:52<03:13,  5.70s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [05:59<03:14,  5.89s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [06:04<02:59,  5.62s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [06:09<02:56,  5.70s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [06:14<02:43,  5.43s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [06:21<02:45,  5.72s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [06:27<02:46,  5.93s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [06:32<02:34,  5.71s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [06:37<02:20,  5.40s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [06:44<02:23,  5.74s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [06:48<02:10,  5.42s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [06:54<02:05,  5.46s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [07:02<02:19,  6.32s/it]\u001b[A\n",
      " 79%|███████▉  | 79/100 [07:08<02:08,  6.14s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [07:14<02:05,  6.27s/it]\u001b[A\n",
      " 81%|████████  | 81/100 [07:21<02:02,  6.44s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [07:28<01:56,  6.45s/it]\u001b[A\n",
      " 83%|████████▎ | 83/100 [07:32<01:40,  5.92s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [07:36<01:25,  5.36s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [07:41<01:19,  5.28s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [07:46<01:12,  5.17s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [07:51<01:05,  5.05s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [07:56<00:58,  4.92s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [08:00<00:51,  4.66s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [08:03<00:42,  4.27s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [08:09<00:41,  4.59s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [08:13<00:37,  4.65s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [08:18<00:32,  4.62s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [08:22<00:26,  4.36s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [08:26<00:22,  4.47s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [08:32<00:19,  4.87s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [08:38<00:15,  5.27s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [08:44<00:10,  5.31s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [08:49<00:05,  5.38s/it]\u001b[A\n",
      "100%|██████████| 100/100 [08:55<00:00,  5.35s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Mean 719.46\n",
      "Inter Quantile Mean 711.06\n",
      "Inter Quantile STD 19.904270898478046\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_envs=1\n",
    "\n",
    "#env = gym.vector.make(f\"{env_name}NoFrameskip-v4\", num_envs=num_envs, render_mode='human')\n",
    "env = gym.vector.make(f\"{env_name}NoFrameskip-v4\", num_envs=num_envs)\n",
    "env = MaxLast2FrameSkipWrapper(env,seed=SEED)\n",
    "\n",
    "def eval_phase(eval_runs=50, max_eval_steps=27000, num_envs=1):\n",
    "    progress_bar = tqdm.tqdm(total=eval_runs)\n",
    "    \n",
    "    scores=[]\n",
    "    \n",
    "    state, info = env.reset()\n",
    "    state = preprocess(state)\n",
    "    print(f\"init state {state.shape}\")\n",
    "    \n",
    "    states = deque(maxlen=4)\n",
    "    for i in range(4):\n",
    "        states.append(state)\n",
    "    \n",
    "    \n",
    "    eps_reward=torch.tensor([0]*num_envs, dtype=torch.float)\n",
    "    \n",
    "    reward=np.array([0]*num_envs)\n",
    "    terminated=np.array([False]*num_envs)\n",
    "    \n",
    "    last_lives=np.array([0]*num_envs)\n",
    "    life_loss=np.array([0]*num_envs)\n",
    "    resetted=np.array([0])\n",
    "\n",
    "    finished_envs=np.array([False]*num_envs)\n",
    "    done_flag=0\n",
    "    last_grad_update=0\n",
    "    eval_run=0\n",
    "    step=np.array([0]*num_envs)\n",
    "    while eval_run<eval_runs:\n",
    "        #seed_np_torch(SEED+eval_run)\n",
    "        env.seed=SEED+eval_run\n",
    "        model_target.train()\n",
    "        \n",
    "        #if resetted[0]>0:\n",
    "        #    states = env.noop_steps(states)\n",
    "        \n",
    "        Q_action = model_target.env_step(torch.cat(list(states),-3).unsqueeze(0))\n",
    "        action = epsilon_greedy(Q_action.squeeze(), 5000, 0.0005, num_envs).cpu()\n",
    "        \n",
    "        state, reward, terminated, truncated, info = env.step([action.numpy()] if num_envs==1 else action.numpy())\n",
    "        state = preprocess(state)\n",
    "        states.append(state)\n",
    "        \n",
    "        eps_reward+=reward\n",
    "\n",
    "        \n",
    "        done_flag = np.logical_or(terminated, truncated)\n",
    "        lives = info['lives']\n",
    "        life_loss = (last_lives-lives).clip(min=0)\n",
    "        resetted = (lives-last_lives).clip(min=0)\n",
    "        last_lives = lives        \n",
    "        \n",
    "        step+=1\n",
    "        \n",
    "        log_t = done_flag.astype(float).nonzero()[0]\n",
    "        if len(log_t)>0:# or (step>max_eval_steps).any():\n",
    "            progress_bar.update(1)\n",
    "            for log in log_t:\n",
    "                #wandb.log({'eval_eps_reward': eps_reward[log].sum()})\n",
    "                if finished_envs[log]==False:\n",
    "                    scores.append(eps_reward[log].clone())\n",
    "                    eval_run+=1\n",
    "                    #finished_envs[log]=True\n",
    "                step[log]=0\n",
    "                \n",
    "            eps_reward[log_t]=0            \n",
    "            for i, log in enumerate(step>max_eval_steps):\n",
    "                if log==True and finished_envs[i]==False:\n",
    "                    scores.append(eps_reward[i].clone())\n",
    "                    step[i]=0\n",
    "                    eval_run+=1\n",
    "                    eps_reward[i]=0\n",
    "                    #finished_envs[i]=True\n",
    "            \n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "def eval(eval_runs=50, max_eval_steps=27000, num_envs=1):\n",
    "    assert num_envs==1, 'The code for num eval envs > 1 is messed up.'\n",
    "    \n",
    "    scores = eval_phase(eval_runs, max_eval_steps, num_envs)    \n",
    "    scores = torch.stack(scores)\n",
    "    scores, _ = scores.sort()\n",
    "    \n",
    "    _25th = eval_runs//4\n",
    "\n",
    "    iq = scores[_25th:-_25th]\n",
    "    iqm = iq.mean()\n",
    "    iqs = iq.std()\n",
    "\n",
    "    print(f\"Scores Mean {scores.mean()}\")\n",
    "    print(f\"Inter Quantile Mean {iqm}\")\n",
    "    print(f\"Inter Quantile STD {iqs}\")\n",
    "\n",
    "    \n",
    "    plt.xlabel('Episode (Sorted by Reward)')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.plot(scores)\n",
    "    \n",
    "    new_row = {'env_name': env_name, 'mean': scores.mean().item(), 'iqm': iqm.item(), 'std': iqs.item(), 'seed': SEED}\n",
    "    add_to_csv('results.csv', new_row)\n",
    "\n",
    "    with open(f'results/{env_name}-{SEED}.txt', 'w') as f:\n",
    "        f.write(f\" Scores Mean {scores.mean()}\\n Inter Quantile Mean {iqm}\\n Inter Quantile STD {iqs}\")\n",
    "    \n",
    "    \n",
    "    return scores\n",
    "\n",
    "scores = eval(eval_runs=100, num_envs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57556912-f811-4eb5-9030-f8f77e3962ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b215ce8f-b10d-4ed3-8651-86ae074d14af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7021, 3.7418, 4.6646, 5.3234, 5.7941, 6.0386, 6.2082, 6.2924, 6.3797,\n",
       "        6.4553, 6.5053, 6.5614, 6.5681, 6.5962, 6.6273, 6.6817, 6.7313, 6.7394,\n",
       "        6.7672, 6.7908, 6.8267, 6.8355, 6.8195, 6.8823, 6.9239, 6.9206, 6.9285,\n",
       "        6.9620, 6.9763, 6.9806, 7.0162, 7.0238, 7.0462, 7.0272, 7.0795, 7.0721,\n",
       "        7.0703, 7.0855, 7.1469, 7.0964, 7.1540, 7.1505, 7.1517, 7.1784, 7.1825,\n",
       "        7.1999, 7.1673, 7.2023, 7.2002, 7.2142, 7.2626, 7.3072, 7.2542, 7.2726,\n",
       "        7.2810, 7.2700, 7.2823, 7.2986, 7.3233, 7.3076, 7.2940, 7.3118, 7.3660,\n",
       "        7.3586, 7.3486, 7.3695, 7.3675, 7.3482, 7.3709, 7.3859, 7.3716, 7.4275,\n",
       "        7.3961, 7.3985, 7.3822, 7.4635, 7.4398, 7.4374, 7.4580, 7.4686, 7.4588,\n",
       "        7.4625, 7.4982, 7.4752, 7.4880, 7.5213, 7.5128, 7.5053, 7.5106, 7.5105,\n",
       "        7.5385, 7.5565, 7.5390, 7.5461, 7.5827, 7.6023, 7.5898, 7.5808, 7.5818,\n",
       "        7.5862, 7.5807, 7.6003, 7.5980, 7.6403, 7.6408, 7.6058, 7.6078, 7.6186,\n",
       "        7.6360, 7.6668, 7.6330, 7.7007, 7.6500, 7.6706, 7.6823, 7.6863, 7.6948,\n",
       "        7.7144, 7.7339, 7.7319, 7.7241, 7.7227, 7.7547, 7.7349, 7.7617, 7.7731,\n",
       "        7.7409, 7.7750, 7.7564, 7.7855, 7.8425, 7.8108, 7.7857, 7.8177, 7.7948,\n",
       "        7.8548, 7.8517, 7.8358, 7.8591, 7.8546, 7.8502, 7.8783, 7.9062, 7.8764,\n",
       "        7.8603, 7.9094, 7.9153, 7.9326, 7.9287, 7.9304, 7.9521, 7.9585, 7.9627,\n",
       "        7.9688, 7.9794, 8.0079, 8.0023, 8.0067, 8.0012, 8.0309, 8.0131, 8.0192,\n",
       "        8.0449, 8.0487, 8.0849, 8.0997, 8.0901, 8.1154, 8.1333, 8.1364, 8.1196,\n",
       "        8.1686, 8.1766, 8.2327, 8.1837, 8.2003, 8.2375, 8.2441, 8.2664, 8.2744,\n",
       "        8.2582, 8.3256, 8.3316, 8.3147, 8.3272, 8.3950, 8.3963, 8.4254, 8.4321,\n",
       "        8.4505, 8.5262, 8.5548, 8.5902, 8.6460, 8.6271, 8.7550, 8.8109, 8.9440,\n",
       "        9.0735, 9.3384], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = model_target(torch.cat(list(states),-3).unsqueeze(0), torch.randint(0,n_actions,(1,5),device='cuda').long())\n",
    "Q[0][0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b117b-8b90-40b7-8cce-1dd696fe6294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
